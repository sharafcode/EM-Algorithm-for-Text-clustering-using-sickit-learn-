{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from em_utilities import *\n",
    "import sframe as sf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer , CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import scipy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 0:\n",
    "## Dataset definition and feature extraction (tf-idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] sframe.cython.cy_server: SFrame v2.1 started. Logging /tmp/sframe_server_1504103005.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,str,str,dict]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/abdl-rahman/Desktop/Recommendation systems/EM for clustering/KO_articles_tfidf.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/abdl-rahman/Desktop/Recommendation systems/EM for clustering/KO_articles_tfidf.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1390 lines in 0.848133 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1390 lines in 0.848133 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset= sf.SFrame('KO_articles_tfidf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidfvec= TfidfVectorizer(stop_words='english')\n",
    "tf_idf_matrix= tfidfvec.fit_transform(dataset['text'])\n",
    "tf_idf_matrix = normalize(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: \n",
    "## Model Parameters smart initialization\n",
    "\n",
    "Used Kmeans++ model to initialize the parameters for the model of EM algorithm.\n",
    "- Kmeans++ used to initialize the means (Centroids of clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Smart Initialization for means with using KMeans++ model \n",
    "def initialize_means(num_clusters,features_matrix):\n",
    "    from sklearn.cluster import KMeans\n",
    "    np.random.seed(5)\n",
    "    kmeans_model = KMeans(n_clusters=num_clusters, init='k-means++', n_init=5, max_iter=400, random_state=1, n_jobs=1)\n",
    "    kmeans_model.fit(features_matrix)\n",
    "    centroids, cluster_assignment = kmeans_model.cluster_centers_, kmeans_model.labels_\n",
    "    means = [centroid for centroid in centroids]\n",
    "    return [means , cluster_assignment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Smart initialization for weights\n",
    "def initialize_weights(num_clusters,features_matrix,cluster_assignment):\n",
    "    num_docs = features_matrix.shape[0]\n",
    "    weights = []\n",
    "    for i in xrange(num_clusters):\n",
    "        num_assigned = len(cluster_assignment[cluster_assignment==i]) # YOUR CODE HERE\n",
    "        w = float(num_assigned) / num_docs\n",
    "        weights.append(w)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Smart initialization for covariances\n",
    "def initialize_covs(num_clusters,features_matrix,cluster_assignment):\n",
    "    covs = []\n",
    "    for i in xrange(num_clusters):\n",
    "        member_rows = features_matrix[cluster_assignment==i]\n",
    "        cov = (member_rows.multiply(member_rows) - 2*member_rows.dot(diag(means[i]))).sum(axis=0).A1 / member_rows.shape[0] \\\n",
    "        + means[i]**2\n",
    "        cov[cov < 1e-8] = 1e-8\n",
    "        covs.append(cov)\n",
    "    return covs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2:\n",
    "## Training Models with different number of clusters\n",
    "\n",
    "Initializing the parameters for each model then start training using the Expectation-Maximization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 1 with 10 clusters\n",
    "(means , cluster_assignment_10model)= initialize_means(10,tf_idf_matrix)\n",
    "covs= initialize_covs(10,tf_idf_matrix, cluster_assignment_10model)\n",
    "weights= initialize_weights(10,tf_idf_matrix, cluster_assignment_10model)\n",
    "model_em_10k= EM_for_high_dimension(tf_idf_matrix, means, covs, weights, cov_smoothing=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model 2 with 20 clusters.\n",
    "(means , cluster_assignment_20model)= initialize_means(20,tf_idf_matrix)\n",
    "covs= initialize_covs(20,tf_idf_matrix, cluster_assignment_20model)\n",
    "weights= initialize_weights(20,tf_idf_matrix, cluster_assignment_20model)\n",
    "model_em_20k= EM_for_high_dimension(tf_idf_matrix, means, covs, weights, cov_smoothing=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3:\n",
    "## Evaluation report for each cluster (Interpreting clusters)\n",
    "\n",
    "Evaluation report is divided into two partitions the first one is the word representation for each cluster the really interpret the cluster, the second one is for the variety of article types in one cluster counting each category for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_EM_clusters(tf_idf, means, covs, map_index_to_word):\n",
    "    print('')\n",
    "    print('==========================================================')\n",
    "\n",
    "    num_clusters = len(means)\n",
    "    for c in xrange(num_clusters):\n",
    "        print('Cluster {0:d}: Largest mean parameters in cluster '.format(c))\n",
    "        print('\\n{0: <12}{1: <12}{2: <12}'.format('Word', 'Mean', 'Variance'))\n",
    "        \n",
    "        # The k'th element of sorted_word_ids should be the index of the word \n",
    "        # that has the k'th-largest value in the cluster mean. Hint: Use np.argsort().\n",
    "        sorted_word_ids = np.argsort(means[c])[::-1]\n",
    "\n",
    "        for i in sorted_word_ids[:10]:\n",
    "            print '{0: <12}{1:<10.2e}{2:10.2e}'.format(map_index_to_word[i], \n",
    "                                                       means[c][i],\n",
    "                                                       covs[c][i])\n",
    "        print '\\n=========================================================='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clusters_report(clusters_idx):\n",
    "    cluster_id=0\n",
    "    for cluster_indicies in clusters_idx:\n",
    "        countP=0\n",
    "        countB=0\n",
    "        countE=0\n",
    "        for i in cluster_indicies:\n",
    "            if dataset['category'][i]=='product':\n",
    "                countP+=1\n",
    "            elif dataset['category'][i]=='engineering':\n",
    "                countE+=1\n",
    "            elif dataset['category'][i]=='business':\n",
    "                countB+=1\n",
    "        print \"Cluster \",cluster_id ,\"\\n==========================\\n\"\n",
    "        cluster_id+=1\n",
    "        print \"product count : \",countP ,\"\\nengineering count : \",countE,\"\\nbusiness count : \",countB , \"\\n\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================\n",
      "Cluster 0: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "company     4.83e-02    3.26e-03\n",
      "startup     4.27e-02    4.71e-03\n",
      "people      4.07e-02    1.93e-03\n",
      "business    3.88e-02    2.90e-03\n",
      "companies   3.66e-02    2.38e-03\n",
      "investors   2.95e-02    3.70e-03\n",
      "time        2.83e-02    6.75e-04\n",
      "founders    2.70e-02    3.10e-03\n",
      "like        2.63e-02    5.71e-04\n",
      "market      2.49e-02    1.96e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 1: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "data        5.34e-02    8.40e-03\n",
      "code        3.72e-02    4.48e-03\n",
      "microservices3.05e-02    1.23e-02\n",
      "services    2.43e-02    3.18e-03\n",
      "service     2.29e-02    3.02e-03\n",
      "serverless  2.12e-02    1.07e-02\n",
      "use         2.01e-02    4.50e-04\n",
      "new         1.96e-02    5.97e-04\n",
      "time        1.93e-02    4.59e-04\n",
      "application 1.89e-02    1.21e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 2: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "product     2.28e-01    1.03e-02\n",
      "customer    5.76e-02    5.95e-03\n",
      "customers   5.72e-02    5.05e-03\n",
      "team        4.65e-02    2.59e-03\n",
      "manager     4.26e-02    4.71e-03\n",
      "users       3.88e-02    3.52e-03\n",
      "management  3.71e-02    3.94e-03\n",
      "user        3.64e-02    3.06e-03\n",
      "managers    3.64e-02    3.29e-03\n",
      "people      3.61e-02    1.95e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 3: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "users       8.33e-02    7.54e-03\n",
      "user        6.69e-02    6.01e-03\n",
      "app         6.40e-02    1.28e-02\n",
      "mobile      5.60e-02    1.24e-02\n",
      "design      4.65e-02    3.03e-03\n",
      "content     4.56e-02    8.84e-03\n",
      "product     4.06e-02    2.01e-03\n",
      "platform    3.84e-02    8.94e-03\n",
      "people      3.46e-02    1.83e-03\n",
      "apps        3.28e-02    3.98e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 4: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "pricing     3.46e-01    5.25e-02\n",
      "price       2.52e-01    3.12e-02\n",
      "product     9.03e-02    5.64e-03\n",
      "customers   8.37e-02    2.89e-03\n",
      "prices      7.67e-02    5.47e-03\n",
      "pay         6.44e-02    2.28e-03\n",
      "value       5.59e-02    2.03e-03\n",
      "apple       5.24e-02    3.38e-02\n",
      "market      4.63e-02    1.85e-03\n",
      "customer    4.50e-02    2.11e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 5: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "team        1.30e-01    9.49e-03\n",
      "people      5.72e-02    3.58e-03\n",
      "teams       4.68e-02    6.28e-03\n",
      "work        4.61e-02    2.00e-03\n",
      "culture     4.30e-02    1.05e-02\n",
      "time        4.24e-02    1.14e-03\n",
      "company     4.09e-02    2.37e-03\n",
      "product     3.82e-02    2.09e-03\n",
      "buffer      3.29e-02    9.88e-03\n",
      "ve          2.98e-02    1.20e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 6: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "design      2.40e-01    2.62e-02\n",
      "designer    2.06e-01    2.56e-02\n",
      "newslog     1.06e-01    4.00e-02\n",
      "meets       7.31e-02    1.90e-02\n",
      "medium      5.69e-02    5.23e-02\n",
      "community   5.59e-02    7.55e-03\n",
      "startup     5.23e-02    3.37e-02\n",
      "join        5.13e-02    9.36e-03\n",
      "news        4.79e-02    8.17e-03\n",
      "start       4.27e-02    1.83e-02\n",
      "\n",
      "==========================================================\n",
      "Cluster 7: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "netflix     6.58e-01    4.27e-03\n",
      "blog        2.51e-01    7.75e-03\n",
      "technology  1.75e-01    4.70e-03\n",
      "regarding   1.62e-01    4.03e-03\n",
      "perspectives1.57e-01    3.81e-03\n",
      "tech        1.36e-01    3.63e-03\n",
      "issues      1.02e-01    1.17e-03\n",
      "challenges  9.98e-02    1.53e-03\n",
      "focused     9.80e-02    1.48e-03\n",
      "decisions   9.44e-02    1.37e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 8: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "design      2.09e-01    1.29e-02\n",
      "designers   9.05e-02    1.17e-02\n",
      "ux          5.97e-02    1.60e-02\n",
      "team        5.29e-02    4.26e-03\n",
      "product     5.22e-02    3.18e-03\n",
      "work        5.18e-02    2.86e-03\n",
      "designer    4.72e-02    2.37e-03\n",
      "project     4.29e-02    5.74e-03\n",
      "people      4.12e-02    2.17e-03\n",
      "sprint      3.62e-02    1.32e-02\n",
      "\n",
      "==========================================================\n",
      "Cluster 9: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "xero        3.86e-01    3.81e-06\n",
      "vet         2.42e-01    1.50e-06\n",
      "institute   2.20e-01    1.23e-06\n",
      "codigodelsur1.98e-01    1.00e-06\n",
      "tech        1.78e-01    8.07e-07\n",
      "veteran     1.65e-01    7.01e-07\n",
      "accounting  1.56e-01    6.25e-07\n",
      "firms       1.38e-01    4.89e-07\n",
      "founder     1.31e-01    4.38e-07\n",
      "highly      1.01e-01    2.61e-07\n",
      "\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "visualize_EM_clusters(tf_idf_matrix, model_em_10k['means'], model_em_10k['covs'], tfidfvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================\n",
      "Cluster 0: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "pitch       1.20e-01    2.29e-02\n",
      "story       1.01e-01    2.12e-02\n",
      "investors   8.74e-02    1.20e-02\n",
      "investor    6.82e-02    1.29e-02\n",
      "startup     6.59e-02    3.21e-02\n",
      "start       5.06e-02    1.60e-02\n",
      "company     5.06e-02    3.31e-03\n",
      "founders    4.96e-02    6.69e-03\n",
      "product     4.72e-02    3.23e-03\n",
      "habit       4.40e-02    1.15e-02\n",
      "\n",
      "==========================================================\n",
      "Cluster 1: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "people      7.25e-02    4.49e-03\n",
      "work        4.99e-02    3.34e-03\n",
      "time        4.81e-02    1.08e-03\n",
      "team        4.79e-02    2.55e-03\n",
      "things      3.91e-02    1.74e-03\n",
      "company     3.79e-02    2.43e-03\n",
      "ve          3.70e-02    1.48e-03\n",
      "like        3.67e-02    9.08e-04\n",
      "buffer      3.39e-02    9.56e-03\n",
      "just        3.36e-02    8.72e-04\n",
      "\n",
      "==========================================================\n",
      "Cluster 2: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "netflix     6.58e-01    4.27e-03\n",
      "blog        2.51e-01    7.75e-03\n",
      "technology  1.75e-01    4.70e-03\n",
      "regarding   1.62e-01    4.03e-03\n",
      "perspectives1.57e-01    3.81e-03\n",
      "tech        1.36e-01    3.63e-03\n",
      "issues      1.02e-01    1.17e-03\n",
      "challenges  9.98e-02    1.53e-03\n",
      "focused     9.80e-02    1.48e-03\n",
      "decisions   9.44e-02    1.37e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 3: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "innovation  5.46e-02    1.51e-02\n",
      "people      5.17e-02    3.00e-03\n",
      "customers   5.11e-02    5.75e-03\n",
      "product     4.62e-02    2.09e-03\n",
      "company     4.43e-02    3.51e-03\n",
      "design      4.10e-02    3.63e-03\n",
      "lean        3.74e-02    1.04e-02\n",
      "teams       3.53e-02    2.79e-03\n",
      "employees   3.52e-02    5.84e-03\n",
      "vr          3.46e-02    2.02e-02\n",
      "\n",
      "==========================================================\n",
      "Cluster 4: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "startup     8.90e-02    8.30e-03\n",
      "company     7.03e-02    4.94e-03\n",
      "investors   6.54e-02    6.01e-03\n",
      "business    6.01e-02    5.13e-03\n",
      "founders    5.97e-02    5.52e-03\n",
      "capital     5.67e-02    5.71e-03\n",
      "founder     5.32e-02    4.82e-03\n",
      "money       4.55e-02    3.16e-03\n",
      "startups    4.14e-02    2.49e-03\n",
      "venture     3.99e-02    4.15e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 5: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "companies   5.75e-02    3.67e-03\n",
      "people      4.49e-02    1.89e-03\n",
      "yc          4.28e-02    1.66e-02\n",
      "ai          3.88e-02    1.14e-02\n",
      "trump       3.80e-02    1.45e-02\n",
      "uber        3.42e-02    1.56e-02\n",
      "growth      3.35e-02    6.29e-03\n",
      "company     3.10e-02    1.45e-03\n",
      "price       2.68e-02    8.28e-03\n",
      "market      2.56e-02    1.79e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 6: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "data        8.05e-02    1.21e-02\n",
      "code        4.63e-02    6.60e-03\n",
      "database    2.89e-02    7.07e-03\n",
      "learning    2.80e-02    6.48e-03\n",
      "machine     2.47e-02    4.88e-03\n",
      "server      2.35e-02    2.52e-03\n",
      "use         2.18e-02    4.14e-04\n",
      "new         2.16e-02    4.67e-04\n",
      "performance 2.11e-02    2.31e-03\n",
      "using       2.11e-02    4.40e-04\n",
      "\n",
      "==========================================================\n",
      "Cluster 7: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "design      2.54e-01    1.20e-02\n",
      "designers   1.03e-01    1.30e-02\n",
      "team        6.42e-02    5.43e-03\n",
      "product     5.54e-02    3.46e-03\n",
      "designer    5.30e-02    2.77e-03\n",
      "sprint      5.07e-02    2.15e-02\n",
      "work        5.03e-02    2.75e-03\n",
      "project     3.65e-02    4.07e-03\n",
      "process     3.56e-02    1.71e-03\n",
      "people      3.53e-02    1.51e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 8: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "product     3.44e-01    1.27e-02\n",
      "manager     1.73e-01    6.34e-03\n",
      "managers    1.08e-01    8.43e-03\n",
      "management  1.07e-01    7.23e-03\n",
      "role        6.14e-02    5.65e-03\n",
      "team        6.01e-02    2.07e-03\n",
      "roles       3.72e-02    3.88e-03\n",
      "people      3.32e-02    9.36e-04\n",
      "ceo         3.32e-02    8.91e-03\n",
      "flares      3.10e-02    2.19e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 9: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "customer    2.00e-01    1.27e-02\n",
      "customers   1.52e-01    9.02e-03\n",
      "support     1.00e-01    1.85e-02\n",
      "product     8.34e-02    5.51e-03\n",
      "pricing     6.37e-02    3.08e-02\n",
      "value       6.05e-02    1.21e-02\n",
      "team        6.00e-02    6.06e-03\n",
      "intercom    4.29e-02    6.76e-03\n",
      "revenue     4.14e-02    4.67e-03\n",
      "sales       4.03e-02    8.06e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 10: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "memory      1.18e-01    3.75e-02\n",
      "python      6.32e-02    1.16e-02\n",
      "code        5.99e-02    4.61e-03\n",
      "cpu         5.19e-02    1.83e-02\n",
      "file        4.79e-02    1.20e-02\n",
      "cache       3.87e-02    1.46e-02\n",
      "profiling   3.68e-02    1.28e-02\n",
      "ranking     3.37e-02    1.36e-02\n",
      "disk        3.18e-02    4.93e-03\n",
      "data        3.03e-02    1.12e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 11: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "users       1.32e-01    8.87e-03\n",
      "user        1.13e-01    9.28e-03\n",
      "product     8.06e-02    4.60e-03\n",
      "app         7.46e-02    1.72e-02\n",
      "onboarding  6.14e-02    2.12e-02\n",
      "mobile      4.82e-02    1.39e-02\n",
      "research    4.63e-02    9.67e-03\n",
      "design      4.24e-02    2.81e-03\n",
      "people      4.15e-02    2.54e-03\n",
      "ux          3.84e-02    6.02e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 12: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "platform    1.59e-01    2.52e-02\n",
      "platforms   1.20e-01    1.63e-02\n",
      "network     1.03e-01    2.30e-02\n",
      "effects     6.43e-02    1.35e-02\n",
      "product     4.80e-02    6.65e-03\n",
      "products    4.48e-02    5.47e-03\n",
      "value       4.22e-02    2.69e-03\n",
      "facebook    3.97e-02    9.95e-03\n",
      "business    3.97e-02    2.07e-03\n",
      "snap        3.52e-02    1.96e-02\n",
      "\n",
      "==========================================================\n",
      "Cluster 13: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "product     2.31e-01    7.54e-03\n",
      "market      5.20e-02    6.99e-03\n",
      "customers   5.06e-02    2.52e-03\n",
      "customer    4.64e-02    2.93e-03\n",
      "team        4.16e-02    2.37e-03\n",
      "products    4.08e-02    1.43e-03\n",
      "development 3.79e-02    4.58e-03\n",
      "new         3.64e-02    1.79e-03\n",
      "marketing   3.61e-02    4.98e-03\n",
      "users       3.38e-02    2.19e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 14: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "team        2.24e-01    1.03e-02\n",
      "teams       1.18e-01    1.48e-02\n",
      "culture     9.06e-02    2.81e-02\n",
      "work        5.13e-02    1.41e-03\n",
      "people      5.05e-02    2.09e-03\n",
      "product     4.98e-02    4.39e-03\n",
      "company     4.53e-02    2.26e-03\n",
      "members     4.43e-02    3.49e-03\n",
      "growth      4.20e-02    1.67e-02\n",
      "time        3.62e-02    8.41e-04\n",
      "\n",
      "==========================================================\n",
      "Cluster 15: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "page        2.52e-02    3.42e-03\n",
      "product     2.35e-02    1.22e-03\n",
      "content     2.31e-02    4.85e-03\n",
      "email       2.27e-02    6.55e-03\n",
      "like        1.86e-02    4.80e-04\n",
      "design      1.80e-02    1.13e-03\n",
      "people      1.79e-02    6.76e-04\n",
      "brand       1.77e-02    3.44e-03\n",
      "sketch      1.76e-02    6.88e-03\n",
      "google      1.66e-02    3.95e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 16: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "microservices1.87e-01    4.90e-02\n",
      "serverless  1.36e-01    5.29e-02\n",
      "services    9.59e-02    8.54e-03\n",
      "faas        8.30e-02    4.58e-02\n",
      "service     7.83e-02    9.55e-03\n",
      "application 5.73e-02    2.56e-03\n",
      "architecture5.41e-02    3.38e-03\n",
      "cloud       5.20e-02    8.43e-03\n",
      "processing  4.99e-02    1.39e-02\n",
      "microservice4.52e-02    6.69e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 17: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "ux          2.81e-01    4.83e-02\n",
      "design      1.58e-01    9.25e-03\n",
      "designer    1.58e-01    2.66e-02\n",
      "newslog     9.08e-02    3.56e-02\n",
      "meets       6.33e-02    1.69e-02\n",
      "medium      5.44e-02    4.55e-02\n",
      "community   4.83e-02    6.82e-03\n",
      "experience  4.55e-02    2.70e-03\n",
      "news        4.51e-02    7.15e-03\n",
      "product     4.50e-02    5.30e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 18: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "pm          2.58e-01    3.52e-02\n",
      "product     1.90e-01    7.29e-03\n",
      "pms         1.11e-01    1.13e-02\n",
      "team        6.56e-02    2.21e-03\n",
      "manager     5.72e-02    1.65e-03\n",
      "good        4.48e-02    2.62e-03\n",
      "design      4.44e-02    2.99e-03\n",
      "goals       3.86e-02    1.31e-02\n",
      "need        3.79e-02    6.49e-04\n",
      "ve          3.66e-02    1.52e-03\n",
      "\n",
      "==========================================================\n",
      "Cluster 19: Largest mean parameters in cluster \n",
      "\n",
      "Word        Mean        Variance    \n",
      "xero        3.86e-01    3.81e-06\n",
      "vet         2.42e-01    1.50e-06\n",
      "institute   2.20e-01    1.23e-06\n",
      "codigodelsur1.98e-01    1.00e-06\n",
      "tech        1.78e-01    8.07e-07\n",
      "veteran     1.65e-01    7.01e-07\n",
      "accounting  1.56e-01    6.25e-07\n",
      "firms       1.38e-01    4.89e-07\n",
      "founder     1.31e-01    4.38e-07\n",
      "highly      1.01e-01    2.61e-07\n",
      "\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "visualize_EM_clusters(tf_idf_matrix, model_em_20k['means'], model_em_20k['covs'], tfidfvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster  0 assignments:  358.0\n",
      "cluster  1 assignments:  301.0\n",
      "cluster  2 assignments:  257.0\n",
      "cluster  3 assignments:  127.0\n",
      "cluster  4 assignments:  17.0\n",
      "cluster  5 assignments:  155.0\n",
      "cluster  6 assignments:  18.0\n",
      "cluster  7 assignments:  25.0\n",
      "cluster  8 assignments:  121.0\n",
      "cluster  9 assignments:  11.0\n"
     ]
    }
   ],
   "source": [
    "# No. of articles in each cluster for first model with 10 clusters\n",
    "resps_10k= sf.SFrame(model_em_10k['resp'])\n",
    "resps_10k= resps_10k.unpack('X1', '')\n",
    "cluster_id=0\n",
    "cluster_hash_10model = {}\n",
    "for col in resps_10k.column_names():\n",
    "    cluster_10k= np.array(resps_10k[col])\n",
    "    print \"cluster \",cluster_id , \"assignments: \", cluster_10k.sum()\n",
    "    cluster_hash_10model[cluster_id] =cluster_10k.nonzero() \n",
    "    cluster_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster  0 assignments:  21.0\n",
      "cluster  1 assignments:  165.0\n",
      "cluster  2 assignments:  25.0\n",
      "cluster  3 assignments:  45.0\n",
      "cluster  4 assignments:  112.0\n",
      "cluster  5 assignments:  90.0\n",
      "cluster  6 assignments:  160.0\n",
      "cluster  7 assignments:  97.0\n",
      "cluster  8 assignments:  38.0\n",
      "cluster  9 assignments:  51.0\n",
      "cluster  10 assignments:  26.0\n",
      "cluster  11 assignments:  89.0\n",
      "cluster  12 assignments:  32.0\n",
      "cluster  13 assignments:  134.0\n",
      "cluster  14 assignments:  47.0\n",
      "cluster  15 assignments:  153.0\n",
      "cluster  16 assignments:  47.0\n",
      "cluster  17 assignments:  21.0\n",
      "cluster  18 assignments:  26.0\n",
      "cluster  19 assignments:  11.0\n"
     ]
    }
   ],
   "source": [
    "# No. of articles in each cluster for second model with 20 clusters\n",
    "resps_20k= sf.SFrame(model_em_20k['resp'])\n",
    "resps_20k= resps_20k.unpack('X1', '')\n",
    "cluster_id=0\n",
    "cluster_hash_20model = {}\n",
    "for col in resps_20k.column_names():\n",
    "    cluster_20k= np.array(resps_20k[col])\n",
    "    print \"cluster \",cluster_id , \"assignments: \", cluster_20k.sum()\n",
    "    cluster_hash_20model[cluster_id] =cluster_20k.nonzero() \n",
    "    cluster_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster  0 \n",
      "==========================\n",
      "\n",
      "product count :  49 \n",
      "engineering count :  6 \n",
      "business count :  303 \n",
      "\n",
      "Cluster  1 \n",
      "==========================\n",
      "\n",
      "product count :  32 \n",
      "engineering count :  235 \n",
      "business count :  34 \n",
      "\n",
      "Cluster  2 \n",
      "==========================\n",
      "\n",
      "product count :  207 \n",
      "engineering count :  0 \n",
      "business count :  50 \n",
      "\n",
      "Cluster  3 \n",
      "==========================\n",
      "\n",
      "product count :  88 \n",
      "engineering count :  3 \n",
      "business count :  36 \n",
      "\n",
      "Cluster  4 \n",
      "==========================\n",
      "\n",
      "product count :  7 \n",
      "engineering count :  0 \n",
      "business count :  10 \n",
      "\n",
      "Cluster  5 \n",
      "==========================\n",
      "\n",
      "product count :  45 \n",
      "engineering count :  8 \n",
      "business count :  102 \n",
      "\n",
      "Cluster  6 \n",
      "==========================\n",
      "\n",
      "product count :  15 \n",
      "engineering count :  2 \n",
      "business count :  1 \n",
      "\n",
      "Cluster  7 \n",
      "==========================\n",
      "\n",
      "product count :  1 \n",
      "engineering count :  23 \n",
      "business count :  1 \n",
      "\n",
      "Cluster  8 \n",
      "==========================\n",
      "\n",
      "product count :  108 \n",
      "engineering count :  0 \n",
      "business count :  13 \n",
      "\n",
      "Cluster  9 \n",
      "==========================\n",
      "\n",
      "product count :  0 \n",
      "engineering count :  0 \n",
      "business count :  11 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Articles' categories in model 1 with 10 clusters\n",
    "clusters_10k_idx=[]\n",
    "for col in resps_10k.column_names():\n",
    "    cluster_10k= np.array(resps_10k[col])\n",
    "    cluster_10k= cluster_10k.nonzero()[0]\n",
    "    clusters_10k_idx.append(cluster_10k)\n",
    "clusters_report(clusters_10k_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster  0 \n",
      "==========================\n",
      "\n",
      "product count :  3 \n",
      "engineering count :  0 \n",
      "business count :  18 \n",
      "\n",
      "Cluster  1 \n",
      "==========================\n",
      "\n",
      "product count :  41 \n",
      "engineering count :  11 \n",
      "business count :  113 \n",
      "\n",
      "Cluster  2 \n",
      "==========================\n",
      "\n",
      "product count :  1 \n",
      "engineering count :  23 \n",
      "business count :  1 \n",
      "\n",
      "Cluster  3 \n",
      "==========================\n",
      "\n",
      "product count :  27 \n",
      "engineering count :  0 \n",
      "business count :  18 \n",
      "\n",
      "Cluster  4 \n",
      "==========================\n",
      "\n",
      "product count :  2 \n",
      "engineering count :  0 \n",
      "business count :  110 \n",
      "\n",
      "Cluster  5 \n",
      "==========================\n",
      "\n",
      "product count :  13 \n",
      "engineering count :  3 \n",
      "business count :  74 \n",
      "\n",
      "Cluster  6 \n",
      "==========================\n",
      "\n",
      "product count :  11 \n",
      "engineering count :  141 \n",
      "business count :  8 \n",
      "\n",
      "Cluster  7 \n",
      "==========================\n",
      "\n",
      "product count :  91 \n",
      "engineering count :  0 \n",
      "business count :  6 \n",
      "\n",
      "Cluster  8 \n",
      "==========================\n",
      "\n",
      "product count :  38 \n",
      "engineering count :  0 \n",
      "business count :  0 \n",
      "\n",
      "Cluster  9 \n",
      "==========================\n",
      "\n",
      "product count :  21 \n",
      "engineering count :  0 \n",
      "business count :  30 \n",
      "\n",
      "Cluster  10 \n",
      "==========================\n",
      "\n",
      "product count :  1 \n",
      "engineering count :  24 \n",
      "business count :  1 \n",
      "\n",
      "Cluster  11 \n",
      "==========================\n",
      "\n",
      "product count :  78 \n",
      "engineering count :  1 \n",
      "business count :  10 \n",
      "\n",
      "Cluster  12 \n",
      "==========================\n",
      "\n",
      "product count :  3 \n",
      "engineering count :  1 \n",
      "business count :  28 \n",
      "\n",
      "Cluster  13 \n",
      "==========================\n",
      "\n",
      "product count :  103 \n",
      "engineering count :  0 \n",
      "business count :  31 \n",
      "\n",
      "Cluster  14 \n",
      "==========================\n",
      "\n",
      "product count :  13 \n",
      "engineering count :  6 \n",
      "business count :  28 \n",
      "\n",
      "Cluster  15 \n",
      "==========================\n",
      "\n",
      "product count :  67 \n",
      "engineering count :  20 \n",
      "business count :  66 \n",
      "\n",
      "Cluster  16 \n",
      "==========================\n",
      "\n",
      "product count :  0 \n",
      "engineering count :  45 \n",
      "business count :  2 \n",
      "\n",
      "Cluster  17 \n",
      "==========================\n",
      "\n",
      "product count :  16 \n",
      "engineering count :  2 \n",
      "business count :  3 \n",
      "\n",
      "Cluster  18 \n",
      "==========================\n",
      "\n",
      "product count :  23 \n",
      "engineering count :  0 \n",
      "business count :  3 \n",
      "\n",
      "Cluster  19 \n",
      "==========================\n",
      "\n",
      "product count :  0 \n",
      "engineering count :  0 \n",
      "business count :  11 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Articles' categories in model 2 with 20 clusters\n",
    "clusters_20k_idx=[]\n",
    "for col in resps_20k.column_names():\n",
    "    cluster_20k= np.array(resps_20k[col])\n",
    "    cluster_20k= cluster_20k.nonzero()[0]\n",
    "    clusters_20k_idx.append(cluster_20k)\n",
    "clusters_report(clusters_20k_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4\n",
    "## Recommendation and predictions for Articles\n",
    "\n",
    "#### Recommendation method: \n",
    "A method for recommending articles by retrieving the cluster that the article belong to, then fetch all the articles in that cluster articles passed to nearest neighbour model to find the best 10 articles recommended for this article.\n",
    "\n",
    "#### Predicting method:\n",
    "Sending set of articles to predict the cluster it belong based on the trained data \n",
    "\n",
    "\n",
    "- Using the test dataset to predict cluster for each one using two different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def articles_inds(article_id , cluster_hash_model):\n",
    "    for cluster_id in cluster_hash_model: \n",
    "        np_array = np.array(cluster_hash_model[cluster_id])\n",
    "        if article_id in np_array:\n",
    "            return cluster_id, np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommender(article_id ,cluster_hash_model, no_articles, data_articles):\n",
    "    start_time = time.time()\n",
    "    cid , inds = articles_inds(article_id ,cluster_hash_model)\n",
    "    cluster_articles= data_articles.filter_by(inds[0] , 'X1')\n",
    "    cluster_articles = cluster_articles.add_row_number()\n",
    "\n",
    "    recom_vec= TfidfVectorizer(stop_words='english')\n",
    "    tfidf_recommend= recom_vec.fit_transform(cluster_articles['text'])\n",
    "    tfidf_recommend = normalize(tfidf_recommend)\n",
    "    \n",
    "    row_id = cluster_articles[cluster_articles['X1']==article_id]['id'][0]\n",
    "    NN_model = NearestNeighbors(n_neighbors=no_articles).fit(tfidf_recommend)\n",
    "    distances, indices = NN_model.kneighbors(tfidf_recommend[row_id])\n",
    "    \n",
    "    recommended_ids=[]\n",
    "    for i in indices[0]:\n",
    "        recommended_ids.append(cluster_articles[cluster_articles['id']==i]['X1'][0])\n",
    "    \n",
    "    del cluster_articles\n",
    "    del tfidf_recommend\n",
    "    #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    #print len(inds[0])\n",
    "    return recommended_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_cluster(articles,em_model):\n",
    "    article_tfidf= tfidfvec.transform(articles['text'])\n",
    "    mu= deepcopy(em_model['means'])\n",
    "    sigma= deepcopy(em_model['covs'])\n",
    "    assignments=[]\n",
    "    for j in range(article_tfidf.shape[0]):\n",
    "        resps=[]\n",
    "        for i in range(len(em_model['weights'])):\n",
    "            predict= np.log(em_model['weights'][i]) + logpdf_diagonal_gaussian(article_tfidf[j], mu[i],sigma[i])\n",
    "            resps.append(predict)\n",
    "        assignments.append(resps.index(np.max(resps)))\n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 608.989954948 seconds (Final time complexity): ---\n"
     ]
    }
   ],
   "source": [
    "# Recommend articles for all dataset then append it into the SFrame database then export it.\n",
    "recommended_inds = []\n",
    "start_time = time.time()\n",
    "for i in range(len(dataset)):\n",
    "    recommended_inds.append(recommender(i,cluster_hash_20model,11,dataset))\n",
    "\n",
    "print(\"--- %s seconds (Final time complexity): ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">X1</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">category</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">text</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">tf_idf</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">recommendations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">business</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Policy for Growth and<br>InnovationI get asked ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'stock':<br>3.248074979560463, 'r ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[0.0, 1.0, 217.0, 7.0,<br>609.0, 506.0, 210.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">business</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Sam AltmanThe most<br>important story of 2014 ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'petroyuan':<br>7.237059026124737, 'a ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[1.0, 0.0, 7.0, 506.0,<br>210.0, 130.0, 1067.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">business</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Bubble talkI m tired of<br>reading about investors ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'talki':<br>7.237059026124737, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[2.0, 236.0, 461.0, 7.0,<br>0.0, 77.0, 441.0, 407.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">business</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">A new team at redditLast<br>week  Yishan Wong ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'ohanian':<br>7.237059026124737, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[3.0, 1038.0, 222.0,<br>132.0, 550.0, 404.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">business</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Why  Ops  Is Taking Over<br>Startup LandA little  ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'operations':<br>26.401277084533294, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[4.0, 680.0, 1079.0,<br>735.0, 5.0, 138.0, 67 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">business</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">10 Data Acquisition<br>Strategies for Startups ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'exclusive':<br>3.28581530754331, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[5.0, 476.0, 580.0,<br>680.0, 1079.0, 138.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">business</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">One of the Greatest<br>Entrepreneurial Stories ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'all':<br>0.3912947246598535, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[6.0, 164.0, 984.0,<br>388.0, 916.0, 67.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">business</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2017 YC Annual LetterDear<br>YC Community   In ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'represent':<br>2.583098675967214, 'a ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[7.0, 77.0, 407.0, 245.0,<br>613.0, 0.0, 30.0, 217.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">business</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">How to Build a Startup<br>Ecosystem in Your ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'all':<br>0.3912947246598535, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[8.0, 348.0, 53.0, 480.0,<br>380.0, 335.0, 510.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">9</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">business</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Growth vs  Profitability<br>and Venture ReturnsThere ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">{'all':<br>0.3912947246598535, ...</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">[9.0, 497.0, 470.0,<br>162.0, 514.0, 114.0, ...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[1390 rows x 5 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tX1\tint\n",
       "\tcategory\tstr\n",
       "\ttext\tstr\n",
       "\ttf_idf\tdict\n",
       "\trecommendations\tarray\n",
       "\n",
       "Rows: 1390\n",
       "\n",
       "Data:\n",
       "+----+----------+-------------------------------+-------------------------------+\n",
       "| X1 | category |              text             |             tf_idf            |\n",
       "+----+----------+-------------------------------+-------------------------------+\n",
       "| 0  | business | Policy for Growth and Inno... | {'stock': 3.24807497956046... |\n",
       "| 1  | business | Sam AltmanThe most importa... | {'petroyuan': 7.2370590261... |\n",
       "| 2  | business | Bubble talkI m tired of re... | {'talki': 7.23705902612473... |\n",
       "| 3  | business | A new team at redditLast w... | {'ohanian': 7.237059026124... |\n",
       "| 4  | business | Why  Ops  Is Taking Over S... | {'operations': 26.40127708... |\n",
       "| 5  | business | 10 Data Acquisition Strate... | {'exclusive': 3.2858153075... |\n",
       "| 6  | business | One of the Greatest Entrep... | {'all': 0.3912947246598535... |\n",
       "| 7  | business | 2017 YC Annual LetterDear ... | {'represent': 2.5830986759... |\n",
       "| 8  | business | How to Build a Startup Eco... | {'all': 0.3912947246598535... |\n",
       "| 9  | business | Growth vs  Profitability a... | {'all': 0.3912947246598535... |\n",
       "+----+----------+-------------------------------+-------------------------------+\n",
       "+-------------------------------+\n",
       "|        recommendations        |\n",
       "+-------------------------------+\n",
       "| [0.0, 1.0, 217.0, 7.0, 609... |\n",
       "| [1.0, 0.0, 7.0, 506.0, 210... |\n",
       "| [2.0, 236.0, 461.0, 7.0, 0... |\n",
       "| [3.0, 1038.0, 222.0, 132.0... |\n",
       "| [4.0, 680.0, 1079.0, 735.0... |\n",
       "| [5.0, 476.0, 580.0, 680.0,... |\n",
       "| [6.0, 164.0, 984.0, 388.0,... |\n",
       "| [7.0, 77.0, 407.0, 245.0, ... |\n",
       "| [8.0, 348.0, 53.0, 480.0, ... |\n",
       "| [9.0, 497.0, 470.0, 162.0,... |\n",
       "+-------------------------------+\n",
       "[1390 rows x 5 columns]\n",
       "Note: Only the head of the SFrame is printed.\n",
       "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_inds= sf.SArray(recommended_inds)\n",
    "dataset.add_column(rec_inds,name='recommendations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.save('Articles_with_recommendations.csv',format='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing data for cluster assigning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/abdl-rahman/Desktop/Recommendation systems/EM for clustering/KO_articles_test.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/abdl-rahman/Desktop/Recommendation systems/EM for clustering/KO_articles_test.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 97 lines in 0.142104 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 97 lines in 0.142104 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /home/abdl-rahman/Desktop/Recommendation systems/EM for clustering/KO_articles_test.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /home/abdl-rahman/Desktop/Recommendation systems/EM for clustering/KO_articles_test.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 97 lines in 0.052418 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 97 lines in 0.052418 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testset = sf.SFrame('KO_articles_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 1, 5, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 1, 5,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 2, 3, 2, 0, 0, 0, 2, 2, 2, 0, 5, 3,\n",
       "       1, 2, 0, 2, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf= tfidfvec.transform(testset['text'])\n",
    "# Predict Using model with 10 clusters.\n",
    "test_predictions= predict_cluster(testset,model_em_10k)\n",
    "test_predictions= np.array(test_predictions)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  1,  1,  1,  5,  1,  4,  4,  6, 13,  1,  4,  5, 15,  4,  5, 15,\n",
       "        1,  6, 13,  6,  6,  6,  6,  6, 13,  4,  6,  6,  6,  6,  1,  6,  7,\n",
       "       16,  6,  6,  6,  6,  6,  6, 11,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6, 13,  4,  6,  6,  6,  6,  1,  6,  7, 16,  6,  6,  6,  6,  6,  6,\n",
       "       11,  6,  6,  6,  6,  6,  5,  6,  4,  1, 15,  1, 13,  1, 13,  4,  1,\n",
       "        4,  1,  1, 13,  1, 13, 11,  6,  8,  1,  1, 15])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Using model with 20 clusters.\n",
    "test_predictions= predict_cluster(testset,model_em_20k)\n",
    "test_predictions= np.array(test_predictions)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
